@inproceedings{10.1145/3252390,
author = {Zhou, Yuanyuan},
title = {Session details: Keynote Address I},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252390},
doi = {10.1145/3252390},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872416,
author = {McKinley, Kathryn S.},
title = {Programming Uncertain &lt;T&gt;hings},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872416},
doi = {10.1145/2954679.2872416},
abstract = {Innovation flourishes with good abstractions. For instance, codification of the IEEE Floating Point standard in 1985 was critical to the subsequent success of scientific computing. Programming languages currently lack appropriate abstractions for uncertain data. Applications already use estimates from sensors, machine learning, big data, humans, and approximate algorithms, but most programming languages do not help developers address correctness, programmability, and optimization problems due to estimates.To address these problems, we propose a new programming abstraction called Uncertain&lt;T&gt; embedded into languages, such as C#, C++, Java, Python, and JavaScript. Applications use familiar discrete operations for estimates with Uncertain&lt;T&gt;. Overloaded conditional operators specify hypothesis tests and applications use them to control false positives and negatives. A simple compositional operator expresses domain knowledge. We carefully restrict expressiveness such that we can build a runtime that implements correct statistical reasoning at conditionals. Our system relieves developers of the need to implement or deeply understand statistics. We demonstrate substantial programmability, correctness, and efficiency benefits of this programming model for GPS sensor navigation, approximate computing, machine learning, and xBox.We encourage the community to develop and use abstractions for estimates.},
journal = {SIGPLAN Not.},
month = mar,
pages = {1–2},
numpages = {2},
keywords = {verification, programming with estimates, probabilistic programming, measurement, lazy evaluation, languages, bayesian logic}
}

@article{10.1145/2980024.2872416,
author = {McKinley, Kathryn S.},
title = {Programming Uncertain &lt;T&gt;hings},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872416},
doi = {10.1145/2980024.2872416},
abstract = {Innovation flourishes with good abstractions. For instance, codification of the IEEE Floating Point standard in 1985 was critical to the subsequent success of scientific computing. Programming languages currently lack appropriate abstractions for uncertain data. Applications already use estimates from sensors, machine learning, big data, humans, and approximate algorithms, but most programming languages do not help developers address correctness, programmability, and optimization problems due to estimates.To address these problems, we propose a new programming abstraction called Uncertain&lt;T&gt; embedded into languages, such as C#, C++, Java, Python, and JavaScript. Applications use familiar discrete operations for estimates with Uncertain&lt;T&gt;. Overloaded conditional operators specify hypothesis tests and applications use them to control false positives and negatives. A simple compositional operator expresses domain knowledge. We carefully restrict expressiveness such that we can build a runtime that implements correct statistical reasoning at conditionals. Our system relieves developers of the need to implement or deeply understand statistics. We demonstrate substantial programmability, correctness, and efficiency benefits of this programming model for GPS sensor navigation, approximate computing, machine learning, and xBox.We encourage the community to develop and use abstractions for estimates.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {1–2},
numpages = {2},
keywords = {verification, programming with estimates, probabilistic programming, measurement, lazy evaluation, languages, bayesian logic}
}

@inproceedings{10.1145/2872362.2872416,
author = {McKinley, Kathryn S.},
title = {Programming Uncertain &lt;T&gt;hings},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872416},
doi = {10.1145/2872362.2872416},
abstract = {Innovation flourishes with good abstractions. For instance, codification of the IEEE Floating Point standard in 1985 was critical to the subsequent success of scientific computing. Programming languages currently lack appropriate abstractions for uncertain data. Applications already use estimates from sensors, machine learning, big data, humans, and approximate algorithms, but most programming languages do not help developers address correctness, programmability, and optimization problems due to estimates.To address these problems, we propose a new programming abstraction called Uncertain&lt;T&gt; embedded into languages, such as C#, C++, Java, Python, and JavaScript. Applications use familiar discrete operations for estimates with Uncertain&lt;T&gt;. Overloaded conditional operators specify hypothesis tests and applications use them to control false positives and negatives. A simple compositional operator expresses domain knowledge. We carefully restrict expressiveness such that we can build a runtime that implements correct statistical reasoning at conditionals. Our system relieves developers of the need to implement or deeply understand statistics. We demonstrate substantial programmability, correctness, and efficiency benefits of this programming model for GPS sensor navigation, approximate computing, machine learning, and xBox.We encourage the community to develop and use abstractions for estimates.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {1–2},
numpages = {2},
keywords = {verification, programming with estimates, probabilistic programming, measurement, lazy evaluation, languages, bayesian logic},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252391,
author = {Wentzlaff, David},
title = {Session details: Session 1A: Multicore},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252391},
doi = {10.1145/3252391},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872396,
author = {Abadal, Sergi and Cabellos-Aparicio, Albert and Alarcon, Eduard and Torrellas, Josep},
title = {WiSync: An Architecture for Fast Synchronization through On-Chip Wireless Communication},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872396},
doi = {10.1145/2980024.2872396},
abstract = {In shared-memory multiprocessing, fine-grain synchronization is challenging because it requires frequent communication. As technology scaling delivers larger manycore chips, such pattern is expected to remain costly to support. In this paper, we propose to address this challenge by using on-chip wireless communication. Each core has a transceiver and an antenna to communicate with all the other cores. This environment supports very low latency global communication. Our architecture, called WiSync, uses a per-core Broadcast Memory (BM). When a core writes to its BM, all the other 100+ BMs get updated in less than 10 processor cycles. We also use a second wireless channel with cheaper transfers to execute barriers efficiently. WiSync supports multiprogramming, virtual memory, and context switching. Our evaluation with simulations of 128-threaded kernels and 64-threaded applications shows that WiSync speeds-up synchronization substantially. Compared to using advanced conventional synchronization, WiSync attains an average speedup of nearly one order of magnitude for the kernels, and 1.12 for PARSEC and SPLASH-2.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {3–17},
numpages = {15},
keywords = {on-chip wireless communication, synchronization}
}

@article{10.1145/2954679.2872396,
author = {Abadal, Sergi and Cabellos-Aparicio, Albert and Alarcon, Eduard and Torrellas, Josep},
title = {WiSync: An Architecture for Fast Synchronization through On-Chip Wireless Communication},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872396},
doi = {10.1145/2954679.2872396},
abstract = {In shared-memory multiprocessing, fine-grain synchronization is challenging because it requires frequent communication. As technology scaling delivers larger manycore chips, such pattern is expected to remain costly to support. In this paper, we propose to address this challenge by using on-chip wireless communication. Each core has a transceiver and an antenna to communicate with all the other cores. This environment supports very low latency global communication. Our architecture, called WiSync, uses a per-core Broadcast Memory (BM). When a core writes to its BM, all the other 100+ BMs get updated in less than 10 processor cycles. We also use a second wireless channel with cheaper transfers to execute barriers efficiently. WiSync supports multiprogramming, virtual memory, and context switching. Our evaluation with simulations of 128-threaded kernels and 64-threaded applications shows that WiSync speeds-up synchronization substantially. Compared to using advanced conventional synchronization, WiSync attains an average speedup of nearly one order of magnitude for the kernels, and 1.12 for PARSEC and SPLASH-2.},
journal = {SIGPLAN Not.},
month = mar,
pages = {3–17},
numpages = {15},
keywords = {on-chip wireless communication, synchronization}
}

@inproceedings{10.1145/2872362.2872396,
author = {Abadal, Sergi and Cabellos-Aparicio, Albert and Alarcon, Eduard and Torrellas, Josep},
title = {WiSync: An Architecture for Fast Synchronization through On-Chip Wireless Communication},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872396},
doi = {10.1145/2872362.2872396},
abstract = {In shared-memory multiprocessing, fine-grain synchronization is challenging because it requires frequent communication. As technology scaling delivers larger manycore chips, such pattern is expected to remain costly to support. In this paper, we propose to address this challenge by using on-chip wireless communication. Each core has a transceiver and an antenna to communicate with all the other cores. This environment supports very low latency global communication. Our architecture, called WiSync, uses a per-core Broadcast Memory (BM). When a core writes to its BM, all the other 100+ BMs get updated in less than 10 processor cycles. We also use a second wireless channel with cheaper transfers to execute barriers efficiently. WiSync supports multiprogramming, virtual memory, and context switching. Our evaluation with simulations of 128-threaded kernels and 64-threaded applications shows that WiSync speeds-up synchronization substantially. Compared to using advanced conventional synchronization, WiSync attains an average speedup of nearly one order of magnitude for the kernels, and 1.12 for PARSEC and SPLASH-2.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {3–17},
numpages = {15},
keywords = {on-chip wireless communication, synchronization},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872382,
author = {Wang, Xiaodong and Mart\'{\i}nez, Jos\'{e} F.},
title = {ReBudget: Trading Off Efficiency vs. Fairness in Market-Based Multicore Resource Allocation via Runtime Budget Reassignment},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872382},
doi = {10.1145/2954679.2872382},
abstract = {Efficiently allocating shared resources in computer systems is critical to optimizing execution. Recently, a number of market-based solutions have been proposed to attack this problem. Some of them provide provable theoretical bounds to efficiency and/or fairness losses under market equilibrium. However, they are limited to markets with potentially important constraints, such as enforcing equal budget for all players, or curve-fitting players' utility into a specific function type. Moreover, they do not generally provide an intuitive "knob" to control efficiency vs. fairness. In this paper, we introduce two new metrics, Market Utility Range (MUR) and Market Budget Range (MBR), through which we provide for the first time theoretical bounds on efficiency and fairness of market equilibria under arbitrary budget assignments. We leverage this result and propose ReBudget, an iterative budget re-assignment algorithm that can be used to control efficiency vs. fairness at run-time. We apply our algorithm to a multi-resource allocation problem in multicore chips. Our evaluation using detailed execution-driven simulations shows that our budget re-assignment technique is intuitive, effective, and efficient.},
journal = {SIGPLAN Not.},
month = mar,
pages = {19–32},
numpages = {14},
keywords = {efficiency, fairness, market equilibria, multicore architectures, scalable resource allocation}
}

@article{10.1145/2980024.2872382,
author = {Wang, Xiaodong and Mart\'{\i}nez, Jos\'{e} F.},
title = {ReBudget: Trading Off Efficiency vs. Fairness in Market-Based Multicore Resource Allocation via Runtime Budget Reassignment},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872382},
doi = {10.1145/2980024.2872382},
abstract = {Efficiently allocating shared resources in computer systems is critical to optimizing execution. Recently, a number of market-based solutions have been proposed to attack this problem. Some of them provide provable theoretical bounds to efficiency and/or fairness losses under market equilibrium. However, they are limited to markets with potentially important constraints, such as enforcing equal budget for all players, or curve-fitting players' utility into a specific function type. Moreover, they do not generally provide an intuitive "knob" to control efficiency vs. fairness. In this paper, we introduce two new metrics, Market Utility Range (MUR) and Market Budget Range (MBR), through which we provide for the first time theoretical bounds on efficiency and fairness of market equilibria under arbitrary budget assignments. We leverage this result and propose ReBudget, an iterative budget re-assignment algorithm that can be used to control efficiency vs. fairness at run-time. We apply our algorithm to a multi-resource allocation problem in multicore chips. Our evaluation using detailed execution-driven simulations shows that our budget re-assignment technique is intuitive, effective, and efficient.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {19–32},
numpages = {14},
keywords = {efficiency, fairness, market equilibria, multicore architectures, scalable resource allocation}
}

@inproceedings{10.1145/2872362.2872382,
author = {Wang, Xiaodong and Mart\'{\i}nez, Jos\'{e} F.},
title = {ReBudget: Trading Off Efficiency vs. Fairness in Market-Based Multicore Resource Allocation via Runtime Budget Reassignment},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872382},
doi = {10.1145/2872362.2872382},
abstract = {Efficiently allocating shared resources in computer systems is critical to optimizing execution. Recently, a number of market-based solutions have been proposed to attack this problem. Some of them provide provable theoretical bounds to efficiency and/or fairness losses under market equilibrium. However, they are limited to markets with potentially important constraints, such as enforcing equal budget for all players, or curve-fitting players' utility into a specific function type. Moreover, they do not generally provide an intuitive "knob" to control efficiency vs. fairness. In this paper, we introduce two new metrics, Market Utility Range (MUR) and Market Budget Range (MBR), through which we provide for the first time theoretical bounds on efficiency and fairness of market equilibria under arbitrary budget assignments. We leverage this result and propose ReBudget, an iterative budget re-assignment algorithm that can be used to control efficiency vs. fairness at run-time. We apply our algorithm to a multi-resource allocation problem in multicore chips. Our evaluation using detailed execution-driven simulations shows that our budget re-assignment technique is intuitive, effective, and efficient.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {19–32},
numpages = {14},
keywords = {efficiency, fairness, market equilibria, multicore architectures, scalable resource allocation},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872394,
author = {Zhu, Haishan and Erez, Mattan},
title = {Dirigent: Enforcing QoS for Latency-Critical Tasks on Shared Multicore Systems},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872394},
doi = {10.1145/2980024.2872394},
abstract = {Latency-critical applications suffer from both average performance degradation and reduced completion time predictability when collocated with batch tasks. Such variation forces the system to overprovision resources to ensure Quality of Service (QoS) for latency-critical tasks, degrading overall system throughput. We explore the causes of this variation and exploit the opportunities of mitigating variation directly to simultaneously improve both QoS and utilization. We develop, implement, and evaluate Dirigent, a lightweight performance-management runtime system that accurately controls the QoS of latency-critical applications at fine time scales, leveraging existing architecture mechanisms. We evaluate Dirigent on a real machine and show that it is significantly more effective than configurations representative of prior schemes.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {33–47},
numpages = {15},
keywords = {run-time prediction, latency tail, latency distribution, colocation, cache partitioning, QoS, DVFs}
}

@article{10.1145/2954679.2872394,
author = {Zhu, Haishan and Erez, Mattan},
title = {Dirigent: Enforcing QoS for Latency-Critical Tasks on Shared Multicore Systems},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872394},
doi = {10.1145/2954679.2872394},
abstract = {Latency-critical applications suffer from both average performance degradation and reduced completion time predictability when collocated with batch tasks. Such variation forces the system to overprovision resources to ensure Quality of Service (QoS) for latency-critical tasks, degrading overall system throughput. We explore the causes of this variation and exploit the opportunities of mitigating variation directly to simultaneously improve both QoS and utilization. We develop, implement, and evaluate Dirigent, a lightweight performance-management runtime system that accurately controls the QoS of latency-critical applications at fine time scales, leveraging existing architecture mechanisms. We evaluate Dirigent on a real machine and show that it is significantly more effective than configurations representative of prior schemes.},
journal = {SIGPLAN Not.},
month = mar,
pages = {33–47},
numpages = {15},
keywords = {run-time prediction, latency tail, latency distribution, colocation, cache partitioning, QoS, DVFs}
}

@inproceedings{10.1145/2872362.2872394,
author = {Zhu, Haishan and Erez, Mattan},
title = {Dirigent: Enforcing QoS for Latency-Critical Tasks on Shared Multicore Systems},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872394},
doi = {10.1145/2872362.2872394},
abstract = {Latency-critical applications suffer from both average performance degradation and reduced completion time predictability when collocated with batch tasks. Such variation forces the system to overprovision resources to ensure Quality of Service (QoS) for latency-critical tasks, degrading overall system throughput. We explore the causes of this variation and exploit the opportunities of mitigating variation directly to simultaneously improve both QoS and utilization. We develop, implement, and evaluate Dirigent, a lightweight performance-management runtime system that accurately controls the QoS of latency-critical applications at fine time scales, leveraging existing architecture mechanisms. We evaluate Dirigent on a real machine and show that it is significantly more effective than configurations representative of prior schemes.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {33–47},
numpages = {15},
keywords = {run-time prediction, latency tail, latency distribution, colocation, cache partitioning, QoS, DVFs},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252392,
author = {Lu, Shan},
title = {Session details: Session 1B: I/O},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252392},
doi = {10.1145/3252392},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872378,
author = {Kuperman, Yossi and Moscovici, Eyal and Nider, Joel and Ladelsky, Razya and Gordon, Abel and Tsafrir, Dan},
title = {Paravirtual Remote I/O},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872378},
doi = {10.1145/2980024.2872378},
abstract = {The traditional "trap and emulate" I/O paravirtualization model conveniently allows for I/O interposition, yet it inherently incurs costly guest-host context switches. The newer "sidecore" model eliminates this overhead by dedicating host (side)cores to poll the relevant guest memory regions and react accordingly without context switching. But the dedication of sidecores on each host might be wasteful when I/O activity is low, or it might not provide enough computational power when I/O activity is high. We propose to alleviate this problem at rack scale by consolidating the dedicated sidecores spread across several hosts onto one server. The hypervisor is then effectively split into two parts: the local hypervisor that hosts the VMs, and the remote hypervisor that processes their paravirtual I/O. We call this model vRIO---paraVirtual Remote I/O. We find that by increasing the latency somewhat, it provides comparable throughput with fewer sidecores and superior throughput with the same number of sidecores as compared to the state of the art. vRIO additionally constitutes a new, cost-effective way to consolidate I/O devices (on the remote hypervisor) while supporting efficient programmable I/O interposition.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {49–65},
numpages = {17},
keywords = {virtualization, virtual I/O models, sidecore, hypervisor, host, guest}
}

@article{10.1145/2954679.2872378,
author = {Kuperman, Yossi and Moscovici, Eyal and Nider, Joel and Ladelsky, Razya and Gordon, Abel and Tsafrir, Dan},
title = {Paravirtual Remote I/O},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872378},
doi = {10.1145/2954679.2872378},
abstract = {The traditional "trap and emulate" I/O paravirtualization model conveniently allows for I/O interposition, yet it inherently incurs costly guest-host context switches. The newer "sidecore" model eliminates this overhead by dedicating host (side)cores to poll the relevant guest memory regions and react accordingly without context switching. But the dedication of sidecores on each host might be wasteful when I/O activity is low, or it might not provide enough computational power when I/O activity is high. We propose to alleviate this problem at rack scale by consolidating the dedicated sidecores spread across several hosts onto one server. The hypervisor is then effectively split into two parts: the local hypervisor that hosts the VMs, and the remote hypervisor that processes their paravirtual I/O. We call this model vRIO---paraVirtual Remote I/O. We find that by increasing the latency somewhat, it provides comparable throughput with fewer sidecores and superior throughput with the same number of sidecores as compared to the state of the art. vRIO additionally constitutes a new, cost-effective way to consolidate I/O devices (on the remote hypervisor) while supporting efficient programmable I/O interposition.},
journal = {SIGPLAN Not.},
month = mar,
pages = {49–65},
numpages = {17},
keywords = {virtualization, virtual I/O models, sidecore, hypervisor, host, guest}
}

@inproceedings{10.1145/2872362.2872378,
author = {Kuperman, Yossi and Moscovici, Eyal and Nider, Joel and Ladelsky, Razya and Gordon, Abel and Tsafrir, Dan},
title = {Paravirtual Remote I/O},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872378},
doi = {10.1145/2872362.2872378},
abstract = {The traditional "trap and emulate" I/O paravirtualization model conveniently allows for I/O interposition, yet it inherently incurs costly guest-host context switches. The newer "sidecore" model eliminates this overhead by dedicating host (side)cores to poll the relevant guest memory regions and react accordingly without context switching. But the dedication of sidecores on each host might be wasteful when I/O activity is low, or it might not provide enough computational power when I/O activity is high. We propose to alleviate this problem at rack scale by consolidating the dedicated sidecores spread across several hosts onto one server. The hypervisor is then effectively split into two parts: the local hypervisor that hosts the VMs, and the remote hypervisor that processes their paravirtual I/O. We call this model vRIO---paraVirtual Remote I/O. We find that by increasing the latency somewhat, it provides comparable throughput with fewer sidecores and superior throughput with the same number of sidecores as compared to the state of the art. vRIO additionally constitutes a new, cost-effective way to consolidate I/O devices (on the remote hypervisor) while supporting efficient programmable I/O interposition.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {49–65},
numpages = {17},
keywords = {virtualization, virtual I/O models, sidecore, hypervisor, host, guest},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872367,
author = {Kaufmann, Antoine and Peter, SImon and Sharma, Naveen Kr. and Anderson, Thomas and Krishnamurthy, Arvind},
title = {High Performance Packet Processing with FlexNIC},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872367},
doi = {10.1145/2980024.2872367},
abstract = {The recent surge of network I/O performance has put enormous pressure on memory and software I/O processing sub systems. We argue that the primary reason for high memory and processing overheads is the inefficient use of these resources by current commodity network interface cards (NICs). We propose FlexNIC, a flexible network DMA interface that can be used by operating systems and applications alike to reduce packet processing overheads. FlexNIC allows services to install packet processing rules into the NIC, which then executes simple operations on packets while exchanging them with host memory. Thus, our proposal moves some of the packet processing traditionally done in software to the NIC, where it can be done flexibly and at high speed.We quantify the potential benefits of FlexNIC by emulating the proposed FlexNIC functionality with existing hardware or in software. We show that significant gains in application performance are possible, in terms of both latency and throughput, for several widely used applications, including a key-value store, a stream processing system, and an intrusion detection system.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {67–81},
numpages = {15},
keywords = {DMA, flexible network processing, match-and-action processing, network interface card}
}

@article{10.1145/2954679.2872367,
author = {Kaufmann, Antoine and Peter, SImon and Sharma, Naveen Kr. and Anderson, Thomas and Krishnamurthy, Arvind},
title = {High Performance Packet Processing with FlexNIC},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872367},
doi = {10.1145/2954679.2872367},
abstract = {The recent surge of network I/O performance has put enormous pressure on memory and software I/O processing sub systems. We argue that the primary reason for high memory and processing overheads is the inefficient use of these resources by current commodity network interface cards (NICs). We propose FlexNIC, a flexible network DMA interface that can be used by operating systems and applications alike to reduce packet processing overheads. FlexNIC allows services to install packet processing rules into the NIC, which then executes simple operations on packets while exchanging them with host memory. Thus, our proposal moves some of the packet processing traditionally done in software to the NIC, where it can be done flexibly and at high speed.We quantify the potential benefits of FlexNIC by emulating the proposed FlexNIC functionality with existing hardware or in software. We show that significant gains in application performance are possible, in terms of both latency and throughput, for several widely used applications, including a key-value store, a stream processing system, and an intrusion detection system.},
journal = {SIGPLAN Not.},
month = mar,
pages = {67–81},
numpages = {15},
keywords = {DMA, flexible network processing, match-and-action processing, network interface card}
}

@inproceedings{10.1145/2872362.2872367,
author = {Kaufmann, Antoine and Peter, SImon and Sharma, Naveen Kr. and Anderson, Thomas and Krishnamurthy, Arvind},
title = {High Performance Packet Processing with FlexNIC},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872367},
doi = {10.1145/2872362.2872367},
abstract = {The recent surge of network I/O performance has put enormous pressure on memory and software I/O processing sub systems. We argue that the primary reason for high memory and processing overheads is the inefficient use of these resources by current commodity network interface cards (NICs). We propose FlexNIC, a flexible network DMA interface that can be used by operating systems and applications alike to reduce packet processing overheads. FlexNIC allows services to install packet processing rules into the NIC, which then executes simple operations on packets while exchanging them with host memory. Thus, our proposal moves some of the packet processing traditionally done in software to the NIC, where it can be done flexibly and at high speed.We quantify the potential benefits of FlexNIC by emulating the proposed FlexNIC functionality with existing hardware or in software. We show that significant gains in application performance are possible, in terms of both latency and throughput, for several widely used applications, including a key-value store, a stream processing system, and an intrusion detection system.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {67–81},
numpages = {15},
keywords = {DMA, flexible network processing, match-and-action processing, network interface card},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872406,
author = {Bornholt, James and Kaufmann, Antoine and Li, Jialin and Krishnamurthy, Arvind and Torlak, Emina and Wang, Xi},
title = {Specifying and Checking File System Crash-Consistency Models},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872406},
doi = {10.1145/2980024.2872406},
abstract = {Applications depend on persistent storage to recover state after system crashes. But the POSIX file system interfaces do not define the possible outcomes of a crash. As a result, it is difficult for application writers to correctly understand the ordering of and dependencies between file system operations, which can lead to corrupt application state and, in the worst case, catastrophic data loss. This paper presents crash-consistency models, analogous to memory consistency models, which describe the behavior of a file system across crashes. Crash-consistency models include both litmus tests, which demonstrate allowed and forbidden behaviors, and axiomatic and operational specifications. We present a formal framework for developing crash-consistency models, and a toolkit, called Ferrite, for validating those models against real file system implementations. We develop a crash-consistency model for ext4, and use Ferrite to demonstrate unintuitive crash behaviors of the ext4 implementation. To demonstrate the utility of crash-consistency models to application writers, we use our models to prototype proof-of-concept verification and synthesis tools, as well as new library interfaces for crash-safe applications.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {83–98},
numpages = {16},
keywords = {crash consistency, file systems, verification}
}

@article{10.1145/2954679.2872406,
author = {Bornholt, James and Kaufmann, Antoine and Li, Jialin and Krishnamurthy, Arvind and Torlak, Emina and Wang, Xi},
title = {Specifying and Checking File System Crash-Consistency Models},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872406},
doi = {10.1145/2954679.2872406},
abstract = {Applications depend on persistent storage to recover state after system crashes. But the POSIX file system interfaces do not define the possible outcomes of a crash. As a result, it is difficult for application writers to correctly understand the ordering of and dependencies between file system operations, which can lead to corrupt application state and, in the worst case, catastrophic data loss. This paper presents crash-consistency models, analogous to memory consistency models, which describe the behavior of a file system across crashes. Crash-consistency models include both litmus tests, which demonstrate allowed and forbidden behaviors, and axiomatic and operational specifications. We present a formal framework for developing crash-consistency models, and a toolkit, called Ferrite, for validating those models against real file system implementations. We develop a crash-consistency model for ext4, and use Ferrite to demonstrate unintuitive crash behaviors of the ext4 implementation. To demonstrate the utility of crash-consistency models to application writers, we use our models to prototype proof-of-concept verification and synthesis tools, as well as new library interfaces for crash-safe applications.},
journal = {SIGPLAN Not.},
month = mar,
pages = {83–98},
numpages = {16},
keywords = {crash consistency, file systems, verification}
}

@inproceedings{10.1145/2872362.2872406,
author = {Bornholt, James and Kaufmann, Antoine and Li, Jialin and Krishnamurthy, Arvind and Torlak, Emina and Wang, Xi},
title = {Specifying and Checking File System Crash-Consistency Models},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872406},
doi = {10.1145/2872362.2872406},
abstract = {Applications depend on persistent storage to recover state after system crashes. But the POSIX file system interfaces do not define the possible outcomes of a crash. As a result, it is difficult for application writers to correctly understand the ordering of and dependencies between file system operations, which can lead to corrupt application state and, in the worst case, catastrophic data loss. This paper presents crash-consistency models, analogous to memory consistency models, which describe the behavior of a file system across crashes. Crash-consistency models include both litmus tests, which demonstrate allowed and forbidden behaviors, and axiomatic and operational specifications. We present a formal framework for developing crash-consistency models, and a toolkit, called Ferrite, for validating those models against real file system implementations. We develop a crash-consistency model for ext4, and use Ferrite to demonstrate unintuitive crash behaviors of the ext4 implementation. To demonstrate the utility of crash-consistency models to application writers, we use our models to prototype proof-of-concept verification and synthesis tools, as well as new library interfaces for crash-safe applications.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {83–98},
numpages = {16},
keywords = {crash consistency, file systems, verification},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252393,
author = {Bianchini, Ricardo},
title = {Session details: Session 2A: Memory Management},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252393},
doi = {10.1145/3252393},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872405,
author = {Prasad, Aravinda and Gopinath, K.},
title = {Prudent Memory Reclamation in Procrastination-Based Synchronization},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872405},
doi = {10.1145/2954679.2872405},
abstract = {Procrastination is the fundamental technique used in synchronization mechanisms such as Read-Copy-Update (RCU) where writers, in order to synchronize with readers, defer the freeing of an object until there are no readers referring to the object. The synchronization mechanism determines when the deferred object is safe to reclaim and when it is actually reclaimed. Hence, such memory reclamations are completely oblivious of the memory allocator state. This induces poor memory allocator performance, for instance, when the reclamations are ill-timed. Furthermore, deferred objects provide hints about the future that inform memory regions that are about to be freed. Although useful, hints are not exploited as deferred objects are not visible to memory allocators. We introduce Prudence, a dynamic memory allocator, that is tightly integrated with the synchronization mechanism to ensure visibility of deferred objects to the memory allocator. Such an integration enables Prudence to (i) identify the safe time to reclaim deferred objects' memory, (ii) have an inclusive view of the allocated, free and about-to-be-freed objects, and (iii) exploit optimizations based on the hints about the future during important state transitions. Our evaluation in the Linux kernel shows that Prudence integrated with RCU performs 3.9X to 28X better in micro-benchmarks compared to SLUB, a recent memory allocator in the Linux kernel. It also improves the overall performance perceptibly (4\%-18\%) for a mix of widely used synthetic and application benchmarks. Further, it performs better (up to 98\%) in terms of object hits in caches, object cache churns, slab churns, peak memory usage and total fragmentation, when compared with the SLUB allocator.},
journal = {SIGPLAN Not.},
month = mar,
pages = {99–112},
numpages = {14},
keywords = {read-copy-update (RCU), memory reclamation, dynamic memory allocator}
}

@article{10.1145/2980024.2872405,
author = {Prasad, Aravinda and Gopinath, K.},
title = {Prudent Memory Reclamation in Procrastination-Based Synchronization},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872405},
doi = {10.1145/2980024.2872405},
abstract = {Procrastination is the fundamental technique used in synchronization mechanisms such as Read-Copy-Update (RCU) where writers, in order to synchronize with readers, defer the freeing of an object until there are no readers referring to the object. The synchronization mechanism determines when the deferred object is safe to reclaim and when it is actually reclaimed. Hence, such memory reclamations are completely oblivious of the memory allocator state. This induces poor memory allocator performance, for instance, when the reclamations are ill-timed. Furthermore, deferred objects provide hints about the future that inform memory regions that are about to be freed. Although useful, hints are not exploited as deferred objects are not visible to memory allocators. We introduce Prudence, a dynamic memory allocator, that is tightly integrated with the synchronization mechanism to ensure visibility of deferred objects to the memory allocator. Such an integration enables Prudence to (i) identify the safe time to reclaim deferred objects' memory, (ii) have an inclusive view of the allocated, free and about-to-be-freed objects, and (iii) exploit optimizations based on the hints about the future during important state transitions. Our evaluation in the Linux kernel shows that Prudence integrated with RCU performs 3.9X to 28X better in micro-benchmarks compared to SLUB, a recent memory allocator in the Linux kernel. It also improves the overall performance perceptibly (4\%-18\%) for a mix of widely used synthetic and application benchmarks. Further, it performs better (up to 98\%) in terms of object hits in caches, object cache churns, slab churns, peak memory usage and total fragmentation, when compared with the SLUB allocator.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {99–112},
numpages = {14},
keywords = {read-copy-update (RCU), memory reclamation, dynamic memory allocator}
}

@inproceedings{10.1145/2872362.2872405,
author = {Prasad, Aravinda and Gopinath, K.},
title = {Prudent Memory Reclamation in Procrastination-Based Synchronization},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872405},
doi = {10.1145/2872362.2872405},
abstract = {Procrastination is the fundamental technique used in synchronization mechanisms such as Read-Copy-Update (RCU) where writers, in order to synchronize with readers, defer the freeing of an object until there are no readers referring to the object. The synchronization mechanism determines when the deferred object is safe to reclaim and when it is actually reclaimed. Hence, such memory reclamations are completely oblivious of the memory allocator state. This induces poor memory allocator performance, for instance, when the reclamations are ill-timed. Furthermore, deferred objects provide hints about the future that inform memory regions that are about to be freed. Although useful, hints are not exploited as deferred objects are not visible to memory allocators. We introduce Prudence, a dynamic memory allocator, that is tightly integrated with the synchronization mechanism to ensure visibility of deferred objects to the memory allocator. Such an integration enables Prudence to (i) identify the safe time to reclaim deferred objects' memory, (ii) have an inclusive view of the allocated, free and about-to-be-freed objects, and (iii) exploit optimizations based on the hints about the future during important state transitions. Our evaluation in the Linux kernel shows that Prudence integrated with RCU performs 3.9X to 28X better in micro-benchmarks compared to SLUB, a recent memory allocator in the Linux kernel. It also improves the overall performance perceptibly (4\%-18\%) for a mix of widely used synthetic and application benchmarks. Further, it performs better (up to 98\%) in terms of object hits in caches, object cache churns, slab churns, peak memory usage and total fragmentation, when compared with the SLUB allocator.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {99–112},
numpages = {14},
keywords = {read-copy-update (RCU), memory reclamation, dynamic memory allocator},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872363,
author = {Mukkara, Anurag and Beckmann, Nathan and Sanchez, Daniel},
title = {Whirlpool: Improving Dynamic Cache Management with Static Data Classification},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872363},
doi = {10.1145/2980024.2872363},
abstract = {Cache hierarchies are increasingly non-uniform and difficult to manage. Several techniques, such as scratchpads or reuse hints, use static information about how programs access data to manage the memory hierarchy. Static techniques are effective on regular programs, but because they set fixed policies, they are vulnerable to changes in program behavior or available cache space. Instead, most systems rely on dynamic caching policies that adapt to observed program behavior. Unfortunately, dynamic policies spend significant resources trying to learn how programs use memory, and yet they often perform worse than a static policy. We present Whirlpool, a novel approach that combines static information with dynamic policies to reap the benefits of each. Whirlpool statically classifies data into pools based on how the program uses memory. Whirlpool then uses dynamic policies to tune the cache to each pool. Hence, rather than setting policies statically, Whirlpool uses static analysis to guide dynamic policies. We present both an API that lets programmers specify pools manually and a profiling tool that discovers pools automatically in unmodified binaries.We evaluate Whirlpool on a state-of-the-art NUCA cache. Whirlpool significantly outperforms prior approaches: on sequential programs, Whirlpool improves performance by up to 38\% and reduces data movement energy by up to 53\%; on parallel programs, Whirlpool improves performance by up to 67\% and reduces data movement energy by up to 2.6x.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {113–127},
numpages = {15},
keywords = {cache modeling, data movement, non-uniform cache access (NUCA), static analysis}
}

@article{10.1145/2954679.2872363,
author = {Mukkara, Anurag and Beckmann, Nathan and Sanchez, Daniel},
title = {Whirlpool: Improving Dynamic Cache Management with Static Data Classification},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872363},
doi = {10.1145/2954679.2872363},
abstract = {Cache hierarchies are increasingly non-uniform and difficult to manage. Several techniques, such as scratchpads or reuse hints, use static information about how programs access data to manage the memory hierarchy. Static techniques are effective on regular programs, but because they set fixed policies, they are vulnerable to changes in program behavior or available cache space. Instead, most systems rely on dynamic caching policies that adapt to observed program behavior. Unfortunately, dynamic policies spend significant resources trying to learn how programs use memory, and yet they often perform worse than a static policy. We present Whirlpool, a novel approach that combines static information with dynamic policies to reap the benefits of each. Whirlpool statically classifies data into pools based on how the program uses memory. Whirlpool then uses dynamic policies to tune the cache to each pool. Hence, rather than setting policies statically, Whirlpool uses static analysis to guide dynamic policies. We present both an API that lets programmers specify pools manually and a profiling tool that discovers pools automatically in unmodified binaries.We evaluate Whirlpool on a state-of-the-art NUCA cache. Whirlpool significantly outperforms prior approaches: on sequential programs, Whirlpool improves performance by up to 38\% and reduces data movement energy by up to 53\%; on parallel programs, Whirlpool improves performance by up to 67\% and reduces data movement energy by up to 2.6x.},
journal = {SIGPLAN Not.},
month = mar,
pages = {113–127},
numpages = {15},
keywords = {cache modeling, data movement, non-uniform cache access (NUCA), static analysis}
}

@inproceedings{10.1145/2872362.2872363,
author = {Mukkara, Anurag and Beckmann, Nathan and Sanchez, Daniel},
title = {Whirlpool: Improving Dynamic Cache Management with Static Data Classification},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872363},
doi = {10.1145/2872362.2872363},
abstract = {Cache hierarchies are increasingly non-uniform and difficult to manage. Several techniques, such as scratchpads or reuse hints, use static information about how programs access data to manage the memory hierarchy. Static techniques are effective on regular programs, but because they set fixed policies, they are vulnerable to changes in program behavior or available cache space. Instead, most systems rely on dynamic caching policies that adapt to observed program behavior. Unfortunately, dynamic policies spend significant resources trying to learn how programs use memory, and yet they often perform worse than a static policy. We present Whirlpool, a novel approach that combines static information with dynamic policies to reap the benefits of each. Whirlpool statically classifies data into pools based on how the program uses memory. Whirlpool then uses dynamic policies to tune the cache to each pool. Hence, rather than setting policies statically, Whirlpool uses static analysis to guide dynamic policies. We present both an API that lets programmers specify pools manually and a profiling tool that discovers pools automatically in unmodified binaries.We evaluate Whirlpool on a state-of-the-art NUCA cache. Whirlpool significantly outperforms prior approaches: on sequential programs, Whirlpool improves performance by up to 38\% and reduces data movement energy by up to 53\%; on parallel programs, Whirlpool improves performance by up to 67\% and reduces data movement energy by up to 2.6x.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {113–127},
numpages = {15},
keywords = {cache modeling, data movement, non-uniform cache access (NUCA), static analysis},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872370,
author = {Jeon, Myeongjae and He, Yuxiong and Kim, Hwanju and Elnikety, Sameh and Rixner, Scott and Cox, Alan L.},
title = {TPC: Target-Driven Parallelism Combining Prediction and Correction to Reduce Tail Latency in Interactive Services},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872370},
doi = {10.1145/2980024.2872370},
abstract = {In interactive services such as web search, recommendations, games and finance, reducing the tail latency is crucial to provide fast response to every user. Using web search as a driving example, we systematically characterize interactive workload to identify the opportunities and challenges for reducing tail latency. We find that the workload consists of mainly short requests that do not benefit from parallelism, and a few long requests which significantly impact the tail but exhibit high parallelism speedup. This motivates estimating request execution time, using a predictor, to identify long requests and to parallelize them. Prediction, however, is not perfect; a long request mispredicted as short is likely to contribute to the server tail latency, setting a ceiling on the achievable tail latency. We propose TPC, an approach that combines prediction information judiciously with dynamic correction for inaccurate prediction. Dynamic correction increases parallelism to accelerate a long request that is mispredicted as short. TPC carefully selects the appropriate target latencies based on system load and parallelism efficiency to reduce tail latency.We implement TPC and several prior approaches to compare them experimentally on a single search server and on a cluster of 40 search servers. The experimental results show that TPC reduces the 99th- and 99.9th-percentile latency by up to 40\% compared with the best prior work. Moreover, we evaluate TPC on a finance server, demonstrating its effectiveness on reducing tail latency of interactive services beyond web search.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {129–141},
numpages = {13},
keywords = {web search, thread scheduling, tail latency, parallelism, machine learning, interactive services}
}

@article{10.1145/2954679.2872370,
author = {Jeon, Myeongjae and He, Yuxiong and Kim, Hwanju and Elnikety, Sameh and Rixner, Scott and Cox, Alan L.},
title = {TPC: Target-Driven Parallelism Combining Prediction and Correction to Reduce Tail Latency in Interactive Services},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872370},
doi = {10.1145/2954679.2872370},
abstract = {In interactive services such as web search, recommendations, games and finance, reducing the tail latency is crucial to provide fast response to every user. Using web search as a driving example, we systematically characterize interactive workload to identify the opportunities and challenges for reducing tail latency. We find that the workload consists of mainly short requests that do not benefit from parallelism, and a few long requests which significantly impact the tail but exhibit high parallelism speedup. This motivates estimating request execution time, using a predictor, to identify long requests and to parallelize them. Prediction, however, is not perfect; a long request mispredicted as short is likely to contribute to the server tail latency, setting a ceiling on the achievable tail latency. We propose TPC, an approach that combines prediction information judiciously with dynamic correction for inaccurate prediction. Dynamic correction increases parallelism to accelerate a long request that is mispredicted as short. TPC carefully selects the appropriate target latencies based on system load and parallelism efficiency to reduce tail latency.We implement TPC and several prior approaches to compare them experimentally on a single search server and on a cluster of 40 search servers. The experimental results show that TPC reduces the 99th- and 99.9th-percentile latency by up to 40\% compared with the best prior work. Moreover, we evaluate TPC on a finance server, demonstrating its effectiveness on reducing tail latency of interactive services beyond web search.},
journal = {SIGPLAN Not.},
month = mar,
pages = {129–141},
numpages = {13},
keywords = {web search, thread scheduling, tail latency, parallelism, machine learning, interactive services}
}

@inproceedings{10.1145/2872362.2872370,
author = {Jeon, Myeongjae and He, Yuxiong and Kim, Hwanju and Elnikety, Sameh and Rixner, Scott and Cox, Alan L.},
title = {TPC: Target-Driven Parallelism Combining Prediction and Correction to Reduce Tail Latency in Interactive Services},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872370},
doi = {10.1145/2872362.2872370},
abstract = {In interactive services such as web search, recommendations, games and finance, reducing the tail latency is crucial to provide fast response to every user. Using web search as a driving example, we systematically characterize interactive workload to identify the opportunities and challenges for reducing tail latency. We find that the workload consists of mainly short requests that do not benefit from parallelism, and a few long requests which significantly impact the tail but exhibit high parallelism speedup. This motivates estimating request execution time, using a predictor, to identify long requests and to parallelize them. Prediction, however, is not perfect; a long request mispredicted as short is likely to contribute to the server tail latency, setting a ceiling on the achievable tail latency. We propose TPC, an approach that combines prediction information judiciously with dynamic correction for inaccurate prediction. Dynamic correction increases parallelism to accelerate a long request that is mispredicted as short. TPC carefully selects the appropriate target latencies based on system load and parallelism efficiency to reduce tail latency.We implement TPC and several prior approaches to compare them experimentally on a single search server and on a cluster of 40 search servers. The experimental results show that TPC reduces the 99th- and 99.9th-percentile latency by up to 40\% compared with the best prior work. Moreover, we evaluate TPC on a finance server, demonstrating its effectiveness on reducing tail latency of interactive services beyond web search.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {129–141},
numpages = {13},
keywords = {web search, thread scheduling, tail latency, parallelism, machine learning, interactive services},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252394,
author = {Muller, Gilles},
title = {Session details: Session 2B: Reliability and Debugging I},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252394},
doi = {10.1145/3252394},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872364,
author = {Brown, Fraser and N\"{o}tzli, Andres and Engler, Dawson},
title = {How to Build Static Checking Systems Using Orders of Magnitude Less Code},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872364},
doi = {10.1145/2954679.2872364},
abstract = {Modern static bug finding tools are complex. They typically consist of hundreds of thousands of lines of code, and most of them are wedded to one language (or even one compiler). This complexity makes the systems hard to understand, hard to debug, and hard to retarget to new languages, thereby dramatically limiting their scope. This paper reduces checking system complexity by addressing a fundamental assumption, the assumption that checkers must depend on a full-blown language specification and compiler front end. Instead, our program checkers are based on drastically incomplete language grammars ("micro-grammars") that describe only portions of a language relevant to a checker. As a result, our implementation is tiny-roughly 2500 lines of code, about two orders of magnitude smaller than a typical system. We hope that this dramatic increase in simplicity will allow people to use more checkers on more systems in more languages.We implement our approach in μchex, a language-agnostic framework for writing static bug checkers. We use it to build micro-grammar based checkers for six languages (C, the C preprocessor, C++, Java, JavaScript, and Dart) and find over 700 errors in real-world projects.},
journal = {SIGPLAN Not.},
month = mar,
pages = {143–157},
numpages = {15},
keywords = {bug finding, micro-grammars, parsing, static analysis}
}

@article{10.1145/2980024.2872364,
author = {Brown, Fraser and N\"{o}tzli, Andres and Engler, Dawson},
title = {How to Build Static Checking Systems Using Orders of Magnitude Less Code},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872364},
doi = {10.1145/2980024.2872364},
abstract = {Modern static bug finding tools are complex. They typically consist of hundreds of thousands of lines of code, and most of them are wedded to one language (or even one compiler). This complexity makes the systems hard to understand, hard to debug, and hard to retarget to new languages, thereby dramatically limiting their scope. This paper reduces checking system complexity by addressing a fundamental assumption, the assumption that checkers must depend on a full-blown language specification and compiler front end. Instead, our program checkers are based on drastically incomplete language grammars ("micro-grammars") that describe only portions of a language relevant to a checker. As a result, our implementation is tiny-roughly 2500 lines of code, about two orders of magnitude smaller than a typical system. We hope that this dramatic increase in simplicity will allow people to use more checkers on more systems in more languages.We implement our approach in μchex, a language-agnostic framework for writing static bug checkers. We use it to build micro-grammar based checkers for six languages (C, the C preprocessor, C++, Java, JavaScript, and Dart) and find over 700 errors in real-world projects.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {143–157},
numpages = {15},
keywords = {bug finding, micro-grammars, parsing, static analysis}
}

@inproceedings{10.1145/2872362.2872364,
author = {Brown, Fraser and N\"{o}tzli, Andres and Engler, Dawson},
title = {How to Build Static Checking Systems Using Orders of Magnitude Less Code},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872364},
doi = {10.1145/2872362.2872364},
abstract = {Modern static bug finding tools are complex. They typically consist of hundreds of thousands of lines of code, and most of them are wedded to one language (or even one compiler). This complexity makes the systems hard to understand, hard to debug, and hard to retarget to new languages, thereby dramatically limiting their scope. This paper reduces checking system complexity by addressing a fundamental assumption, the assumption that checkers must depend on a full-blown language specification and compiler front end. Instead, our program checkers are based on drastically incomplete language grammars ("micro-grammars") that describe only portions of a language relevant to a checker. As a result, our implementation is tiny-roughly 2500 lines of code, about two orders of magnitude smaller than a typical system. We hope that this dramatic increase in simplicity will allow people to use more checkers on more systems in more languages.We implement our approach in μchex, a language-agnostic framework for writing static bug checkers. We use it to build micro-grammar based checkers for six languages (C, the C preprocessor, C++, Java, JavaScript, and Dart) and find over 700 errors in real-world projects.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {143–157},
numpages = {15},
keywords = {bug finding, micro-grammars, parsing, static analysis},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872384,
author = {Zhang, Tong and Lee, Dongyoon and Jung, Changhee},
title = {TxRace: Efficient Data Race Detection Using Commodity Hardware Transactional Memory},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872384},
doi = {10.1145/2954679.2872384},
abstract = {Detecting data races is important for debugging shared-memory multithreaded programs, but the high runtime overhead prevents the wide use of dynamic data race detectors. This paper presents TxRace, a new software data race detector that leverages commodity hardware transactional memory (HTM) to speed up data race detection. TxRace instruments a multithreaded program to transform synchronization-free regions into transactions, and exploits the conflict detection mechanism of HTM for lightweight data race detection at runtime. However, the limitations of the current best-effort commodity HTMs expose several challenges in using them for data race detection: (1) lack of ability to pinpoint racy instructions, (2) false positives caused by cache line granularity of conflict detection, and (3) transactional aborts for non-conflict reasons (e.g., capacity or unknown). To overcome these challenges, TxRace performs lightweight HTM-based data race detection at first, and occasionally switches to slow yet precise data race detection only for the small fraction of execution intervals in which potential races are reported by HTM. According to the experimental results, TxRace reduces the average runtime overhead of dynamic data race detection from 11.68x to 4.65x with only a small number of false negatives.},
journal = {SIGPLAN Not.},
month = mar,
pages = {159–173},
numpages = {15},
keywords = {hardware transactional memory, dynamic program analysis, data race, concurrency bug detection}
}

@article{10.1145/2980024.2872384,
author = {Zhang, Tong and Lee, Dongyoon and Jung, Changhee},
title = {TxRace: Efficient Data Race Detection Using Commodity Hardware Transactional Memory},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872384},
doi = {10.1145/2980024.2872384},
abstract = {Detecting data races is important for debugging shared-memory multithreaded programs, but the high runtime overhead prevents the wide use of dynamic data race detectors. This paper presents TxRace, a new software data race detector that leverages commodity hardware transactional memory (HTM) to speed up data race detection. TxRace instruments a multithreaded program to transform synchronization-free regions into transactions, and exploits the conflict detection mechanism of HTM for lightweight data race detection at runtime. However, the limitations of the current best-effort commodity HTMs expose several challenges in using them for data race detection: (1) lack of ability to pinpoint racy instructions, (2) false positives caused by cache line granularity of conflict detection, and (3) transactional aborts for non-conflict reasons (e.g., capacity or unknown). To overcome these challenges, TxRace performs lightweight HTM-based data race detection at first, and occasionally switches to slow yet precise data race detection only for the small fraction of execution intervals in which potential races are reported by HTM. According to the experimental results, TxRace reduces the average runtime overhead of dynamic data race detection from 11.68x to 4.65x with only a small number of false negatives.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {159–173},
numpages = {15},
keywords = {hardware transactional memory, dynamic program analysis, data race, concurrency bug detection}
}

@inproceedings{10.1145/2872362.2872384,
author = {Zhang, Tong and Lee, Dongyoon and Jung, Changhee},
title = {TxRace: Efficient Data Race Detection Using Commodity Hardware Transactional Memory},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872384},
doi = {10.1145/2872362.2872384},
abstract = {Detecting data races is important for debugging shared-memory multithreaded programs, but the high runtime overhead prevents the wide use of dynamic data race detectors. This paper presents TxRace, a new software data race detector that leverages commodity hardware transactional memory (HTM) to speed up data race detection. TxRace instruments a multithreaded program to transform synchronization-free regions into transactions, and exploits the conflict detection mechanism of HTM for lightweight data race detection at runtime. However, the limitations of the current best-effort commodity HTMs expose several challenges in using them for data race detection: (1) lack of ability to pinpoint racy instructions, (2) false positives caused by cache line granularity of conflict detection, and (3) transactional aborts for non-conflict reasons (e.g., capacity or unknown). To overcome these challenges, TxRace performs lightweight HTM-based data race detection at first, and occasionally switches to slow yet precise data race detection only for the small fraction of execution intervals in which potential races are reported by HTM. According to the experimental results, TxRace reduces the average runtime overhead of dynamic data race detection from 11.68x to 4.65x with only a small number of false negatives.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {159–173},
numpages = {15},
keywords = {hardware transactional memory, dynamic program analysis, data race, concurrency bug detection},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872404,
author = {Amani, Sidney and Hixon, Alex and Chen, Zilin and Rizkallah, Christine and Chubb, Peter and O'Connor, Liam and Beeren, Joel and Nagashima, Yutaka and Lim, Japheth and Sewell, Thomas and Tuong, Joseph and Keller, Gabriele and Murray, Toby and Klein, Gerwin and Heiser, Gernot},
title = {Cogent: Verifying High-Assurance File System Implementations},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872404},
doi = {10.1145/2980024.2872404},
abstract = {We present an approach to writing and formally verifying high-assurance file-system code in a restricted language called Cogent, supported by a certifying compiler that produces C code, high-level specification of Cogent, and translation correctness proofs. The language is strongly typed and guarantees absence of a number of common file system implementation errors. We show how verification effort is drastically reduced for proving higher-level properties of the file system implementation by reasoning about the generated formal specification rather than its low-level C code. We use the framework to write two Linux file systems, and compare their performance with their native C implementations.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {175–188},
numpages = {14},
keywords = {verification, isabelle/hol, file systems, domain-specific languages, co-generation}
}

@article{10.1145/2954679.2872404,
author = {Amani, Sidney and Hixon, Alex and Chen, Zilin and Rizkallah, Christine and Chubb, Peter and O'Connor, Liam and Beeren, Joel and Nagashima, Yutaka and Lim, Japheth and Sewell, Thomas and Tuong, Joseph and Keller, Gabriele and Murray, Toby and Klein, Gerwin and Heiser, Gernot},
title = {Cogent: Verifying High-Assurance File System Implementations},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872404},
doi = {10.1145/2954679.2872404},
abstract = {We present an approach to writing and formally verifying high-assurance file-system code in a restricted language called Cogent, supported by a certifying compiler that produces C code, high-level specification of Cogent, and translation correctness proofs. The language is strongly typed and guarantees absence of a number of common file system implementation errors. We show how verification effort is drastically reduced for proving higher-level properties of the file system implementation by reasoning about the generated formal specification rather than its low-level C code. We use the framework to write two Linux file systems, and compare their performance with their native C implementations.},
journal = {SIGPLAN Not.},
month = mar,
pages = {175–188},
numpages = {14},
keywords = {co-generation, domain-specific languages, file systems, isabelle/hol, verification}
}

@inproceedings{10.1145/2872362.2872404,
author = {Amani, Sidney and Hixon, Alex and Chen, Zilin and Rizkallah, Christine and Chubb, Peter and O'Connor, Liam and Beeren, Joel and Nagashima, Yutaka and Lim, Japheth and Sewell, Thomas and Tuong, Joseph and Keller, Gabriele and Murray, Toby and Klein, Gerwin and Heiser, Gernot},
title = {Cogent: Verifying High-Assurance File System Implementations},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872404},
doi = {10.1145/2872362.2872404},
abstract = {We present an approach to writing and formally verifying high-assurance file-system code in a restricted language called Cogent, supported by a certifying compiler that produces C code, high-level specification of Cogent, and translation correctness proofs. The language is strongly typed and guarantees absence of a number of common file system implementation errors. We show how verification effort is drastically reduced for proving higher-level properties of the file system implementation by reasoning about the generated formal specification rather than its low-level C code. We use the framework to write two Linux file systems, and compare their performance with their native C implementations.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {175–188},
numpages = {14},
keywords = {co-generation, domain-specific languages, file systems, isabelle/hol, verification},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252395,
author = {Cascaval, Calin},
title = {Session details: Session 3A: Heterogeneous Architectures and Accelerators I},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252395},
doi = {10.1145/3252395},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872371,
author = {Asmussen, Nils and V\"{o}lp, Marcus and N\"{o}then, Benedikt and H\"{a}rtig, Hermann and Fettweis, Gerhard},
title = {M3: A Hardware/Operating-System Co-Design to Tame Heterogeneous Manycores},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872371},
doi = {10.1145/2954679.2872371},
abstract = {In the last decade, the number of available cores increased and heterogeneity grew. In this work, we ask the question whether the design of the current operating systems (OSes) is still appropriate if these trends continue and lead to abundantly available but heterogeneous cores, or whether it forces a fundamental rethinking of how systems are designed. We argue that: 1. hiding heterogeneity behind a common hardware interface unifies, to a large extent, the control and coordination of cores and accelerators in the OS, 2. isolating at the network-on-chip rather than with processor features (like privileged mode, memory management unit, ...), allows running untrusted code on arbitrary cores, and 3. providing OS services via protocols over the network-on-chip, instead of via system calls, makes them accessible to arbitrary types of cores as well.In summary, this turns accelerators into first-class citizens and enables a single and convenient programming environment for all cores without the need to trust any application.In this paper, we introduce network-on-chip-level isolation, present the design of our microkernel-based OS, M3, and the common hardware interface, and evaluate the performance of our prototype in comparison to Linux. A bit surprising, without using accelerators, M3 outperforms Linux in some application-level benchmarks by more than a factor of five.},
journal = {SIGPLAN Not.},
month = mar,
pages = {189–203},
numpages = {15},
keywords = {operating systems, on-chip networks, heterogeneous architectures, capabilities, accelerators}
}

@article{10.1145/2980024.2872371,
author = {Asmussen, Nils and V\"{o}lp, Marcus and N\"{o}then, Benedikt and H\"{a}rtig, Hermann and Fettweis, Gerhard},
title = {M3: A Hardware/Operating-System Co-Design to Tame Heterogeneous Manycores},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872371},
doi = {10.1145/2980024.2872371},
abstract = {In the last decade, the number of available cores increased and heterogeneity grew. In this work, we ask the question whether the design of the current operating systems (OSes) is still appropriate if these trends continue and lead to abundantly available but heterogeneous cores, or whether it forces a fundamental rethinking of how systems are designed. We argue that: 1. hiding heterogeneity behind a common hardware interface unifies, to a large extent, the control and coordination of cores and accelerators in the OS, 2. isolating at the network-on-chip rather than with processor features (like privileged mode, memory management unit, ...), allows running untrusted code on arbitrary cores, and 3. providing OS services via protocols over the network-on-chip, instead of via system calls, makes them accessible to arbitrary types of cores as well.In summary, this turns accelerators into first-class citizens and enables a single and convenient programming environment for all cores without the need to trust any application.In this paper, we introduce network-on-chip-level isolation, present the design of our microkernel-based OS, M3, and the common hardware interface, and evaluate the performance of our prototype in comparison to Linux. A bit surprising, without using accelerators, M3 outperforms Linux in some application-level benchmarks by more than a factor of five.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {189–203},
numpages = {15},
keywords = {operating systems, on-chip networks, heterogeneous architectures, capabilities, accelerators}
}

@inproceedings{10.1145/2872362.2872371,
author = {Asmussen, Nils and V\"{o}lp, Marcus and N\"{o}then, Benedikt and H\"{a}rtig, Hermann and Fettweis, Gerhard},
title = {M3: A Hardware/Operating-System Co-Design to Tame Heterogeneous Manycores},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872371},
doi = {10.1145/2872362.2872371},
abstract = {In the last decade, the number of available cores increased and heterogeneity grew. In this work, we ask the question whether the design of the current operating systems (OSes) is still appropriate if these trends continue and lead to abundantly available but heterogeneous cores, or whether it forces a fundamental rethinking of how systems are designed. We argue that: 1. hiding heterogeneity behind a common hardware interface unifies, to a large extent, the control and coordination of cores and accelerators in the OS, 2. isolating at the network-on-chip rather than with processor features (like privileged mode, memory management unit, ...), allows running untrusted code on arbitrary cores, and 3. providing OS services via protocols over the network-on-chip, instead of via system calls, makes them accessible to arbitrary types of cores as well.In summary, this turns accelerators into first-class citizens and enables a single and convenient programming environment for all cores without the need to trust any application.In this paper, we introduce network-on-chip-level isolation, present the design of our microkernel-based OS, M3, and the common hardware interface, and evaluate the performance of our prototype in comparison to Linux. A bit surprising, without using accelerators, M3 outperforms Linux in some application-level benchmarks by more than a factor of five.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {189–203},
numpages = {15},
keywords = {operating systems, on-chip networks, heterogeneous architectures, capabilities, accelerators},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872398,
author = {Liaqat, Daniyal and Jingoi, Silviu and de Lara, Eyal and Goel, Ashvin and To, Wilson and Lee, Kevin and De Moraes Garcia, Italo and Saldana, Manuel},
title = {Sidewinder: An Energy Efficient and Developer Friendly Heterogeneous Architecture for Continuous Mobile Sensing},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872398},
doi = {10.1145/2980024.2872398},
abstract = {Applications that perform continuous sensing on mobile phones have the potential to revolutionize everyday life. Examples range from medical and health monitoring applications, such as pedometers and fall detectors, to participatory sensing applications, such as noise pollution, traffic and seismic activity monitoring. Unfortunately, current mobile devices are a poor match for continuous sensing applications as they require the device to remain awake for extended periods of time, resulting in poor battery life. This paper presents Sidewinder, a new approach towards offloading sensor data processing to a low-power processor and waking up the main processor when events of interest occur. This approach differs from other heterogeneous architectures in that developers are presented with a programming interface that lets them construct application specific wake-up conditions by linking together and parameterizing predefined sensor data processing algorithms. Our experiments indicate performance that is comparable to approaches that provide fully programmable offloading, but do so with a much simpler programming interface that facilitates deployment and portability.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {205–215},
numpages = {11},
keywords = {mobile computing, heterogeneous architecture, energy efficiency, continuous sensing}
}

@article{10.1145/2954679.2872398,
author = {Liaqat, Daniyal and Jingoi, Silviu and de Lara, Eyal and Goel, Ashvin and To, Wilson and Lee, Kevin and De Moraes Garcia, Italo and Saldana, Manuel},
title = {Sidewinder: An Energy Efficient and Developer Friendly Heterogeneous Architecture for Continuous Mobile Sensing},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872398},
doi = {10.1145/2954679.2872398},
abstract = {Applications that perform continuous sensing on mobile phones have the potential to revolutionize everyday life. Examples range from medical and health monitoring applications, such as pedometers and fall detectors, to participatory sensing applications, such as noise pollution, traffic and seismic activity monitoring. Unfortunately, current mobile devices are a poor match for continuous sensing applications as they require the device to remain awake for extended periods of time, resulting in poor battery life. This paper presents Sidewinder, a new approach towards offloading sensor data processing to a low-power processor and waking up the main processor when events of interest occur. This approach differs from other heterogeneous architectures in that developers are presented with a programming interface that lets them construct application specific wake-up conditions by linking together and parameterizing predefined sensor data processing algorithms. Our experiments indicate performance that is comparable to approaches that provide fully programmable offloading, but do so with a much simpler programming interface that facilitates deployment and portability.},
journal = {SIGPLAN Not.},
month = mar,
pages = {205–215},
numpages = {11},
keywords = {mobile computing, heterogeneous architecture, energy efficiency, continuous sensing}
}

@inproceedings{10.1145/2872362.2872398,
author = {Liaqat, Daniyal and Jingoi, Silviu and de Lara, Eyal and Goel, Ashvin and To, Wilson and Lee, Kevin and De Moraes Garcia, Italo and Saldana, Manuel},
title = {Sidewinder: An Energy Efficient and Developer Friendly Heterogeneous Architecture for Continuous Mobile Sensing},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872398},
doi = {10.1145/2872362.2872398},
abstract = {Applications that perform continuous sensing on mobile phones have the potential to revolutionize everyday life. Examples range from medical and health monitoring applications, such as pedometers and fall detectors, to participatory sensing applications, such as noise pollution, traffic and seismic activity monitoring. Unfortunately, current mobile devices are a poor match for continuous sensing applications as they require the device to remain awake for extended periods of time, resulting in poor battery life. This paper presents Sidewinder, a new approach towards offloading sensor data processing to a low-power processor and waking up the main processor when events of interest occur. This approach differs from other heterogeneous architectures in that developers are presented with a programming interface that lets them construct application specific wake-up conditions by linking together and parameterizing predefined sensor data processing algorithms. Our experiments indicate performance that is comparable to approaches that provide fully programmable offloading, but do so with a much simpler programming interface that facilitates deployment and portability.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {205–215},
numpages = {11},
keywords = {continuous sensing, energy efficiency, heterogeneous architecture, mobile computing},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872414,
author = {Balkind, Jonathan and McKeown, Michael and Fu, Yaosheng and Nguyen, Tri and Zhou, Yanqi and Lavrov, Alexey and Shahrad, Mohammad and Fuchs, Adi and Payne, Samuel and Liang, Xiaohua and Matl, Matthew and Wentzlaff, David},
title = {OpenPiton: An Open Source Manycore Research Framework},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872414},
doi = {10.1145/2954679.2872414},
abstract = {Industry is building larger, more complex, manycore processors on the back of strong institutional knowledge, but academic projects face difficulties in replicating that scale. To alleviate these difficulties and to develop and share knowledge, the community needs open architecture frameworks for simulation, synthesis, and software exploration which support extensibility, scalability, and configurability, alongside an established base of verification tools and supported software. In this paper we present OpenPiton, an open source framework for building scalable architecture research prototypes from 1 core to 500 million cores. OpenPiton is the world's first open source, general-purpose, multithreaded manycore processor and framework. OpenPiton leverages the industry hardened OpenSPARC T1 core with modifications and builds upon it with a scratch-built, scalable uncore creating a flexible, modern manycore design. In addition, OpenPiton provides synthesis and backend scripts for ASIC and FPGA to enable other researchers to bring their designs to implementation. OpenPiton provides a complete verification infrastructure of over 8000 tests, is supported by mature software tools, runs full-stack multiuser Debian Linux, and is written in industry standard Verilog. Multiple implementations of OpenPiton have been created including a taped-out 25-core implementation in IBM's 32nm process and multiple Xilinx FPGA prototypes.},
journal = {SIGPLAN Not.},
month = mar,
pages = {217–232},
numpages = {16},
keywords = {manycore, multicore, open-source}
}

@article{10.1145/2980024.2872414,
author = {Balkind, Jonathan and McKeown, Michael and Fu, Yaosheng and Nguyen, Tri and Zhou, Yanqi and Lavrov, Alexey and Shahrad, Mohammad and Fuchs, Adi and Payne, Samuel and Liang, Xiaohua and Matl, Matthew and Wentzlaff, David},
title = {OpenPiton: An Open Source Manycore Research Framework},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872414},
doi = {10.1145/2980024.2872414},
abstract = {Industry is building larger, more complex, manycore processors on the back of strong institutional knowledge, but academic projects face difficulties in replicating that scale. To alleviate these difficulties and to develop and share knowledge, the community needs open architecture frameworks for simulation, synthesis, and software exploration which support extensibility, scalability, and configurability, alongside an established base of verification tools and supported software. In this paper we present OpenPiton, an open source framework for building scalable architecture research prototypes from 1 core to 500 million cores. OpenPiton is the world's first open source, general-purpose, multithreaded manycore processor and framework. OpenPiton leverages the industry hardened OpenSPARC T1 core with modifications and builds upon it with a scratch-built, scalable uncore creating a flexible, modern manycore design. In addition, OpenPiton provides synthesis and backend scripts for ASIC and FPGA to enable other researchers to bring their designs to implementation. OpenPiton provides a complete verification infrastructure of over 8000 tests, is supported by mature software tools, runs full-stack multiuser Debian Linux, and is written in industry standard Verilog. Multiple implementations of OpenPiton have been created including a taped-out 25-core implementation in IBM's 32nm process and multiple Xilinx FPGA prototypes.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {217–232},
numpages = {16},
keywords = {manycore, multicore, open-source}
}

@inproceedings{10.1145/2872362.2872414,
author = {Balkind, Jonathan and McKeown, Michael and Fu, Yaosheng and Nguyen, Tri and Zhou, Yanqi and Lavrov, Alexey and Shahrad, Mohammad and Fuchs, Adi and Payne, Samuel and Liang, Xiaohua and Matl, Matthew and Wentzlaff, David},
title = {OpenPiton: An Open Source Manycore Research Framework},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872414},
doi = {10.1145/2872362.2872414},
abstract = {Industry is building larger, more complex, manycore processors on the back of strong institutional knowledge, but academic projects face difficulties in replicating that scale. To alleviate these difficulties and to develop and share knowledge, the community needs open architecture frameworks for simulation, synthesis, and software exploration which support extensibility, scalability, and configurability, alongside an established base of verification tools and supported software. In this paper we present OpenPiton, an open source framework for building scalable architecture research prototypes from 1 core to 500 million cores. OpenPiton is the world's first open source, general-purpose, multithreaded manycore processor and framework. OpenPiton leverages the industry hardened OpenSPARC T1 core with modifications and builds upon it with a scratch-built, scalable uncore creating a flexible, modern manycore design. In addition, OpenPiton provides synthesis and backend scripts for ASIC and FPGA to enable other researchers to bring their designs to implementation. OpenPiton provides a complete verification infrastructure of over 8000 tests, is supported by mature software tools, runs full-stack multiuser Debian Linux, and is written in industry standard Verilog. Multiple implementations of OpenPiton have been created including a taped-out 25-core implementation in IBM's 32nm process and multiple Xilinx FPGA prototypes.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {217–232},
numpages = {16},
keywords = {manycore, multicore, open-source},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872399,
author = {Lustig, Daniel and Sethi, Geet and Martonosi, Margaret and Bhattacharjee, Abhishek},
title = {COATCheck: Verifying Memory Ordering at the Hardware-OS Interface},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872399},
doi = {10.1145/2954679.2872399},
abstract = {Modern computer systems include numerous compute elements, from CPUs to GPUs to accelerators. Harnessing their full potential requires well-defined, properly-implemented memory consistency models (MCMs), and low-level system functionality such as virtual memory and address translation (AT). Unfortunately, it is difficult to specify and implement hardware-OS interactions correctly; in the past, many hardware and OS specification mismatches have resulted in implementation bugs in commercial processors. In an effort to resolve this verification gap, this paper makes the following contributions. First, we present COATCheck, an address translation-aware framework for specifying and statically verifying memory ordering enforcement at the microarchitecture and operating system levels. We develop a domain-specific language for specifying ordering enforcement, for including ordering-related OS events and hardware micro-operations, and for programmatically enumerating happens-before graphs. Using a fast and automated static constraint solver, COATCheck can efficiently analyze interesting and important memory ordering scenarios for modern, high-performance, out-of-order processors. Second, we show that previous work on Virtual Address Memory Consistency (VAMC) does not capture every translation-related ordering scenario of interest, and that some such cases even fall outside the traditional scope of consistency. We therefore introduce the term transistency model to describe the superset of consistency which captures all translation-aware sets of ordering rules.},
journal = {SIGPLAN Not.},
month = mar,
pages = {233–247},
numpages = {15},
keywords = {address translation, computer architecture, memory consistency models, verification, virtual memory}
}

@article{10.1145/2980024.2872399,
author = {Lustig, Daniel and Sethi, Geet and Martonosi, Margaret and Bhattacharjee, Abhishek},
title = {COATCheck: Verifying Memory Ordering at the Hardware-OS Interface},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872399},
doi = {10.1145/2980024.2872399},
abstract = {Modern computer systems include numerous compute elements, from CPUs to GPUs to accelerators. Harnessing their full potential requires well-defined, properly-implemented memory consistency models (MCMs), and low-level system functionality such as virtual memory and address translation (AT). Unfortunately, it is difficult to specify and implement hardware-OS interactions correctly; in the past, many hardware and OS specification mismatches have resulted in implementation bugs in commercial processors. In an effort to resolve this verification gap, this paper makes the following contributions. First, we present COATCheck, an address translation-aware framework for specifying and statically verifying memory ordering enforcement at the microarchitecture and operating system levels. We develop a domain-specific language for specifying ordering enforcement, for including ordering-related OS events and hardware micro-operations, and for programmatically enumerating happens-before graphs. Using a fast and automated static constraint solver, COATCheck can efficiently analyze interesting and important memory ordering scenarios for modern, high-performance, out-of-order processors. Second, we show that previous work on Virtual Address Memory Consistency (VAMC) does not capture every translation-related ordering scenario of interest, and that some such cases even fall outside the traditional scope of consistency. We therefore introduce the term transistency model to describe the superset of consistency which captures all translation-aware sets of ordering rules.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {233–247},
numpages = {15},
keywords = {address translation, computer architecture, memory consistency models, verification, virtual memory}
}

@inproceedings{10.1145/2872362.2872399,
author = {Lustig, Daniel and Sethi, Geet and Martonosi, Margaret and Bhattacharjee, Abhishek},
title = {COATCheck: Verifying Memory Ordering at the Hardware-OS Interface},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872399},
doi = {10.1145/2872362.2872399},
abstract = {Modern computer systems include numerous compute elements, from CPUs to GPUs to accelerators. Harnessing their full potential requires well-defined, properly-implemented memory consistency models (MCMs), and low-level system functionality such as virtual memory and address translation (AT). Unfortunately, it is difficult to specify and implement hardware-OS interactions correctly; in the past, many hardware and OS specification mismatches have resulted in implementation bugs in commercial processors. In an effort to resolve this verification gap, this paper makes the following contributions. First, we present COATCheck, an address translation-aware framework for specifying and statically verifying memory ordering enforcement at the microarchitecture and operating system levels. We develop a domain-specific language for specifying ordering enforcement, for including ordering-related OS events and hardware micro-operations, and for programmatically enumerating happens-before graphs. Using a fast and automated static constraint solver, COATCheck can efficiently analyze interesting and important memory ordering scenarios for modern, high-performance, out-of-order processors. Second, we show that previous work on Virtual Address Memory Consistency (VAMC) does not capture every translation-related ordering scenario of interest, and that some such cases even fall outside the traditional scope of consistency. We therefore introduce the term transistency model to describe the superset of consistency which captures all translation-aware sets of ordering rules.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {233–247},
numpages = {15},
keywords = {address translation, computer architecture, memory consistency models, verification, virtual memory},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252396,
author = {Heiser, Gernot},
title = {Session details: Session 3B: Security I},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252396},
doi = {10.1145/3252396},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872379,
author = {Markuze, Alex and Morrison, Adam and Tsafrir, Dan},
title = {True IOMMU Protection from DMA Attacks: When Copy is Faster than Zero Copy},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872379},
doi = {10.1145/2954679.2872379},
abstract = {Malicious I/O devices might compromise the OS using DMAs. The OS therefore utilizes the IOMMU to map and unmap every target buffer right before and after its DMA is processed, thereby restricting DMAs to their designated locations. This usage model, however, is not truly secure for two reasons: (1) it provides protection at page granularity only, whereas DMA buffers can reside on the same page as other data; and (2) it delays DMA buffer unmaps due to performance considerations, creating a vulnerability window in which devices can access in-use memory. We propose that OSes utilize the IOMMU differently, in a manner that eliminates these two flaws. Our new usage model restricts device access to a set of shadow DMA buffers that are never unmapped, and it copies DMAed data to/from these buffers, thus providing sub-page protection while eliminating the aforementioned vulnerability window. Our key insight is that the cost of interacting with, and synchronizing access to the slow IOMMU hardware---required for zero-copy protection against devices---make copying preferable to zero-copying.We implement our model in Linux and evaluate it with standard networking benchmarks utilizing a 40,Gb/s NIC. We demonstrate that despite being more secure than the safest preexisting usage model, our approach provides up to 5x higher throughput. Additionally, whereas it is inherently less scalable than an IOMMU-less (unprotected) system, our approach incurs only 0\%--25\% performance degradation in comparison.},
journal = {SIGPLAN Not.},
month = mar,
pages = {249–262},
numpages = {14},
keywords = {IOMMU, dma attacks}
}

@article{10.1145/2980024.2872379,
author = {Markuze, Alex and Morrison, Adam and Tsafrir, Dan},
title = {True IOMMU Protection from DMA Attacks: When Copy is Faster than Zero Copy},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872379},
doi = {10.1145/2980024.2872379},
abstract = {Malicious I/O devices might compromise the OS using DMAs. The OS therefore utilizes the IOMMU to map and unmap every target buffer right before and after its DMA is processed, thereby restricting DMAs to their designated locations. This usage model, however, is not truly secure for two reasons: (1) it provides protection at page granularity only, whereas DMA buffers can reside on the same page as other data; and (2) it delays DMA buffer unmaps due to performance considerations, creating a vulnerability window in which devices can access in-use memory. We propose that OSes utilize the IOMMU differently, in a manner that eliminates these two flaws. Our new usage model restricts device access to a set of shadow DMA buffers that are never unmapped, and it copies DMAed data to/from these buffers, thus providing sub-page protection while eliminating the aforementioned vulnerability window. Our key insight is that the cost of interacting with, and synchronizing access to the slow IOMMU hardware---required for zero-copy protection against devices---make copying preferable to zero-copying.We implement our model in Linux and evaluate it with standard networking benchmarks utilizing a 40,Gb/s NIC. We demonstrate that despite being more secure than the safest preexisting usage model, our approach provides up to 5x higher throughput. Additionally, whereas it is inherently less scalable than an IOMMU-less (unprotected) system, our approach incurs only 0\%--25\% performance degradation in comparison.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {249–262},
numpages = {14},
keywords = {dma attacks, IOMMU}
}

@inproceedings{10.1145/2872362.2872379,
author = {Markuze, Alex and Morrison, Adam and Tsafrir, Dan},
title = {True IOMMU Protection from DMA Attacks: When Copy is Faster than Zero Copy},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872379},
doi = {10.1145/2872362.2872379},
abstract = {Malicious I/O devices might compromise the OS using DMAs. The OS therefore utilizes the IOMMU to map and unmap every target buffer right before and after its DMA is processed, thereby restricting DMAs to their designated locations. This usage model, however, is not truly secure for two reasons: (1) it provides protection at page granularity only, whereas DMA buffers can reside on the same page as other data; and (2) it delays DMA buffer unmaps due to performance considerations, creating a vulnerability window in which devices can access in-use memory. We propose that OSes utilize the IOMMU differently, in a manner that eliminates these two flaws. Our new usage model restricts device access to a set of shadow DMA buffers that are never unmapped, and it copies DMAed data to/from these buffers, thus providing sub-page protection while eliminating the aforementioned vulnerability window. Our key insight is that the cost of interacting with, and synchronizing access to the slow IOMMU hardware---required for zero-copy protection against devices---make copying preferable to zero-copying.We implement our model in Linux and evaluate it with standard networking benchmarks utilizing a 40,Gb/s NIC. We demonstrate that despite being more secure than the safest preexisting usage model, our approach provides up to 5x higher throughput. Additionally, whereas it is inherently less scalable than an IOMMU-less (unprotected) system, our approach incurs only 0\%--25\% performance degradation in comparison.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {249–262},
numpages = {14},
keywords = {IOMMU, dma attacks},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872377,
author = {Awad, Amro and Manadhata, Pratyusa and Haber, Stuart and Solihin, Yan and Horne, William},
title = {Silent Shredder: Zero-Cost Shredding for Secure Non-Volatile Main Memory Controllers},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872377},
doi = {10.1145/2954679.2872377},
abstract = {As non-volatile memory (NVM) technologies are expected to replace DRAM in the near future, new challenges have emerged. For example, NVMs have slow and power-consuming writes, and limited write endurance. In addition, NVMs have a data remanence vulnerability, i.e., they retain data for a long time after being powered off. NVM encryption alleviates the vulnerability, but exacerbates the limited endurance by increasing the number of writes to memory. We observe that, in current systems, a large percentage of main memory writes result from data shredding in operating systems, a process of zeroing out physical pages before mapping them to new processes, in order to protect previous processes' data. In this paper, we propose Silent Shredder, which repurposes initialization vectors used in standard counter mode encryption to completely eliminate the data shredding writes. Silent Shredder also speeds up reading shredded cache lines, and hence reduces power consumption and improves overall performance. To evaluate our design, we run three PowerGraph applications and 26 multi-programmed workloads from the SPEC 2006 suite, on a gem5-based full system simulator. Silent Shredder eliminates an average of 48.6\% of the writes in the initialization and graph construction phases. It speeds up main memory reads by 3.3 times, and improves the number of instructions per cycle (IPC) by 6.4\% on average. Finally, we discuss several use cases, including virtual machines' data isolation and user-level large data initialization, where Silent Shredder can be used effectively at no extra cost.},
journal = {SIGPLAN Not.},
month = mar,
pages = {263–276},
numpages = {14},
keywords = {phase-change memory, keywords encryption, hardware security, data protection}
}

@article{10.1145/2980024.2872377,
author = {Awad, Amro and Manadhata, Pratyusa and Haber, Stuart and Solihin, Yan and Horne, William},
title = {Silent Shredder: Zero-Cost Shredding for Secure Non-Volatile Main Memory Controllers},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872377},
doi = {10.1145/2980024.2872377},
abstract = {As non-volatile memory (NVM) technologies are expected to replace DRAM in the near future, new challenges have emerged. For example, NVMs have slow and power-consuming writes, and limited write endurance. In addition, NVMs have a data remanence vulnerability, i.e., they retain data for a long time after being powered off. NVM encryption alleviates the vulnerability, but exacerbates the limited endurance by increasing the number of writes to memory. We observe that, in current systems, a large percentage of main memory writes result from data shredding in operating systems, a process of zeroing out physical pages before mapping them to new processes, in order to protect previous processes' data. In this paper, we propose Silent Shredder, which repurposes initialization vectors used in standard counter mode encryption to completely eliminate the data shredding writes. Silent Shredder also speeds up reading shredded cache lines, and hence reduces power consumption and improves overall performance. To evaluate our design, we run three PowerGraph applications and 26 multi-programmed workloads from the SPEC 2006 suite, on a gem5-based full system simulator. Silent Shredder eliminates an average of 48.6\% of the writes in the initialization and graph construction phases. It speeds up main memory reads by 3.3 times, and improves the number of instructions per cycle (IPC) by 6.4\% on average. Finally, we discuss several use cases, including virtual machines' data isolation and user-level large data initialization, where Silent Shredder can be used effectively at no extra cost.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {263–276},
numpages = {14},
keywords = {phase-change memory, keywords encryption, hardware security, data protection}
}

@inproceedings{10.1145/2872362.2872377,
author = {Awad, Amro and Manadhata, Pratyusa and Haber, Stuart and Solihin, Yan and Horne, William},
title = {Silent Shredder: Zero-Cost Shredding for Secure Non-Volatile Main Memory Controllers},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872377},
doi = {10.1145/2872362.2872377},
abstract = {As non-volatile memory (NVM) technologies are expected to replace DRAM in the near future, new challenges have emerged. For example, NVMs have slow and power-consuming writes, and limited write endurance. In addition, NVMs have a data remanence vulnerability, i.e., they retain data for a long time after being powered off. NVM encryption alleviates the vulnerability, but exacerbates the limited endurance by increasing the number of writes to memory. We observe that, in current systems, a large percentage of main memory writes result from data shredding in operating systems, a process of zeroing out physical pages before mapping them to new processes, in order to protect previous processes' data. In this paper, we propose Silent Shredder, which repurposes initialization vectors used in standard counter mode encryption to completely eliminate the data shredding writes. Silent Shredder also speeds up reading shredded cache lines, and hence reduces power consumption and improves overall performance. To evaluate our design, we run three PowerGraph applications and 26 multi-programmed workloads from the SPEC 2006 suite, on a gem5-based full system simulator. Silent Shredder eliminates an average of 48.6\% of the writes in the initialization and graph construction phases. It speeds up main memory reads by 3.3 times, and improves the number of instructions per cycle (IPC) by 6.4\% on average. Finally, we discuss several use cases, including virtual machines' data isolation and user-level large data initialization, where Silent Shredder can be used effectively at no extra cost.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {263–276},
numpages = {14},
keywords = {data protection, hardware security, keywords encryption, phase-change memory},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872372,
author = {Kwon, Youngjin and Dunn, Alan M. and Lee, Michael Z. and Hofmann, Owen S. and Xu, Yuanzhong and Witchel, Emmett},
title = {Sego: Pervasive Trusted Metadata for Efficiently Verified Untrusted System Services},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872372},
doi = {10.1145/2980024.2872372},
abstract = {Sego is a hypervisor-based system that gives strong privacy and integrity guarantees to trusted applications, even when the guest operating system is compromised or hostile. Sego verifies operating system services, like the file system, instead of replacing them. By associating trusted metadata with user data across all system devices, Sego verifies system services more efficiently than previous systems, especially services that depend on data contents. We extensively evaluate Sego's performance on real workloads and implement a kernel fault injector to validate Sego's file system-agnostic crash consistency and recovery protocol.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {277–290},
numpages = {14},
keywords = {application protection, crash consistency, para-verification, virtualization-based security}
}

@article{10.1145/2954679.2872372,
author = {Kwon, Youngjin and Dunn, Alan M. and Lee, Michael Z. and Hofmann, Owen S. and Xu, Yuanzhong and Witchel, Emmett},
title = {Sego: Pervasive Trusted Metadata for Efficiently Verified Untrusted System Services},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872372},
doi = {10.1145/2954679.2872372},
abstract = {Sego is a hypervisor-based system that gives strong privacy and integrity guarantees to trusted applications, even when the guest operating system is compromised or hostile. Sego verifies operating system services, like the file system, instead of replacing them. By associating trusted metadata with user data across all system devices, Sego verifies system services more efficiently than previous systems, especially services that depend on data contents. We extensively evaluate Sego's performance on real workloads and implement a kernel fault injector to validate Sego's file system-agnostic crash consistency and recovery protocol.},
journal = {SIGPLAN Not.},
month = mar,
pages = {277–290},
numpages = {14},
keywords = {application protection, crash consistency, para-verification, virtualization-based security}
}

@inproceedings{10.1145/2872362.2872372,
author = {Kwon, Youngjin and Dunn, Alan M. and Lee, Michael Z. and Hofmann, Owen S. and Xu, Yuanzhong and Witchel, Emmett},
title = {Sego: Pervasive Trusted Metadata for Efficiently Verified Untrusted System Services},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872372},
doi = {10.1145/2872362.2872372},
abstract = {Sego is a hypervisor-based system that gives strong privacy and integrity guarantees to trusted applications, even when the guest operating system is compromised or hostile. Sego verifies operating system services, like the file system, instead of replacing them. By associating trusted metadata with user data across all system devices, Sego verifies system services more efficiently than previous systems, especially services that depend on data contents. We extensively evaluate Sego's performance on real workloads and implement a kernel fault injector to validate Sego's file system-agnostic crash consistency and recovery protocol.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {277–290},
numpages = {14},
keywords = {application protection, crash consistency, para-verification, virtualization-based security},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252397,
author = {Tsafrir, Dan},
title = {Session details: Wild and Crazy Ideas},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252397},
doi = {10.1145/3252397},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2876512,
author = {Tsafrir, Dan},
title = {Synopsis of the ASPLOS '16 Wild and Crazy Ideas (WACI) Invited-Speakers Session},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2876512},
doi = {10.1145/2980024.2876512},
abstract = {The Wild and Crazy Ideas (WACI) session is a longstanding tradition at ASPLOS, soliciting talks that consist of forward-looking, visionary, inspiring, creative, far out or just plain amazing ideas presented in an exciting way. (Amusing elements in the presentations are tolerated ;-) but are in fact optional.)The first WACI session took place in 1998. Back then, the call for talks included a problem statement, which contended that "papers usually do not get admitted to [such conferences as] ISCA or ASPLOS unless the systems that they describe are mature enough to run [some standard benchmark suites, which] has a chilling effect on the idea generation process---encouraging incremental research" [1]. The 1998 WACI session turned out to be a great success. Its webpage states that "there were 42 submissions [competing over] only eight time slots, [which resulted in] this session [having] a lower acceptance rate than the conference itself" [2].But the times they are a-changin' [3], and the WACI session no longer enjoys that many submissions (Figure 1), perhaps because nowadays there exist many forums for researchers to describe/discuss their preliminary ideas, including: the ``hot topics in'' workshops [4--7]; a journal like CAL, dedicated to early results [8]; main conferences soliciting short submissions describing ``original or unconventional ideas at a preliminary stage'' in addition to regular papers [9]; and the many workshops co-located with main conferences, like ISCA '15, which hosted thirteen such workshops [10].Regardless of the reason for the declining number of submissions, this time we've decided to organize the WACI session differently to ensure its continued high quality. Instead of soliciting talks via an open call and hoping for the best, we proactively invited speakers whom we believe are capable of delivering excellent WACI presentations. That is, this year's WACI session consists exclusively of invited speakers. Filling up the available slots turned out to be fairly easy, as most of the researchers we invited promptly accepted our invitation. The duration of each talk was set to be eight minutes (exactly as in the first WACI session from 1998) plus two minutes for questions.The talks are outlined below. We believe they are interesting and exciting, and we hope the attendees of the session will find them stimulating and insightful.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {291–294},
numpages = {4}
}

@article{10.1145/2954679.2876512,
author = {Tsafrir, Dan},
title = {Synopsis of the ASPLOS '16 Wild and Crazy Ideas (WACI) Invited-Speakers Session},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2876512},
doi = {10.1145/2954679.2876512},
abstract = {The Wild and Crazy Ideas (WACI) session is a longstanding tradition at ASPLOS, soliciting talks that consist of forward-looking, visionary, inspiring, creative, far out or just plain amazing ideas presented in an exciting way. (Amusing elements in the presentations are tolerated ;-) but are in fact optional.)The first WACI session took place in 1998. Back then, the call for talks included a problem statement, which contended that "papers usually do not get admitted to [such conferences as] ISCA or ASPLOS unless the systems that they describe are mature enough to run [some standard benchmark suites, which] has a chilling effect on the idea generation process---encouraging incremental research" [1]. The 1998 WACI session turned out to be a great success. Its webpage states that "there were 42 submissions [competing over] only eight time slots, [which resulted in] this session [having] a lower acceptance rate than the conference itself" [2].But the times they are a-changin' [3], and the WACI session no longer enjoys that many submissions (Figure 1), perhaps because nowadays there exist many forums for researchers to describe/discuss their preliminary ideas, including: the ``hot topics in'' workshops [4--7]; a journal like CAL, dedicated to early results [8]; main conferences soliciting short submissions describing ``original or unconventional ideas at a preliminary stage'' in addition to regular papers [9]; and the many workshops co-located with main conferences, like ISCA '15, which hosted thirteen such workshops [10].Regardless of the reason for the declining number of submissions, this time we've decided to organize the WACI session differently to ensure its continued high quality. Instead of soliciting talks via an open call and hoping for the best, we proactively invited speakers whom we believe are capable of delivering excellent WACI presentations. That is, this year's WACI session consists exclusively of invited speakers. Filling up the available slots turned out to be fairly easy, as most of the researchers we invited promptly accepted our invitation. The duration of each talk was set to be eight minutes (exactly as in the first WACI session from 1998) plus two minutes for questions.The talks are outlined below. We believe they are interesting and exciting, and we hope the attendees of the session will find them stimulating and insightful.},
journal = {SIGPLAN Not.},
month = mar,
pages = {291–294},
numpages = {4}
}

@inproceedings{10.1145/2872362.2876512,
author = {Tsafrir, Dan},
title = {Synopsis of the ASPLOS '16 Wild and Crazy Ideas (WACI) Invited-Speakers Session},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2876512},
doi = {10.1145/2872362.2876512},
abstract = {The Wild and Crazy Ideas (WACI) session is a longstanding tradition at ASPLOS, soliciting talks that consist of forward-looking, visionary, inspiring, creative, far out or just plain amazing ideas presented in an exciting way. (Amusing elements in the presentations are tolerated ;-) but are in fact optional.)The first WACI session took place in 1998. Back then, the call for talks included a problem statement, which contended that "papers usually do not get admitted to [such conferences as] ISCA or ASPLOS unless the systems that they describe are mature enough to run [some standard benchmark suites, which] has a chilling effect on the idea generation process---encouraging incremental research" [1]. The 1998 WACI session turned out to be a great success. Its webpage states that "there were 42 submissions [competing over] only eight time slots, [which resulted in] this session [having] a lower acceptance rate than the conference itself" [2].But the times they are a-changin' [3], and the WACI session no longer enjoys that many submissions (Figure 1), perhaps because nowadays there exist many forums for researchers to describe/discuss their preliminary ideas, including: the ``hot topics in'' workshops [4--7]; a journal like CAL, dedicated to early results [8]; main conferences soliciting short submissions describing ``original or unconventional ideas at a preliminary stage'' in addition to regular papers [9]; and the many workshops co-located with main conferences, like ISCA '15, which hosted thirteen such workshops [10].Regardless of the reason for the declining number of submissions, this time we've decided to organize the WACI session differently to ensure its continued high quality. Instead of soliciting talks via an open call and hoping for the best, we proactively invited speakers whom we believe are capable of delivering excellent WACI presentations. That is, this year's WACI session consists exclusively of invited speakers. Filling up the available slots turned out to be fairly easy, as most of the researchers we invited promptly accepted our invitation. The duration of each talk was set to be eight minutes (exactly as in the first WACI session from 1998) plus two minutes for questions.The talks are outlined below. We believe they are interesting and exciting, and we hope the attendees of the session will find them stimulating and insightful.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {291–294},
numpages = {4},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252398,
author = {Conte, Tom},
title = {Session details: Keynote Address II},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252398},
doi = {10.1145/3252398},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872417,
author = {Williams, R. Stanley},
title = {Brain Inspired Computing},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872417},
doi = {10.1145/2980024.2872417},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {295},
numpages = {1},
keywords = {cortical architecture, dark silicon, neuromorphic co-processors and accelerators, neuromorphic computing, non-volatile memory, system-on-chip}
}

@article{10.1145/2954679.2872417,
author = {Williams, R. Stanley},
title = {Brain Inspired Computing},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872417},
doi = {10.1145/2954679.2872417},
journal = {SIGPLAN Not.},
month = mar,
pages = {295},
numpages = {1},
keywords = {system-on-chip, non-volatile memory, neuromorphic computing, neuromorphic co-processors and accelerators, dark silicon, cortical architecture}
}

@inproceedings{10.1145/2872362.2872417,
author = {Williams, R. Stanley},
title = {Brain Inspired Computing},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872417},
doi = {10.1145/2872362.2872417},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {295},
numpages = {1},
keywords = {cortical architecture, dark silicon, neuromorphic co-processors and accelerators, neuromorphic computing, non-volatile memory, system-on-chip},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252399,
author = {Shen, Xipeng},
title = {Session details: Session 4A: Code Generation and Synthesis},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252399},
doi = {10.1145/3252399},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872387,
author = {Phothilimthana, Phitchaya Mangpo and Thakur, Aditya and Bodik, Rastislav and Dhurjati, Dinakar},
title = {Scaling up Superoptimization},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872387},
doi = {10.1145/2980024.2872387},
abstract = {Developing a code optimizer is challenging, especially for new, idiosyncratic ISAs. Superoptimization can, in principle, discover machine-specific optimizations automatically by searching the space of all instruction sequences. If we can increase the size of code fragments a superoptimizer can optimize, we will be able to discover more optimizations. We develop LENS, a search algorithm that increases the size of code a superoptimizer can synthesize by rapidly pruning away invalid candidate programs. Pruning is achieved by selectively refining the abstraction under which candidates are considered equivalent, only in the promising part of the candidate space. LENS also uses a bidirectional search strategy to prune the candidate space from both forward and backward directions. These pruning strategies allow LENS to solve twice as many benchmarks as existing enumerative search algorithms, while LENS is about 11-times faster.Additionally, we increase the effective size of the superoptimized fragments by relaxing the correctness condition using contexts (surrounding code). Finally, we combine LENS with complementary search techniques into a cooperative superoptimizer, which exploits the stochastic search to make random jumps in a large candidate space, and a symbolic (SAT-solver-based) search to synthesize arbitrary constants. While existing superoptimizers consistently solve 9--16 out of 32 benchmarks, the cooperative superoptimizer solves 29 benchmarks. It can synthesize code fragments that are up to 82\% faster than code generated by gcc -O3 from WiBench and MiBench.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {297–310},
numpages = {14},
keywords = {SMT, program synthesis, superoptimization}
}

@article{10.1145/2954679.2872387,
author = {Phothilimthana, Phitchaya Mangpo and Thakur, Aditya and Bodik, Rastislav and Dhurjati, Dinakar},
title = {Scaling up Superoptimization},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872387},
doi = {10.1145/2954679.2872387},
abstract = {Developing a code optimizer is challenging, especially for new, idiosyncratic ISAs. Superoptimization can, in principle, discover machine-specific optimizations automatically by searching the space of all instruction sequences. If we can increase the size of code fragments a superoptimizer can optimize, we will be able to discover more optimizations. We develop LENS, a search algorithm that increases the size of code a superoptimizer can synthesize by rapidly pruning away invalid candidate programs. Pruning is achieved by selectively refining the abstraction under which candidates are considered equivalent, only in the promising part of the candidate space. LENS also uses a bidirectional search strategy to prune the candidate space from both forward and backward directions. These pruning strategies allow LENS to solve twice as many benchmarks as existing enumerative search algorithms, while LENS is about 11-times faster.Additionally, we increase the effective size of the superoptimized fragments by relaxing the correctness condition using contexts (surrounding code). Finally, we combine LENS with complementary search techniques into a cooperative superoptimizer, which exploits the stochastic search to make random jumps in a large candidate space, and a symbolic (SAT-solver-based) search to synthesize arbitrary constants. While existing superoptimizers consistently solve 9--16 out of 32 benchmarks, the cooperative superoptimizer solves 29 benchmarks. It can synthesize code fragments that are up to 82\% faster than code generated by gcc -O3 from WiBench and MiBench.},
journal = {SIGPLAN Not.},
month = mar,
pages = {297–310},
numpages = {14},
keywords = {SMT, program synthesis, superoptimization}
}

@inproceedings{10.1145/2872362.2872387,
author = {Phothilimthana, Phitchaya Mangpo and Thakur, Aditya and Bodik, Rastislav and Dhurjati, Dinakar},
title = {Scaling up Superoptimization},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872387},
doi = {10.1145/2872362.2872387},
abstract = {Developing a code optimizer is challenging, especially for new, idiosyncratic ISAs. Superoptimization can, in principle, discover machine-specific optimizations automatically by searching the space of all instruction sequences. If we can increase the size of code fragments a superoptimizer can optimize, we will be able to discover more optimizations. We develop LENS, a search algorithm that increases the size of code a superoptimizer can synthesize by rapidly pruning away invalid candidate programs. Pruning is achieved by selectively refining the abstraction under which candidates are considered equivalent, only in the promising part of the candidate space. LENS also uses a bidirectional search strategy to prune the candidate space from both forward and backward directions. These pruning strategies allow LENS to solve twice as many benchmarks as existing enumerative search algorithms, while LENS is about 11-times faster.Additionally, we increase the effective size of the superoptimized fragments by relaxing the correctness condition using contexts (surrounding code). Finally, we combine LENS with complementary search techniques into a cooperative superoptimizer, which exploits the stochastic search to make random jumps in a large candidate space, and a symbolic (SAT-solver-based) search to synthesize arbitrary constants. While existing superoptimizers consistently solve 9--16 out of 32 benchmarks, the cooperative superoptimizer solves 29 benchmarks. It can synthesize code fragments that are up to 82\% faster than code generated by gcc -O3 from WiBench and MiBench.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {297–310},
numpages = {14},
keywords = {SMT, program synthesis, superoptimization},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872380,
author = {Hasabnis, Niranjan and Sekar, R.},
title = {Lifting Assembly to Intermediate Representation: A Novel Approach Leveraging Compilers},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872380},
doi = {10.1145/2980024.2872380},
abstract = {Translating low-level machine instructions into higher-level intermediate language (IL) is one of the central steps in many binary analysis and instrumentation systems. Existing systems build such translators manually. As a result, it takes a great deal of effort to support new architectures. Even for widely deployed architectures, full instruction sets may not be modeled, e.g., mature systems such as Valgrind still lack support for AVX, FMA4 and SSE4.1 for x86 processors. To overcome these difficulties, we propose a novel approach that leverages knowledge about instruction set semantics that is already embedded into modern compilers such as GCC. In particular, we present a learning-based approach for automating the translation of assembly instructions to a compiler's architecture-neutral IL. We present an experimental evaluation that demonstrates the ability of our approach to easily support many architectures (x86, ARM and AVR), including their advanced instruction sets. Our implementation is available as open-source software.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {311–324},
numpages = {14}
}

@article{10.1145/2954679.2872380,
author = {Hasabnis, Niranjan and Sekar, R.},
title = {Lifting Assembly to Intermediate Representation: A Novel Approach Leveraging Compilers},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872380},
doi = {10.1145/2954679.2872380},
abstract = {Translating low-level machine instructions into higher-level intermediate language (IL) is one of the central steps in many binary analysis and instrumentation systems. Existing systems build such translators manually. As a result, it takes a great deal of effort to support new architectures. Even for widely deployed architectures, full instruction sets may not be modeled, e.g., mature systems such as Valgrind still lack support for AVX, FMA4 and SSE4.1 for x86 processors. To overcome these difficulties, we propose a novel approach that leverages knowledge about instruction set semantics that is already embedded into modern compilers such as GCC. In particular, we present a learning-based approach for automating the translation of assembly instructions to a compiler's architecture-neutral IL. We present an experimental evaluation that demonstrates the ability of our approach to easily support many architectures (x86, ARM and AVR), including their advanced instruction sets. Our implementation is available as open-source software.},
journal = {SIGPLAN Not.},
month = mar,
pages = {311–324},
numpages = {14}
}

@inproceedings{10.1145/2872362.2872380,
author = {Hasabnis, Niranjan and Sekar, R.},
title = {Lifting Assembly to Intermediate Representation: A Novel Approach Leveraging Compilers},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872380},
doi = {10.1145/2872362.2872380},
abstract = {Translating low-level machine instructions into higher-level intermediate language (IL) is one of the central steps in many binary analysis and instrumentation systems. Existing systems build such translators manually. As a result, it takes a great deal of effort to support new architectures. Even for widely deployed architectures, full instruction sets may not be modeled, e.g., mature systems such as Valgrind still lack support for AVX, FMA4 and SSE4.1 for x86 processors. To overcome these difficulties, we propose a novel approach that leverages knowledge about instruction set semantics that is already embedded into modern compilers such as GCC. In particular, we present a learning-based approach for automating the translation of assembly instructions to a compiler's architecture-neutral IL. We present an experimental evaluation that demonstrates the ability of our approach to easily support many architectures (x86, ARM and AVR), including their advanced instruction sets. Our implementation is available as open-source software.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {311–324},
numpages = {14},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872411,
author = {Muralidharan, Saurav and Roy, Amit and Hall, Mary and Garland, Michael and Rai, Piyush},
title = {Architecture-Adaptive Code Variant Tuning},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872411},
doi = {10.1145/2980024.2872411},
abstract = {Code variants represent alternative implementations of a computation, and are common in high-performance libraries and applications to facilitate selecting the most appropriate implementation for a specific execution context (target architecture and input dataset). Automating code variant selection typically relies on machine learning to construct a model during an offline learning phase that can be quickly queried at runtime once the execution context is known. In this paper, we define a new approach called architecture-adaptive code variant tuning, where the variant selection model is learned on a set of source architectures, and then used to predict variants on a new target architecture without having to repeat the training process. We pose this as a multi-task learning problem, where each source architecture corresponds to a task; we use device features in the construction of the variant selection model. This work explores the effectiveness of multi-task learning and the impact of different strategies for device feature selection. We evaluate our approach on a set of benchmarks and a collection of six NVIDIA GPU architectures from three distinct generations. We achieve performance results that are mostly comparable to the previous approach of tuning for a single GPU architecture without having to repeat the learning phase.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {325–338},
numpages = {14},
keywords = {autotuning, cross-architectural tuning, device feature selection, input-adaptive, multi-task learning}
}

@article{10.1145/2954679.2872411,
author = {Muralidharan, Saurav and Roy, Amit and Hall, Mary and Garland, Michael and Rai, Piyush},
title = {Architecture-Adaptive Code Variant Tuning},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872411},
doi = {10.1145/2954679.2872411},
abstract = {Code variants represent alternative implementations of a computation, and are common in high-performance libraries and applications to facilitate selecting the most appropriate implementation for a specific execution context (target architecture and input dataset). Automating code variant selection typically relies on machine learning to construct a model during an offline learning phase that can be quickly queried at runtime once the execution context is known. In this paper, we define a new approach called architecture-adaptive code variant tuning, where the variant selection model is learned on a set of source architectures, and then used to predict variants on a new target architecture without having to repeat the training process. We pose this as a multi-task learning problem, where each source architecture corresponds to a task; we use device features in the construction of the variant selection model. This work explores the effectiveness of multi-task learning and the impact of different strategies for device feature selection. We evaluate our approach on a set of benchmarks and a collection of six NVIDIA GPU architectures from three distinct generations. We achieve performance results that are mostly comparable to the previous approach of tuning for a single GPU architecture without having to repeat the learning phase.},
journal = {SIGPLAN Not.},
month = mar,
pages = {325–338},
numpages = {14},
keywords = {autotuning, cross-architectural tuning, device feature selection, input-adaptive, multi-task learning}
}

@inproceedings{10.1145/2872362.2872411,
author = {Muralidharan, Saurav and Roy, Amit and Hall, Mary and Garland, Michael and Rai, Piyush},
title = {Architecture-Adaptive Code Variant Tuning},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872411},
doi = {10.1145/2872362.2872411},
abstract = {Code variants represent alternative implementations of a computation, and are common in high-performance libraries and applications to facilitate selecting the most appropriate implementation for a specific execution context (target architecture and input dataset). Automating code variant selection typically relies on machine learning to construct a model during an offline learning phase that can be quickly queried at runtime once the execution context is known. In this paper, we define a new approach called architecture-adaptive code variant tuning, where the variant selection model is learned on a set of source architectures, and then used to predict variants on a new target architecture without having to repeat the training process. We pose this as a multi-task learning problem, where each source architecture corresponds to a task; we use device features in the construction of the variant selection model. This work explores the effectiveness of multi-task learning and the impact of different strategies for device feature selection. We evaluate our approach on a set of benchmarks and a collection of six NVIDIA GPU architectures from three distinct generations. We achieve performance results that are mostly comparable to the previous approach of tuning for a single GPU architecture without having to repeat the learning phase.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {325–338},
numpages = {14},
keywords = {autotuning, cross-architectural tuning, device feature selection, input-adaptive, multi-task learning},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252400,
author = {Balasubramonian, Rajeev},
title = {Session details: Session 4B: Energy and Thermal Management},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252400},
doi = {10.1145/3252400},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872375,
author = {Zhang, Huazhe and Hoffmann, Henry},
title = {Maximizing Performance Under a Power Cap: A Comparison of Hardware, Software, and Hybrid Techniques},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872375},
doi = {10.1145/2954679.2872375},
abstract = {Power and thermal dissipation constrain multicore performance scaling. Modern processors are built such that they could sustain damaging levels of power dissipation, creating a need for systems that can implement processor power caps. A particular challenge is developing systems that can maximize performance within a power cap, and approaches have been proposed in both software and hardware. Software approaches are flexible, allowing multiple hardware resources to be coordinated for maximum performance, but software is slow, requiring a long time to converge to the power target. In contrast, hardware power capping quickly converges to the the power cap, but only manages voltage and frequency, limiting its potential performance. In this work we propose PUPiL, a hybrid software/hardware power capping system. Unlike previous approaches, PUPiL combines hardware's fast reaction time with software's flexibility. We implement PUPiL on real Linux/x86 platform and compare it to Intel's commercial hardware power capping system for both single and multi-application workloads. We find PUPiL provides the same reaction time as Intel's hardware with significantly higher performance. On average, PUPiL outperforms hardware by from 1:18-2:4 depending on workload and power target. Thus, PUPiL provides a promising way to enforce power caps with greater performance than current state-of-the-art hardware-only approaches.},
journal = {SIGPLAN Not.},
month = mar,
pages = {545–559},
numpages = {15},
keywords = {power management, decision-tree, adaptive systems}
}

@article{10.1145/2980024.2872375,
author = {Zhang, Huazhe and Hoffmann, Henry},
title = {Maximizing Performance Under a Power Cap: A Comparison of Hardware, Software, and Hybrid Techniques},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872375},
doi = {10.1145/2980024.2872375},
abstract = {Power and thermal dissipation constrain multicore performance scaling. Modern processors are built such that they could sustain damaging levels of power dissipation, creating a need for systems that can implement processor power caps. A particular challenge is developing systems that can maximize performance within a power cap, and approaches have been proposed in both software and hardware. Software approaches are flexible, allowing multiple hardware resources to be coordinated for maximum performance, but software is slow, requiring a long time to converge to the power target. In contrast, hardware power capping quickly converges to the the power cap, but only manages voltage and frequency, limiting its potential performance. In this work we propose PUPiL, a hybrid software/hardware power capping system. Unlike previous approaches, PUPiL combines hardware's fast reaction time with software's flexibility. We implement PUPiL on real Linux/x86 platform and compare it to Intel's commercial hardware power capping system for both single and multi-application workloads. We find PUPiL provides the same reaction time as Intel's hardware with significantly higher performance. On average, PUPiL outperforms hardware by from 1:18-2:4 depending on workload and power target. Thus, PUPiL provides a promising way to enforce power caps with greater performance than current state-of-the-art hardware-only approaches.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {545–559},
numpages = {15},
keywords = {adaptive systems, decision-tree, power management}
}

@inproceedings{10.1145/2872362.2872375,
author = {Zhang, Huazhe and Hoffmann, Henry},
title = {Maximizing Performance Under a Power Cap: A Comparison of Hardware, Software, and Hybrid Techniques},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872375},
doi = {10.1145/2872362.2872375},
abstract = {Power and thermal dissipation constrain multicore performance scaling. Modern processors are built such that they could sustain damaging levels of power dissipation, creating a need for systems that can implement processor power caps. A particular challenge is developing systems that can maximize performance within a power cap, and approaches have been proposed in both software and hardware. Software approaches are flexible, allowing multiple hardware resources to be coordinated for maximum performance, but software is slow, requiring a long time to converge to the power target. In contrast, hardware power capping quickly converges to the the power cap, but only manages voltage and frequency, limiting its potential performance. In this work we propose PUPiL, a hybrid software/hardware power capping system. Unlike previous approaches, PUPiL combines hardware's fast reaction time with software's flexibility. We implement PUPiL on real Linux/x86 platform and compare it to Intel's commercial hardware power capping system for both single and multi-application workloads. We find PUPiL provides the same reaction time as Intel's hardware with significantly higher performance. On average, PUPiL outperforms hardware by from 1:18-2:4 depending on workload and power target. Thus, PUPiL provides a promising way to enforce power caps with greater performance than current state-of-the-art hardware-only approaches.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {545–559},
numpages = {15},
keywords = {adaptive systems, decision-tree, power management},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872383,
author = {Fan, Songchun and Zahedi, Seyed Majid and Lee, Benjamin C.},
title = {The Computational Sprinting Game},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872383},
doi = {10.1145/2980024.2872383},
abstract = {Computational sprinting is a class of mechanisms that boost performance but dissipate additional power. We describe a sprinting architecture in which many, independent chip multiprocessors share a power supply and sprints are constrained by the chips' thermal limits and the rack's power limits. Moreover, we present the computational sprinting game, a multi-agent perspective on managing sprints. Strategic agents decide whether to sprint based on application phases and system conditions. The game produces an equilibrium that improves task throughput for data analytics workloads by 4-6\texttimes{} over prior greedy heuristics and performs within 90\% of an upper bound on throughput from a globally optimized policy.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {561–575},
numpages = {15},
keywords = {computational sprinting, energy efficiency, game theory, performance}
}

@article{10.1145/2954679.2872383,
author = {Fan, Songchun and Zahedi, Seyed Majid and Lee, Benjamin C.},
title = {The Computational Sprinting Game},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872383},
doi = {10.1145/2954679.2872383},
abstract = {Computational sprinting is a class of mechanisms that boost performance but dissipate additional power. We describe a sprinting architecture in which many, independent chip multiprocessors share a power supply and sprints are constrained by the chips' thermal limits and the rack's power limits. Moreover, we present the computational sprinting game, a multi-agent perspective on managing sprints. Strategic agents decide whether to sprint based on application phases and system conditions. The game produces an equilibrium that improves task throughput for data analytics workloads by 4-6\texttimes{} over prior greedy heuristics and performs within 90\% of an upper bound on throughput from a globally optimized policy.},
journal = {SIGPLAN Not.},
month = mar,
pages = {561–575},
numpages = {15},
keywords = {computational sprinting, energy efficiency, game theory, performance}
}

@inproceedings{10.1145/2872362.2872383,
author = {Fan, Songchun and Zahedi, Seyed Majid and Lee, Benjamin C.},
title = {The Computational Sprinting Game},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872383},
doi = {10.1145/2872362.2872383},
abstract = {Computational sprinting is a class of mechanisms that boost performance but dissipate additional power. We describe a sprinting architecture in which many, independent chip multiprocessors share a power supply and sprints are constrained by the chips' thermal limits and the rack's power limits. Moreover, we present the computational sprinting game, a multi-agent perspective on managing sprints. Strategic agents decide whether to sprint based on application phases and system conditions. The game produces an equilibrium that improves task throughput for data analytics workloads by 4-6\texttimes{} over prior greedy heuristics and performs within 90\% of an upper bound on throughput from a globally optimized policy.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {561–575},
numpages = {15},
keywords = {computational sprinting, energy efficiency, game theory, performance},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872409,
author = {Colin, Alexei and Harvey, Graham and Lucia, Brandon and Sample, Alanson P.},
title = {An Energy-interference-free Hardware-Software Debugger for Intermittent Energy-harvesting Systems},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872409},
doi = {10.1145/2954679.2872409},
abstract = {Energy-autonomous computing devices have the potential to extend the reach of computing to a scale beyond either wired or battery-powered systems. However, these devices pose a unique set of challenges to application developers who lack both hardware and software support tools. Energy harvesting devices experience power intermittence which causes the system to reset and power-cycle unpredictably, tens to hundreds of times per second. This can result in code execution errors that are not possible in continuously-powered systems and cannot be diagnosed with conventional debugging tools such as JTAG and/or oscilloscopes. We propose the Energy-interference-free Debugger, a hardware and software platform for monitoring and debugging intermittent systems without adversely effecting their energy state. The Energy-interference-free Debugger re-creates a familiar debugging environment for intermittent software and augments it with debugging primitives for effective diagnosis of intermittence bugs. Our evaluation of the Energy-interference-free Debugger quantifies its energy-interference-freedom and shows its value in a set of debugging tasks in complex test programs and several real applications, including RFID code and a machine-learning-based activity recognition system.},
journal = {SIGPLAN Not.},
month = mar,
pages = {577–589},
numpages = {13},
keywords = {energy-harvesting}
}

@article{10.1145/2980024.2872409,
author = {Colin, Alexei and Harvey, Graham and Lucia, Brandon and Sample, Alanson P.},
title = {An Energy-interference-free Hardware-Software Debugger for Intermittent Energy-harvesting Systems},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872409},
doi = {10.1145/2980024.2872409},
abstract = {Energy-autonomous computing devices have the potential to extend the reach of computing to a scale beyond either wired or battery-powered systems. However, these devices pose a unique set of challenges to application developers who lack both hardware and software support tools. Energy harvesting devices experience power intermittence which causes the system to reset and power-cycle unpredictably, tens to hundreds of times per second. This can result in code execution errors that are not possible in continuously-powered systems and cannot be diagnosed with conventional debugging tools such as JTAG and/or oscilloscopes. We propose the Energy-interference-free Debugger, a hardware and software platform for monitoring and debugging intermittent systems without adversely effecting their energy state. The Energy-interference-free Debugger re-creates a familiar debugging environment for intermittent software and augments it with debugging primitives for effective diagnosis of intermittence bugs. Our evaluation of the Energy-interference-free Debugger quantifies its energy-interference-freedom and shows its value in a set of debugging tasks in complex test programs and several real applications, including RFID code and a machine-learning-based activity recognition system.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {577–589},
numpages = {13},
keywords = {energy-harvesting}
}

@inproceedings{10.1145/2872362.2872409,
author = {Colin, Alexei and Harvey, Graham and Lucia, Brandon and Sample, Alanson P.},
title = {An Energy-interference-free Hardware-Software Debugger for Intermittent Energy-harvesting Systems},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872409},
doi = {10.1145/2872362.2872409},
abstract = {Energy-autonomous computing devices have the potential to extend the reach of computing to a scale beyond either wired or battery-powered systems. However, these devices pose a unique set of challenges to application developers who lack both hardware and software support tools. Energy harvesting devices experience power intermittence which causes the system to reset and power-cycle unpredictably, tens to hundreds of times per second. This can result in code execution errors that are not possible in continuously-powered systems and cannot be diagnosed with conventional debugging tools such as JTAG and/or oscilloscopes. We propose the Energy-interference-free Debugger, a hardware and software platform for monitoring and debugging intermittent systems without adversely effecting their energy state. The Energy-interference-free Debugger re-creates a familiar debugging environment for intermittent software and augments it with debugging primitives for effective diagnosis of intermittence bugs. Our evaluation of the Energy-interference-free Debugger quantifies its energy-interference-freedom and shows its value in a set of debugging tasks in complex test programs and several real applications, including RFID code and a machine-learning-based activity recognition system.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {577–589},
numpages = {13},
keywords = {energy-harvesting},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252401,
author = {Tucek, Joseph},
title = {Session details: Session 5A: Emerging Memory Technologies},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252401},
doi = {10.1145/3252401},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872392,
author = {Kim, Wook-Hee and Kim, Jinwoong and Baek, Woongki and Nam, Beomseok and Won, Youjip},
title = {NVWAL: Exploiting NVRAM in Write-Ahead Logging},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872392},
doi = {10.1145/2980024.2872392},
abstract = {Emerging byte-addressable non-volatile memory is considered an alternative storage device for database logs that require persistency and high performance. In this work, we develop NVWAL (NVRAM Write-Ahead Logging) for SQLite. The contribution of NVWAL consists of three elements: (i) byte-granularity differential logging that effectively eliminates the excessive I/O overhead of filesystem-based logging or journaling, (ii) transaction-aware lazy synchronization that reduces cache synchronization overhead by two-thirds, and (iii) user-level heap management of the NVRAM persistent WAL structure, which reduces the overhead of managing persistent objects.We implemented NVWAL in SQLite and measured the performance on a Nexus 5 smartphone and an NVRAM emulation board - Tuna. Our performance study shows the following: (i) the overhead of enforcing strict ordering of NVRAM writes can be reduced via NVRAM-aware transaction management. (ii) From the application performance point of view, the overhead of guaranteeing failure atomicity is negligible; the cache line flush overhead accounts for only 0.8~4.6\% of transaction execution time. Therefore, application performance is much less sensitive to the NVRAM performance than we expected. Decreasing the NVRAM latency by one-fifth (from 1942 nsec to 437 nsec), SQLite achieves a mere 4\% performance gain (from 2517 ins/sec to 2621 ins/sec). (iii) Overall, when the write latency of NVRAM is 2 usec, NVWAL increases SQLite performance by at least 10x compared to that of WAL on flash memory (from 541 ins/sec to 5812 ins/sec).},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {385–398},
numpages = {14},
keywords = {write-ahead-logging, non-volatile memory}
}

@article{10.1145/2954679.2872392,
author = {Kim, Wook-Hee and Kim, Jinwoong and Baek, Woongki and Nam, Beomseok and Won, Youjip},
title = {NVWAL: Exploiting NVRAM in Write-Ahead Logging},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872392},
doi = {10.1145/2954679.2872392},
abstract = {Emerging byte-addressable non-volatile memory is considered an alternative storage device for database logs that require persistency and high performance. In this work, we develop NVWAL (NVRAM Write-Ahead Logging) for SQLite. The contribution of NVWAL consists of three elements: (i) byte-granularity differential logging that effectively eliminates the excessive I/O overhead of filesystem-based logging or journaling, (ii) transaction-aware lazy synchronization that reduces cache synchronization overhead by two-thirds, and (iii) user-level heap management of the NVRAM persistent WAL structure, which reduces the overhead of managing persistent objects.We implemented NVWAL in SQLite and measured the performance on a Nexus 5 smartphone and an NVRAM emulation board - Tuna. Our performance study shows the following: (i) the overhead of enforcing strict ordering of NVRAM writes can be reduced via NVRAM-aware transaction management. (ii) From the application performance point of view, the overhead of guaranteeing failure atomicity is negligible; the cache line flush overhead accounts for only 0.8~4.6\% of transaction execution time. Therefore, application performance is much less sensitive to the NVRAM performance than we expected. Decreasing the NVRAM latency by one-fifth (from 1942 nsec to 437 nsec), SQLite achieves a mere 4\% performance gain (from 2517 ins/sec to 2621 ins/sec). (iii) Overall, when the write latency of NVRAM is 2 usec, NVWAL increases SQLite performance by at least 10x compared to that of WAL on flash memory (from 541 ins/sec to 5812 ins/sec).},
journal = {SIGPLAN Not.},
month = mar,
pages = {385–398},
numpages = {14},
keywords = {non-volatile memory, write-ahead-logging}
}

@inproceedings{10.1145/2872362.2872392,
author = {Kim, Wook-Hee and Kim, Jinwoong and Baek, Woongki and Nam, Beomseok and Won, Youjip},
title = {NVWAL: Exploiting NVRAM in Write-Ahead Logging},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872392},
doi = {10.1145/2872362.2872392},
abstract = {Emerging byte-addressable non-volatile memory is considered an alternative storage device for database logs that require persistency and high performance. In this work, we develop NVWAL (NVRAM Write-Ahead Logging) for SQLite. The contribution of NVWAL consists of three elements: (i) byte-granularity differential logging that effectively eliminates the excessive I/O overhead of filesystem-based logging or journaling, (ii) transaction-aware lazy synchronization that reduces cache synchronization overhead by two-thirds, and (iii) user-level heap management of the NVRAM persistent WAL structure, which reduces the overhead of managing persistent objects.We implemented NVWAL in SQLite and measured the performance on a Nexus 5 smartphone and an NVRAM emulation board - Tuna. Our performance study shows the following: (i) the overhead of enforcing strict ordering of NVRAM writes can be reduced via NVRAM-aware transaction management. (ii) From the application performance point of view, the overhead of guaranteeing failure atomicity is negligible; the cache line flush overhead accounts for only 0.8~4.6\% of transaction execution time. Therefore, application performance is much less sensitive to the NVRAM performance than we expected. Decreasing the NVRAM latency by one-fifth (from 1942 nsec to 437 nsec), SQLite achieves a mere 4\% performance gain (from 2517 ins/sec to 2621 ins/sec). (iii) Overall, when the write latency of NVRAM is 2 usec, NVWAL increases SQLite performance by at least 10x compared to that of WAL on flash memory (from 541 ins/sec to 5812 ins/sec).},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {385–398},
numpages = {14},
keywords = {non-volatile memory, write-ahead-logging},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872381,
author = {Kolli, Aasheesh and Pelley, Steven and Saidi, Ali and Chen, Peter M. and Wenisch, Thomas F.},
title = {High-Performance Transactions for Persistent Memories},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872381},
doi = {10.1145/2980024.2872381},
abstract = {Emerging non-volatile memory (NVRAM) technologies offer the durability of disk with the byte-addressability of DRAM. These devices will allow software to access persistent data structures directly in NVRAM using processor loads and stores, however, ensuring consistency of persistent data across power failures and crashes is difficult. Atomic, durable transactions are a widely used abstraction to enforce such consistency. Implementing transactions on NVRAM requires the ability to constrain the order of NVRAM writes, for example, to ensure that a transaction's log record is complete before it is marked committed. Since NVRAM write latencies are expected to be high, minimizing these ordering constraints is critical for achieving high performance. Recent work has proposed programming interfaces to express NVRAM write ordering constraints to hardware so that NVRAM writes may be coalesced and reordered while preserving necessary constraints. Unfortunately, a straightforward implementation of transactions under these interfaces imposes unnecessary constraints. We show how to remove these dependencies through a variety of techniques, notably, deferring commit until after locks are released. We present a comprehensive analysis contrasting two transaction designs across three NVRAM programming interfaces, demonstrating up to 2.5x speedup.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {399–411},
numpages = {13},
keywords = {memory persistency, non-volatile memory, recoverability, transactions}
}

@article{10.1145/2954679.2872381,
author = {Kolli, Aasheesh and Pelley, Steven and Saidi, Ali and Chen, Peter M. and Wenisch, Thomas F.},
title = {High-Performance Transactions for Persistent Memories},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872381},
doi = {10.1145/2954679.2872381},
abstract = {Emerging non-volatile memory (NVRAM) technologies offer the durability of disk with the byte-addressability of DRAM. These devices will allow software to access persistent data structures directly in NVRAM using processor loads and stores, however, ensuring consistency of persistent data across power failures and crashes is difficult. Atomic, durable transactions are a widely used abstraction to enforce such consistency. Implementing transactions on NVRAM requires the ability to constrain the order of NVRAM writes, for example, to ensure that a transaction's log record is complete before it is marked committed. Since NVRAM write latencies are expected to be high, minimizing these ordering constraints is critical for achieving high performance. Recent work has proposed programming interfaces to express NVRAM write ordering constraints to hardware so that NVRAM writes may be coalesced and reordered while preserving necessary constraints. Unfortunately, a straightforward implementation of transactions under these interfaces imposes unnecessary constraints. We show how to remove these dependencies through a variety of techniques, notably, deferring commit until after locks are released. We present a comprehensive analysis contrasting two transaction designs across three NVRAM programming interfaces, demonstrating up to 2.5x speedup.},
journal = {SIGPLAN Not.},
month = mar,
pages = {399–411},
numpages = {13},
keywords = {memory persistency, non-volatile memory, recoverability, transactions}
}

@inproceedings{10.1145/2872362.2872381,
author = {Kolli, Aasheesh and Pelley, Steven and Saidi, Ali and Chen, Peter M. and Wenisch, Thomas F.},
title = {High-Performance Transactions for Persistent Memories},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872381},
doi = {10.1145/2872362.2872381},
abstract = {Emerging non-volatile memory (NVRAM) technologies offer the durability of disk with the byte-addressability of DRAM. These devices will allow software to access persistent data structures directly in NVRAM using processor loads and stores, however, ensuring consistency of persistent data across power failures and crashes is difficult. Atomic, durable transactions are a widely used abstraction to enforce such consistency. Implementing transactions on NVRAM requires the ability to constrain the order of NVRAM writes, for example, to ensure that a transaction's log record is complete before it is marked committed. Since NVRAM write latencies are expected to be high, minimizing these ordering constraints is critical for achieving high performance. Recent work has proposed programming interfaces to express NVRAM write ordering constraints to hardware so that NVRAM writes may be coalesced and reordered while preserving necessary constraints. Unfortunately, a straightforward implementation of transactions under these interfaces imposes unnecessary constraints. We show how to remove these dependencies through a variety of techniques, notably, deferring commit until after locks are released. We present a comprehensive analysis contrasting two transaction designs across three NVRAM programming interfaces, demonstrating up to 2.5x speedup.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {399–411},
numpages = {13},
keywords = {memory persistency, non-volatile memory, recoverability, transactions},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872413,
author = {Guo, Qing and Strauss, Karin and Ceze, Luis and Malvar, Henrique S.},
title = {High-Density Image Storage Using Approximate Memory Cells},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872413},
doi = {10.1145/2980024.2872413},
abstract = {This paper proposes tailoring image encoding for an approximate storage substrate. We demonstrate that indiscriminately storing encoded images in approximate memory generates unacceptable and uncontrollable quality degradation. The key finding is that errors in the encoded bit streams have non-uniform impact on the decoded image quality. We develop a methodology to determine the relative importance of encoded bits and store them in an approximate storage substrate. The storage cells are optimized to reduce error rate via biasing and are tuned to meet the desired reliability requirement via selective error correction. In a case study with the progressive transform codec (PTC), a precursor to JPEG XR, the proposed approximate image storage system exhibits a 2.7x increase in density of pixels per silicon volume under bounded error rates, and this achievement is additive to the storage savings of PTC compression.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {413–426},
numpages = {14},
keywords = {approximate storage, image encoding, multi-level cells}
}

@article{10.1145/2954679.2872413,
author = {Guo, Qing and Strauss, Karin and Ceze, Luis and Malvar, Henrique S.},
title = {High-Density Image Storage Using Approximate Memory Cells},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872413},
doi = {10.1145/2954679.2872413},
abstract = {This paper proposes tailoring image encoding for an approximate storage substrate. We demonstrate that indiscriminately storing encoded images in approximate memory generates unacceptable and uncontrollable quality degradation. The key finding is that errors in the encoded bit streams have non-uniform impact on the decoded image quality. We develop a methodology to determine the relative importance of encoded bits and store them in an approximate storage substrate. The storage cells are optimized to reduce error rate via biasing and are tuned to meet the desired reliability requirement via selective error correction. In a case study with the progressive transform codec (PTC), a precursor to JPEG XR, the proposed approximate image storage system exhibits a 2.7x increase in density of pixels per silicon volume under bounded error rates, and this achievement is additive to the storage savings of PTC compression.},
journal = {SIGPLAN Not.},
month = mar,
pages = {413–426},
numpages = {14},
keywords = {approximate storage, image encoding, multi-level cells}
}

@inproceedings{10.1145/2872362.2872413,
author = {Guo, Qing and Strauss, Karin and Ceze, Luis and Malvar, Henrique S.},
title = {High-Density Image Storage Using Approximate Memory Cells},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872413},
doi = {10.1145/2872362.2872413},
abstract = {This paper proposes tailoring image encoding for an approximate storage substrate. We demonstrate that indiscriminately storing encoded images in approximate memory generates unacceptable and uncontrollable quality degradation. The key finding is that errors in the encoded bit streams have non-uniform impact on the decoded image quality. We develop a methodology to determine the relative importance of encoded bits and store them in an approximate storage substrate. The storage cells are optimized to reduce error rate via biasing and are tuned to meet the desired reliability requirement via selective error correction. In a case study with the progressive transform codec (PTC), a precursor to JPEG XR, the proposed approximate image storage system exhibits a 2.7x increase in density of pixels per silicon volume under bounded error rates, and this achievement is additive to the storage savings of PTC compression.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {413–426},
numpages = {14},
keywords = {approximate storage, image encoding, multi-level cells},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872410,
author = {Izraelevitz, Joseph and Kelly, Terence and Kolli, Aasheesh},
title = {Failure-Atomic Persistent Memory Updates via JUSTDO Logging},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872410},
doi = {10.1145/2954679.2872410},
abstract = {Persistent memory invites applications to manipulate persistent data via load and store instructions. Because failures during updates may destroy transient data (e.g., in CPU registers), preserving data integrity in the presence of failures requires failure-atomic bundles of updates. Prior failure atomicity approaches for persistent memory entail overheads due to logging and CPU cache flushing. Persistent caches can eliminate the need for flushing, but conventional logging remains complex and memory intensive. We present the design and implementation of JUSTDO logging, a new failure atomicity mechanism that greatly reduces the memory footprint of logs, simplifies log management, and enables fast parallel recovery following failure. Crash-injection tests confirm that JUSTDO logging preserves application data integrity and performance evaluations show that it improves throughput 3x or more compared with a state-of-the-art alternative for a spectrum of data-intensive algorithms.},
journal = {SIGPLAN Not.},
month = mar,
pages = {427–442},
numpages = {16},
keywords = {crash-resilience, failure-atomicity, non-volatile memory, persistent memory, transactions}
}

@article{10.1145/2980024.2872410,
author = {Izraelevitz, Joseph and Kelly, Terence and Kolli, Aasheesh},
title = {Failure-Atomic Persistent Memory Updates via JUSTDO Logging},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872410},
doi = {10.1145/2980024.2872410},
abstract = {Persistent memory invites applications to manipulate persistent data via load and store instructions. Because failures during updates may destroy transient data (e.g., in CPU registers), preserving data integrity in the presence of failures requires failure-atomic bundles of updates. Prior failure atomicity approaches for persistent memory entail overheads due to logging and CPU cache flushing. Persistent caches can eliminate the need for flushing, but conventional logging remains complex and memory intensive. We present the design and implementation of JUSTDO logging, a new failure atomicity mechanism that greatly reduces the memory footprint of logs, simplifies log management, and enables fast parallel recovery following failure. Crash-injection tests confirm that JUSTDO logging preserves application data integrity and performance evaluations show that it improves throughput 3x or more compared with a state-of-the-art alternative for a spectrum of data-intensive algorithms.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {427–442},
numpages = {16},
keywords = {crash-resilience, failure-atomicity, non-volatile memory, persistent memory, transactions}
}

@inproceedings{10.1145/2872362.2872410,
author = {Izraelevitz, Joseph and Kelly, Terence and Kolli, Aasheesh},
title = {Failure-Atomic Persistent Memory Updates via JUSTDO Logging},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872410},
doi = {10.1145/2872362.2872410},
abstract = {Persistent memory invites applications to manipulate persistent data via load and store instructions. Because failures during updates may destroy transient data (e.g., in CPU registers), preserving data integrity in the presence of failures requires failure-atomic bundles of updates. Prior failure atomicity approaches for persistent memory entail overheads due to logging and CPU cache flushing. Persistent caches can eliminate the need for flushing, but conventional logging remains complex and memory intensive. We present the design and implementation of JUSTDO logging, a new failure atomicity mechanism that greatly reduces the memory footprint of logs, simplifies log management, and enables fast parallel recovery following failure. Crash-injection tests confirm that JUSTDO logging preserves application data integrity and performance evaluations show that it improves throughput 3x or more compared with a state-of-the-art alternative for a spectrum of data-intensive algorithms.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {427–442},
numpages = {16},
keywords = {crash-resilience, failure-atomicity, non-volatile memory, persistent memory, transactions},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252402,
author = {Tang, Lingjia},
title = {Session details: Session 5B: Cloud Computing},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252402},
doi = {10.1145/3252402},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872388,
author = {Han, Jaeung and Jeon, Seungheun and Choi, Young-ri and Huh, Jaehyuk},
title = {Interference Management for Distributed Parallel Applications in Consolidated Clusters},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872388},
doi = {10.1145/2954679.2872388},
abstract = {Consolidating multiple applications on a system can improve the overall resource utilization of data center systems. However, such consolidation can adversely affect the performance of some applications due to interference caused by resource contention. Despite many prior studies on the interference effects in single-node systems, the interference behaviors of distributed parallel applications have not been investigated thoroughly. With distributed applications, a local interference in a node can affect the whole execution of an application spanning many nodes. This paper studies an interference modeling methodology for distributed applications to predict their performance under interference effects in consolidated clusters. This study first characterizes the effects of interference for various distributed applications over different interference settings, and analyzes how diverse interference intensities on multiple nodes affect the overall performance. Based on the characterization, this study proposes a static profiling-based model for interference propagation and heterogeneity behaviors. In addition, this paper presents use case studies of the modeling method, two interference-aware placement techniques for consolidated virtual clusters, which attempt to maximize the overall throughput or to guarantee the quality-of-service.},
journal = {SIGPLAN Not.},
month = mar,
pages = {443–456},
numpages = {14},
keywords = {resource contention, placement algorithm, interference model, distributed parallel application, consolidated system, cloud computing}
}

@article{10.1145/2980024.2872388,
author = {Han, Jaeung and Jeon, Seungheun and Choi, Young-ri and Huh, Jaehyuk},
title = {Interference Management for Distributed Parallel Applications in Consolidated Clusters},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872388},
doi = {10.1145/2980024.2872388},
abstract = {Consolidating multiple applications on a system can improve the overall resource utilization of data center systems. However, such consolidation can adversely affect the performance of some applications due to interference caused by resource contention. Despite many prior studies on the interference effects in single-node systems, the interference behaviors of distributed parallel applications have not been investigated thoroughly. With distributed applications, a local interference in a node can affect the whole execution of an application spanning many nodes. This paper studies an interference modeling methodology for distributed applications to predict their performance under interference effects in consolidated clusters. This study first characterizes the effects of interference for various distributed applications over different interference settings, and analyzes how diverse interference intensities on multiple nodes affect the overall performance. Based on the characterization, this study proposes a static profiling-based model for interference propagation and heterogeneity behaviors. In addition, this paper presents use case studies of the modeling method, two interference-aware placement techniques for consolidated virtual clusters, which attempt to maximize the overall throughput or to guarantee the quality-of-service.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {443–456},
numpages = {14},
keywords = {resource contention, placement algorithm, interference model, distributed parallel application, consolidated system, cloud computing}
}

@inproceedings{10.1145/2872362.2872388,
author = {Han, Jaeung and Jeon, Seungheun and Choi, Young-ri and Huh, Jaehyuk},
title = {Interference Management for Distributed Parallel Applications in Consolidated Clusters},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872388},
doi = {10.1145/2872362.2872388},
abstract = {Consolidating multiple applications on a system can improve the overall resource utilization of data center systems. However, such consolidation can adversely affect the performance of some applications due to interference caused by resource contention. Despite many prior studies on the interference effects in single-node systems, the interference behaviors of distributed parallel applications have not been investigated thoroughly. With distributed applications, a local interference in a node can affect the whole execution of an application spanning many nodes. This paper studies an interference modeling methodology for distributed applications to predict their performance under interference effects in consolidated clusters. This study first characterizes the effects of interference for various distributed applications over different interference settings, and analyzes how diverse interference intensities on multiple nodes affect the overall performance. Based on the characterization, this study proposes a static profiling-based model for interference propagation and heterogeneity behaviors. In addition, this paper presents use case studies of the modeling method, two interference-aware placement techniques for consolidated virtual clusters, which attempt to maximize the overall throughput or to guarantee the quality-of-service.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {443–456},
numpages = {14},
keywords = {cloud computing, consolidated system, distributed parallel application, interference model, placement algorithm, resource contention},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872386,
author = {Maas, Martin and Asanovi\'{c}, Krste and Harris, Tim and Kubiatowicz, John},
title = {Taurus: A Holistic Language Runtime System for Coordinating Distributed Managed-Language Applications},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872386},
doi = {10.1145/2954679.2872386},
abstract = {Many distributed workloads in today's data centers are written in managed languages such as Java or Ruby. Examples include big data frameworks such as Hadoop, data stores such as Cassandra or applications such as the SOLR search engine. These workloads typically run across many independent language runtime systems on different nodes. This setup represents a source of inefficiency, as these language runtime systems are unaware of each other. For example, they may perform Garbage Collection at times that are locally reasonable but not in a distributed setting.We address these problems by introducing the concept of a Holistic Runtime System that makes runtime-level decisions for the entire distributed application rather than locally. We then present Taurus, a Holistic Runtime System prototype. Taurus is a JVM drop-in replacement, requires almost no configuration and can run unmodified off-the-shelf Java applications. Taurus enforces user-defined coordination policies and provides a DSL for writing these policies.By applying Taurus to Garbage Collection, we demonstrate the potential of such a system and use it to explore coordination strategies for the runtime systems of real-world distributed applications, to improve application performance and address tail-latencies in latency-sensitive workloads.},
journal = {SIGPLAN Not.},
month = mar,
pages = {457–471},
numpages = {15},
keywords = {DSL, JVM, cassandra, garbage collection, garbage collection coordination, holistic runtime systems, managed languages, raft, runtime systems, spark}
}

@article{10.1145/2980024.2872386,
author = {Maas, Martin and Asanovi\'{c}, Krste and Harris, Tim and Kubiatowicz, John},
title = {Taurus: A Holistic Language Runtime System for Coordinating Distributed Managed-Language Applications},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872386},
doi = {10.1145/2980024.2872386},
abstract = {Many distributed workloads in today's data centers are written in managed languages such as Java or Ruby. Examples include big data frameworks such as Hadoop, data stores such as Cassandra or applications such as the SOLR search engine. These workloads typically run across many independent language runtime systems on different nodes. This setup represents a source of inefficiency, as these language runtime systems are unaware of each other. For example, they may perform Garbage Collection at times that are locally reasonable but not in a distributed setting.We address these problems by introducing the concept of a Holistic Runtime System that makes runtime-level decisions for the entire distributed application rather than locally. We then present Taurus, a Holistic Runtime System prototype. Taurus is a JVM drop-in replacement, requires almost no configuration and can run unmodified off-the-shelf Java applications. Taurus enforces user-defined coordination policies and provides a DSL for writing these policies.By applying Taurus to Garbage Collection, we demonstrate the potential of such a system and use it to explore coordination strategies for the runtime systems of real-world distributed applications, to improve application performance and address tail-latencies in latency-sensitive workloads.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {457–471},
numpages = {15},
keywords = {DSL, JVM, cassandra, garbage collection, garbage collection coordination, holistic runtime systems, managed languages, raft, runtime systems, spark}
}

@inproceedings{10.1145/2872362.2872386,
author = {Maas, Martin and Asanovi\'{c}, Krste and Harris, Tim and Kubiatowicz, John},
title = {Taurus: A Holistic Language Runtime System for Coordinating Distributed Managed-Language Applications},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872386},
doi = {10.1145/2872362.2872386},
abstract = {Many distributed workloads in today's data centers are written in managed languages such as Java or Ruby. Examples include big data frameworks such as Hadoop, data stores such as Cassandra or applications such as the SOLR search engine. These workloads typically run across many independent language runtime systems on different nodes. This setup represents a source of inefficiency, as these language runtime systems are unaware of each other. For example, they may perform Garbage Collection at times that are locally reasonable but not in a distributed setting.We address these problems by introducing the concept of a Holistic Runtime System that makes runtime-level decisions for the entire distributed application rather than locally. We then present Taurus, a Holistic Runtime System prototype. Taurus is a JVM drop-in replacement, requires almost no configuration and can run unmodified off-the-shelf Java applications. Taurus enforces user-defined coordination policies and provides a DSL for writing these policies.By applying Taurus to Garbage Collection, we demonstrate the potential of such a system and use it to explore coordination strategies for the runtime systems of real-world distributed applications, to improve application performance and address tail-latencies in latency-sensitive workloads.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {457–471},
numpages = {15},
keywords = {DSL, JVM, cassandra, garbage collection, garbage collection coordination, holistic runtime systems, managed languages, raft, runtime systems, spark},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872365,
author = {Delimitrou, Christina and Kozyrakis, Christos},
title = {HCloud: Resource-Efficient Provisioning in Shared Cloud Systems},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872365},
doi = {10.1145/2980024.2872365},
abstract = {Cloud computing promises flexibility and high performance for users and cost efficiency for operators. To achieve this, cloud providers offer instances of different sizes, both as long-term reservations and short-term, on-demand allocations. Unfortunately, determining the best provisioning strategy is a complex, multi-dimensional problem that depends on the load fluctuation and duration of incoming jobs, and the performance unpredictability and cost of resources. We first compare the two main provisioning strategies (reserved and on-demand resources) on Google Compute Engine (GCE) using three representative workload scenarios with batch and latency-critical applications. We show that either approach is suboptimal for performance or cost. We then present HCloud, a hybrid provisioning system that uses both reserved and on-demand resources. HCloud determines which jobs should be mapped to reserved versus on-demand resources based on overall load, and resource unpredictability. It also determines the optimal instance size an application needs to satisfy its Quality of Service (QoS) constraints. We demonstrate that hybrid configurations improve performance by 2.1x compared to fully on-demand provisioning, and reduce cost by 46\% compared to fully reserved systems. We also show that hybrid strategies are robust to variation in system and job parameters, such as cost and system load.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {473–488},
numpages = {16},
keywords = {resource efficiency, provisioning, latency, hybrid, datacenter, cloud computing, QoS}
}

@article{10.1145/2954679.2872365,
author = {Delimitrou, Christina and Kozyrakis, Christos},
title = {HCloud: Resource-Efficient Provisioning in Shared Cloud Systems},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872365},
doi = {10.1145/2954679.2872365},
abstract = {Cloud computing promises flexibility and high performance for users and cost efficiency for operators. To achieve this, cloud providers offer instances of different sizes, both as long-term reservations and short-term, on-demand allocations. Unfortunately, determining the best provisioning strategy is a complex, multi-dimensional problem that depends on the load fluctuation and duration of incoming jobs, and the performance unpredictability and cost of resources. We first compare the two main provisioning strategies (reserved and on-demand resources) on Google Compute Engine (GCE) using three representative workload scenarios with batch and latency-critical applications. We show that either approach is suboptimal for performance or cost. We then present HCloud, a hybrid provisioning system that uses both reserved and on-demand resources. HCloud determines which jobs should be mapped to reserved versus on-demand resources based on overall load, and resource unpredictability. It also determines the optimal instance size an application needs to satisfy its Quality of Service (QoS) constraints. We demonstrate that hybrid configurations improve performance by 2.1x compared to fully on-demand provisioning, and reduce cost by 46\% compared to fully reserved systems. We also show that hybrid strategies are robust to variation in system and job parameters, such as cost and system load.},
journal = {SIGPLAN Not.},
month = mar,
pages = {473–488},
numpages = {16},
keywords = {QoS, cloud computing, datacenter, hybrid, latency, provisioning, resource efficiency}
}

@inproceedings{10.1145/2872362.2872365,
author = {Delimitrou, Christina and Kozyrakis, Christos},
title = {HCloud: Resource-Efficient Provisioning in Shared Cloud Systems},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872365},
doi = {10.1145/2872362.2872365},
abstract = {Cloud computing promises flexibility and high performance for users and cost efficiency for operators. To achieve this, cloud providers offer instances of different sizes, both as long-term reservations and short-term, on-demand allocations. Unfortunately, determining the best provisioning strategy is a complex, multi-dimensional problem that depends on the load fluctuation and duration of incoming jobs, and the performance unpredictability and cost of resources. We first compare the two main provisioning strategies (reserved and on-demand resources) on Google Compute Engine (GCE) using three representative workload scenarios with batch and latency-critical applications. We show that either approach is suboptimal for performance or cost. We then present HCloud, a hybrid provisioning system that uses both reserved and on-demand resources. HCloud determines which jobs should be mapped to reserved versus on-demand resources based on overall load, and resource unpredictability. It also determines the optimal instance size an application needs to satisfy its Quality of Service (QoS) constraints. We demonstrate that hybrid configurations improve performance by 2.1x compared to fully on-demand provisioning, and reduce cost by 46\% compared to fully reserved systems. We also show that hybrid strategies are robust to variation in system and job parameters, such as cost and system load.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {473–488},
numpages = {16},
keywords = {resource efficiency, provisioning, latency, hybrid, datacenter, cloud computing, QoS},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872407,
author = {Yu, Xiao and Joshi, Pallavi and Xu, Jianwu and Jin, Guoliang and Zhang, Hui and Jiang, Guofei},
title = {CloudSeer: Workflow Monitoring of Cloud Infrastructures via Interleaved Logs},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872407},
doi = {10.1145/2980024.2872407},
abstract = {Cloud infrastructures provide a rich set of management tasks that operate computing, storage, and networking resources in the cloud. Monitoring the executions of these tasks is crucial for cloud providers to promptly find and understand problems that compromise cloud availability. However, such monitoring is challenging because there are multiple distributed service components involved in the executions. CloudSeer enables effective workflow monitoring. It takes a lightweight non-intrusive approach that purely works on interleaved logs widely existing in cloud infrastructures. CloudSeer first builds an automaton for the workflow of each management task based on normal executions, and then it checks log messages against a set of automata for workflow divergences in a streaming manner. Divergences found during the checking process indicate potential execution problems, which may or may not be accompanied by error log messages. For each potential problem, CloudSeer outputs necessary context information including the affected task automaton and related log messages hinting where the problem occurs to help further diagnosis. Our experiments on OpenStack, a popular open-source cloud infrastructure, show that CloudSeer's efficiency and problem-detection capability are suitable for online monitoring.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {489–502},
numpages = {14},
keywords = {cloud infrastructures, distributed systems, log analysis, workflow monitoring}
}

@article{10.1145/2954679.2872407,
author = {Yu, Xiao and Joshi, Pallavi and Xu, Jianwu and Jin, Guoliang and Zhang, Hui and Jiang, Guofei},
title = {CloudSeer: Workflow Monitoring of Cloud Infrastructures via Interleaved Logs},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872407},
doi = {10.1145/2954679.2872407},
abstract = {Cloud infrastructures provide a rich set of management tasks that operate computing, storage, and networking resources in the cloud. Monitoring the executions of these tasks is crucial for cloud providers to promptly find and understand problems that compromise cloud availability. However, such monitoring is challenging because there are multiple distributed service components involved in the executions. CloudSeer enables effective workflow monitoring. It takes a lightweight non-intrusive approach that purely works on interleaved logs widely existing in cloud infrastructures. CloudSeer first builds an automaton for the workflow of each management task based on normal executions, and then it checks log messages against a set of automata for workflow divergences in a streaming manner. Divergences found during the checking process indicate potential execution problems, which may or may not be accompanied by error log messages. For each potential problem, CloudSeer outputs necessary context information including the affected task automaton and related log messages hinting where the problem occurs to help further diagnosis. Our experiments on OpenStack, a popular open-source cloud infrastructure, show that CloudSeer's efficiency and problem-detection capability are suitable for online monitoring.},
journal = {SIGPLAN Not.},
month = mar,
pages = {489–502},
numpages = {14},
keywords = {cloud infrastructures, distributed systems, log analysis, workflow monitoring}
}

@inproceedings{10.1145/2872362.2872407,
author = {Yu, Xiao and Joshi, Pallavi and Xu, Jianwu and Jin, Guoliang and Zhang, Hui and Jiang, Guofei},
title = {CloudSeer: Workflow Monitoring of Cloud Infrastructures via Interleaved Logs},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872407},
doi = {10.1145/2872362.2872407},
abstract = {Cloud infrastructures provide a rich set of management tasks that operate computing, storage, and networking resources in the cloud. Monitoring the executions of these tasks is crucial for cloud providers to promptly find and understand problems that compromise cloud availability. However, such monitoring is challenging because there are multiple distributed service components involved in the executions. CloudSeer enables effective workflow monitoring. It takes a lightweight non-intrusive approach that purely works on interleaved logs widely existing in cloud infrastructures. CloudSeer first builds an automaton for the workflow of each management task based on normal executions, and then it checks log messages against a set of automata for workflow divergences in a streaming manner. Divergences found during the checking process indicate potential execution problems, which may or may not be accompanied by error log messages. For each potential problem, CloudSeer outputs necessary context information including the affected task automaton and related log messages hinting where the problem occurs to help further diagnosis. Our experiments on OpenStack, a popular open-source cloud infrastructure, show that CloudSeer's efficiency and problem-detection capability are suitable for online monitoring.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {489–502},
numpages = {14},
keywords = {workflow monitoring, log analysis, distributed systems, cloud infrastructures},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252403,
author = {Noh, Sam H.},
title = {Session details: Session 6A: Reliability and Debugging II},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252403},
doi = {10.1145/3252403},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872395,
author = {Kwon, Yonghwi and Kim, Dohyeong and Sumner, William Nick and Kim, Kyungtae and Saltaformaggio, Brendan and Zhang, Xiangyu and Xu, Dongyan},
title = {LDX: Causality Inference by Lightweight Dual Execution},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872395},
doi = {10.1145/2954679.2872395},
abstract = {Causality inference, such as dynamic taint anslysis, has many applications (e.g., information leak detection). It determines whether an event e is causally dependent on a preceding event c during execution. We develop a new causality inference engine LDX. Given an execution, it spawns a slave execution, in which it mutates c and observes whether any change is induced at e. To preclude non-determinism, LDX couples the executions by sharing syscall outcomes. To handle path differences induced by the perturbation, we develop a novel on-the-fly execution alignment scheme that maintains a counter to reflect the progress of execution. The scheme relies on program analysis and compiler transformation. LDX can effectively detect information leak and security attacks with an average overhead of 6.08\% while running the master and the slave concurrently on separate CPUs, much lower than existing systems that require instruction level monitoring. Furthermore, it has much better accuracy in causality inference.},
journal = {SIGPLAN Not.},
month = mar,
pages = {503–515},
numpages = {13},
keywords = {causality inference, dual execution, dynamic analysis}
}

@article{10.1145/2980024.2872395,
author = {Kwon, Yonghwi and Kim, Dohyeong and Sumner, William Nick and Kim, Kyungtae and Saltaformaggio, Brendan and Zhang, Xiangyu and Xu, Dongyan},
title = {LDX: Causality Inference by Lightweight Dual Execution},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872395},
doi = {10.1145/2980024.2872395},
abstract = {Causality inference, such as dynamic taint anslysis, has many applications (e.g., information leak detection). It determines whether an event e is causally dependent on a preceding event c during execution. We develop a new causality inference engine LDX. Given an execution, it spawns a slave execution, in which it mutates c and observes whether any change is induced at e. To preclude non-determinism, LDX couples the executions by sharing syscall outcomes. To handle path differences induced by the perturbation, we develop a novel on-the-fly execution alignment scheme that maintains a counter to reflect the progress of execution. The scheme relies on program analysis and compiler transformation. LDX can effectively detect information leak and security attacks with an average overhead of 6.08\% while running the master and the slave concurrently on separate CPUs, much lower than existing systems that require instruction level monitoring. Furthermore, it has much better accuracy in causality inference.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {503–515},
numpages = {13},
keywords = {causality inference, dual execution, dynamic analysis}
}

@inproceedings{10.1145/2872362.2872395,
author = {Kwon, Yonghwi and Kim, Dohyeong and Sumner, William Nick and Kim, Kyungtae and Saltaformaggio, Brendan and Zhang, Xiangyu and Xu, Dongyan},
title = {LDX: Causality Inference by Lightweight Dual Execution},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872395},
doi = {10.1145/2872362.2872395},
abstract = {Causality inference, such as dynamic taint anslysis, has many applications (e.g., information leak detection). It determines whether an event e is causally dependent on a preceding event c during execution. We develop a new causality inference engine LDX. Given an execution, it spawns a slave execution, in which it mutates c and observes whether any change is induced at e. To preclude non-determinism, LDX couples the executions by sharing syscall outcomes. To handle path differences induced by the perturbation, we develop a novel on-the-fly execution alignment scheme that maintains a counter to reflect the progress of execution. The scheme relies on program analysis and compiler transformation. LDX can effectively detect information leak and security attacks with an average overhead of 6.08\% while running the master and the slave concurrently on separate CPUs, much lower than existing systems that require instruction level monitoring. Furthermore, it has much better accuracy in causality inference.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {503–515},
numpages = {13},
keywords = {causality inference, dual execution, dynamic analysis},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872374,
author = {Leesatapornwongsa, Tanakorn and Lukman, Jeffrey F. and Lu, Shan and Gunawi, Haryadi S.},
title = {TaxDC: A Taxonomy of Non-Deterministic Concurrency Bugs in Datacenter Distributed Systems},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872374},
doi = {10.1145/2980024.2872374},
abstract = {We present TaxDC, the largest and most comprehensive taxonomy of non-deterministic concurrency bugs in distributed systems. We study 104 distributed concurrency (DC) bugs from four widely-deployed cloud-scale datacenter distributed systems, Cassandra, Hadoop MapReduce, HBase and ZooKeeper. We study DC-bug characteristics along several axes of analysis such as the triggering timing condition and input preconditions, error and failure symptoms, and fix strategies, collectively stored as 2,083 classification labels in TaxDC database. We discuss how our study can open up many new research directions in combating DC bugs.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {517–530},
numpages = {14},
keywords = {concurrency bugs, distributed systems, software testing}
}

@article{10.1145/2954679.2872374,
author = {Leesatapornwongsa, Tanakorn and Lukman, Jeffrey F. and Lu, Shan and Gunawi, Haryadi S.},
title = {TaxDC: A Taxonomy of Non-Deterministic Concurrency Bugs in Datacenter Distributed Systems},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872374},
doi = {10.1145/2954679.2872374},
abstract = {We present TaxDC, the largest and most comprehensive taxonomy of non-deterministic concurrency bugs in distributed systems. We study 104 distributed concurrency (DC) bugs from four widely-deployed cloud-scale datacenter distributed systems, Cassandra, Hadoop MapReduce, HBase and ZooKeeper. We study DC-bug characteristics along several axes of analysis such as the triggering timing condition and input preconditions, error and failure symptoms, and fix strategies, collectively stored as 2,083 classification labels in TaxDC database. We discuss how our study can open up many new research directions in combating DC bugs.},
journal = {SIGPLAN Not.},
month = mar,
pages = {517–530},
numpages = {14},
keywords = {concurrency bugs, distributed systems, software testing}
}

@inproceedings{10.1145/2872362.2872374,
author = {Leesatapornwongsa, Tanakorn and Lukman, Jeffrey F. and Lu, Shan and Gunawi, Haryadi S.},
title = {TaxDC: A Taxonomy of Non-Deterministic Concurrency Bugs in Datacenter Distributed Systems},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872374},
doi = {10.1145/2872362.2872374},
abstract = {We present TaxDC, the largest and most comprehensive taxonomy of non-deterministic concurrency bugs in distributed systems. We study 104 distributed concurrency (DC) bugs from four widely-deployed cloud-scale datacenter distributed systems, Cassandra, Hadoop MapReduce, HBase and ZooKeeper. We study DC-bug characteristics along several axes of analysis such as the triggering timing condition and input preconditions, error and failure symptoms, and fix strategies, collectively stored as 2,083 classification labels in TaxDC database. We discuss how our study can open up many new research directions in combating DC bugs.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {517–530},
numpages = {14},
keywords = {concurrency bugs, distributed systems, software testing},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872389,
author = {Mao, Junjie and Chen, Yu and Xiao, Qixue and Shi, Yuanchun},
title = {RID: Finding Reference Count Bugs with Inconsistent Path Pair Checking},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872389},
doi = {10.1145/2980024.2872389},
abstract = {Reference counts are widely used in OS kernels for resource management. However, reference counts are not trivial to be used correctly in large scale programs because it is left to developers to make sure that an increment to a reference count is always paired with a decrement. This paper proposes inconsistent path pair checking, a novel technique that can statically discover bugs related to reference counts without knowing how reference counts should be changed in a function. A prototype called RID is implemented and evaluations show that RID can discover more than 80 bugs which were confirmed by the developers in the latest Linux kernel. The results also show that RID tends to reveal bugs caused by developers' misunderstanding on API specifications or error conditions that are not handled properly.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {531–544},
numpages = {14},
keywords = {static analysis, reference counting, inconsistency}
}

@article{10.1145/2954679.2872389,
author = {Mao, Junjie and Chen, Yu and Xiao, Qixue and Shi, Yuanchun},
title = {RID: Finding Reference Count Bugs with Inconsistent Path Pair Checking},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872389},
doi = {10.1145/2954679.2872389},
abstract = {Reference counts are widely used in OS kernels for resource management. However, reference counts are not trivial to be used correctly in large scale programs because it is left to developers to make sure that an increment to a reference count is always paired with a decrement. This paper proposes inconsistent path pair checking, a novel technique that can statically discover bugs related to reference counts without knowing how reference counts should be changed in a function. A prototype called RID is implemented and evaluations show that RID can discover more than 80 bugs which were confirmed by the developers in the latest Linux kernel. The results also show that RID tends to reveal bugs caused by developers' misunderstanding on API specifications or error conditions that are not handled properly.},
journal = {SIGPLAN Not.},
month = mar,
pages = {531–544},
numpages = {14},
keywords = {inconsistency, reference counting, static analysis}
}

@inproceedings{10.1145/2872362.2872389,
author = {Mao, Junjie and Chen, Yu and Xiao, Qixue and Shi, Yuanchun},
title = {RID: Finding Reference Count Bugs with Inconsistent Path Pair Checking},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872389},
doi = {10.1145/2872362.2872389},
abstract = {Reference counts are widely used in OS kernels for resource management. However, reference counts are not trivial to be used correctly in large scale programs because it is left to developers to make sure that an increment to a reference count is always paired with a decrement. This paper proposes inconsistent path pair checking, a novel technique that can statically discover bugs related to reference counts without knowing how reference counts should be changed in a function. A prototype called RID is implemented and evaluations show that RID can discover more than 80 bugs which were confirmed by the developers in the latest Linux kernel. The results also show that RID tends to reveal bugs caused by developers' misunderstanding on API specifications or error conditions that are not handled properly.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {531–544},
numpages = {14},
keywords = {inconsistency, reference counting, static analysis},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252404,
author = {Witchel, Emmett},
title = {Session details: Session 6B: OS Optimizations},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252404},
doi = {10.1145/3252404},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872391,
author = {Lin, Xiaofeng and Chen, Yu and Li, Xiaodong and Mao, Junjie and He, Jiaquan and Xu, Wei and Shi, Yuanchun},
title = {Scalable Kernel TCP Design and Implementation for Short-Lived Connections},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872391},
doi = {10.1145/2980024.2872391},
abstract = {With the rapid growth of network bandwidth, increases in CPU cores on a single machine, and application API models demanding more short-lived connections, a scalable TCP stack is performance-critical. Although many clean-state designs have been proposed, production environments still call for a bottom-up parallel TCP stack design that is backward-compatible with existing applications.We present Fastsocket, a BSD Socket-compatible and scalable kernel socket design, which achieves table-level connection partition in TCP stack and guarantees connection locality for both passive and active connections. Fastsocket architecture is a ground up partition design, from NIC interrupts all the way up to applications, which naturally eliminates various lock contentions in the entire stack. Moreover, Fastsocket maintains the full functionality of the kernel TCP stack and BSD-socket-compatible API, and thus applications need no modifications.Our evaluations show that Fastsocket achieves a speedup of 20.4x on a 24-core machine under a workload of short-lived connections, outperforming the state-of-the-art Linux kernel TCP implementations. When scaling up to 24 CPU cores, Fastsocket increases the throughput of Nginx and HAProxy by 267\% and 621\% respectively compared with the base Linux kernel. We also demonstrate that Fastsocket can achieve scalability and preserve BSD socket API at the same time. Fastsocket is already deployed in the production environment of Sina WeiBo, serving 50 million daily active users and billions of requests per day.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {339–352},
numpages = {14},
keywords = {TCP/IP, multicore system, operating system}
}

@article{10.1145/2954679.2872391,
author = {Lin, Xiaofeng and Chen, Yu and Li, Xiaodong and Mao, Junjie and He, Jiaquan and Xu, Wei and Shi, Yuanchun},
title = {Scalable Kernel TCP Design and Implementation for Short-Lived Connections},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872391},
doi = {10.1145/2954679.2872391},
abstract = {With the rapid growth of network bandwidth, increases in CPU cores on a single machine, and application API models demanding more short-lived connections, a scalable TCP stack is performance-critical. Although many clean-state designs have been proposed, production environments still call for a bottom-up parallel TCP stack design that is backward-compatible with existing applications.We present Fastsocket, a BSD Socket-compatible and scalable kernel socket design, which achieves table-level connection partition in TCP stack and guarantees connection locality for both passive and active connections. Fastsocket architecture is a ground up partition design, from NIC interrupts all the way up to applications, which naturally eliminates various lock contentions in the entire stack. Moreover, Fastsocket maintains the full functionality of the kernel TCP stack and BSD-socket-compatible API, and thus applications need no modifications.Our evaluations show that Fastsocket achieves a speedup of 20.4x on a 24-core machine under a workload of short-lived connections, outperforming the state-of-the-art Linux kernel TCP implementations. When scaling up to 24 CPU cores, Fastsocket increases the throughput of Nginx and HAProxy by 267\% and 621\% respectively compared with the base Linux kernel. We also demonstrate that Fastsocket can achieve scalability and preserve BSD socket API at the same time. Fastsocket is already deployed in the production environment of Sina WeiBo, serving 50 million daily active users and billions of requests per day.},
journal = {SIGPLAN Not.},
month = mar,
pages = {339–352},
numpages = {14},
keywords = {TCP/IP, multicore system, operating system}
}

@inproceedings{10.1145/2872362.2872391,
author = {Lin, Xiaofeng and Chen, Yu and Li, Xiaodong and Mao, Junjie and He, Jiaquan and Xu, Wei and Shi, Yuanchun},
title = {Scalable Kernel TCP Design and Implementation for Short-Lived Connections},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872391},
doi = {10.1145/2872362.2872391},
abstract = {With the rapid growth of network bandwidth, increases in CPU cores on a single machine, and application API models demanding more short-lived connections, a scalable TCP stack is performance-critical. Although many clean-state designs have been proposed, production environments still call for a bottom-up parallel TCP stack design that is backward-compatible with existing applications.We present Fastsocket, a BSD Socket-compatible and scalable kernel socket design, which achieves table-level connection partition in TCP stack and guarantees connection locality for both passive and active connections. Fastsocket architecture is a ground up partition design, from NIC interrupts all the way up to applications, which naturally eliminates various lock contentions in the entire stack. Moreover, Fastsocket maintains the full functionality of the kernel TCP stack and BSD-socket-compatible API, and thus applications need no modifications.Our evaluations show that Fastsocket achieves a speedup of 20.4x on a 24-core machine under a workload of short-lived connections, outperforming the state-of-the-art Linux kernel TCP implementations. When scaling up to 24 CPU cores, Fastsocket increases the throughput of Nginx and HAProxy by 267\% and 621\% respectively compared with the base Linux kernel. We also demonstrate that Fastsocket can achieve scalability and preserve BSD socket API at the same time. Fastsocket is already deployed in the production environment of Sina WeiBo, serving 50 million daily active users and billions of requests per day.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {339–352},
numpages = {14},
keywords = {TCP/IP, multicore system, operating system},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872366,
author = {El Hajj, Izzat and Merritt, Alexander and Zellweger, Gerd and Milojicic, Dejan and Achermann, Reto and Faraboschi, Paolo and Hwu, Wen-mei and Roscoe, Timothy and Schwan, Karsten},
title = {SpaceJMP: Programming with Multiple Virtual Address Spaces},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872366},
doi = {10.1145/2954679.2872366},
abstract = {Memory-centric computing demands careful organization of the virtual address space, but traditional methods for doing so are inflexible and inefficient. If an application wishes to address larger physical memory than virtual address bits allow, if it wishes to maintain pointer-based data structures beyond process lifetimes, or if it wishes to share large amounts of memory across simultaneously executing processes, legacy interfaces for managing the address space are cumbersome and often incur excessive overheads. We propose a new operating system design that promotes virtual address spaces to first-class citizens, enabling process threads to attach to, detach from, and switch between multiple virtual address spaces. Our work enables data-centric applications to utilize vast physical memory beyond the virtual range, represent persistent pointer-rich data structures without special pointer representations, and share large amounts of memory between processes efficiently.We describe our prototype implementations in the DragonFly BSD and Barrelfish operating systems. We also present programming semantics and a compiler transformation to detect unsafe pointer usage. We demonstrate the benefits of our work on data-intensive applications such as the GUPS benchmark, the SAMTools genomics workflow, and the Redis key-value store.},
journal = {SIGPLAN Not.},
month = mar,
pages = {353–368},
numpages = {16},
keywords = {DRAM, NVM, address spaces, memory-centric computing, virtual memory}
}

@article{10.1145/2980024.2872366,
author = {El Hajj, Izzat and Merritt, Alexander and Zellweger, Gerd and Milojicic, Dejan and Achermann, Reto and Faraboschi, Paolo and Hwu, Wen-mei and Roscoe, Timothy and Schwan, Karsten},
title = {SpaceJMP: Programming with Multiple Virtual Address Spaces},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872366},
doi = {10.1145/2980024.2872366},
abstract = {Memory-centric computing demands careful organization of the virtual address space, but traditional methods for doing so are inflexible and inefficient. If an application wishes to address larger physical memory than virtual address bits allow, if it wishes to maintain pointer-based data structures beyond process lifetimes, or if it wishes to share large amounts of memory across simultaneously executing processes, legacy interfaces for managing the address space are cumbersome and often incur excessive overheads. We propose a new operating system design that promotes virtual address spaces to first-class citizens, enabling process threads to attach to, detach from, and switch between multiple virtual address spaces. Our work enables data-centric applications to utilize vast physical memory beyond the virtual range, represent persistent pointer-rich data structures without special pointer representations, and share large amounts of memory between processes efficiently.We describe our prototype implementations in the DragonFly BSD and Barrelfish operating systems. We also present programming semantics and a compiler transformation to detect unsafe pointer usage. We demonstrate the benefits of our work on data-intensive applications such as the GUPS benchmark, the SAMTools genomics workflow, and the Redis key-value store.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {353–368},
numpages = {16},
keywords = {virtual memory, memory-centric computing, address spaces, NVM, DRAM}
}

@inproceedings{10.1145/2872362.2872366,
author = {El Hajj, Izzat and Merritt, Alexander and Zellweger, Gerd and Milojicic, Dejan and Achermann, Reto and Faraboschi, Paolo and Hwu, Wen-mei and Roscoe, Timothy and Schwan, Karsten},
title = {SpaceJMP: Programming with Multiple Virtual Address Spaces},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872366},
doi = {10.1145/2872362.2872366},
abstract = {Memory-centric computing demands careful organization of the virtual address space, but traditional methods for doing so are inflexible and inefficient. If an application wishes to address larger physical memory than virtual address bits allow, if it wishes to maintain pointer-based data structures beyond process lifetimes, or if it wishes to share large amounts of memory across simultaneously executing processes, legacy interfaces for managing the address space are cumbersome and often incur excessive overheads. We propose a new operating system design that promotes virtual address spaces to first-class citizens, enabling process threads to attach to, detach from, and switch between multiple virtual address spaces. Our work enables data-centric applications to utilize vast physical memory beyond the virtual range, represent persistent pointer-rich data structures without special pointer representations, and share large amounts of memory between processes efficiently.We describe our prototype implementations in the DragonFly BSD and Barrelfish operating systems. We also present programming semantics and a compiler transformation to detect unsafe pointer usage. We demonstrate the benefits of our work on data-intensive applications such as the GUPS benchmark, the SAMTools genomics workflow, and the Redis key-value store.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {353–368},
numpages = {16},
keywords = {DRAM, NVM, address spaces, memory-centric computing, virtual memory},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872401,
author = {Lin, Felix Xiaozhu and Liu, Xu},
title = {memif: Towards Programming Heterogeneous Memory Asynchronously},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872401},
doi = {10.1145/2954679.2872401},
abstract = {To harness a heterogeneous memory hierarchy, it is advantageous to integrate application knowledge in guiding frequent memory move, i.e., replicating or migrating virtual memory regions. To this end, we present memif, a protected OS service for asynchronous, hardware-accelerated memory move. Compared to the state of the art -- page migration in Linux, memif incurs low overhead and low latency; in order to do so, it not only redefines the semantics of kernel interface but also overhauls the underlying mechanisms, including request/completion management, race handling, and DMA engine configuration. We implement memif in Linux for a server-class system-on-chip that features heterogeneous memories. Compared to the current Linux page migration, memif reduces CPU usage by up to 15\% for small pages and by up to 38x for large pages; in continuously serving requests, memif has no need for request batching and reduces latency by up to 63\%. By crafting a small runtime atop memif, we improve the throughputs for a set of streaming workloads by up to 33\%. Overall, memif has opened the door to software management of heterogeneous memory.},
journal = {SIGPLAN Not.},
month = mar,
pages = {369–383},
numpages = {15},
keywords = {data-intensive computing, heterogeneous memory, operating systems}
}

@article{10.1145/2980024.2872401,
author = {Lin, Felix Xiaozhu and Liu, Xu},
title = {memif: Towards Programming Heterogeneous Memory Asynchronously},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872401},
doi = {10.1145/2980024.2872401},
abstract = {To harness a heterogeneous memory hierarchy, it is advantageous to integrate application knowledge in guiding frequent memory move, i.e., replicating or migrating virtual memory regions. To this end, we present memif, a protected OS service for asynchronous, hardware-accelerated memory move. Compared to the state of the art -- page migration in Linux, memif incurs low overhead and low latency; in order to do so, it not only redefines the semantics of kernel interface but also overhauls the underlying mechanisms, including request/completion management, race handling, and DMA engine configuration. We implement memif in Linux for a server-class system-on-chip that features heterogeneous memories. Compared to the current Linux page migration, memif reduces CPU usage by up to 15\% for small pages and by up to 38x for large pages; in continuously serving requests, memif has no need for request batching and reduces latency by up to 63\%. By crafting a small runtime atop memif, we improve the throughputs for a set of streaming workloads by up to 33\%. Overall, memif has opened the door to software management of heterogeneous memory.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {369–383},
numpages = {15},
keywords = {operating systems, heterogeneous memory, data-intensive computing}
}

@inproceedings{10.1145/2872362.2872401,
author = {Lin, Felix Xiaozhu and Liu, Xu},
title = {memif: Towards Programming Heterogeneous Memory Asynchronously},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872401},
doi = {10.1145/2872362.2872401},
abstract = {To harness a heterogeneous memory hierarchy, it is advantageous to integrate application knowledge in guiding frequent memory move, i.e., replicating or migrating virtual memory regions. To this end, we present memif, a protected OS service for asynchronous, hardware-accelerated memory move. Compared to the state of the art -- page migration in Linux, memif incurs low overhead and low latency; in order to do so, it not only redefines the semantics of kernel interface but also overhauls the underlying mechanisms, including request/completion management, race handling, and DMA engine configuration. We implement memif in Linux for a server-class system-on-chip that features heterogeneous memories. Compared to the current Linux page migration, memif reduces CPU usage by up to 15\% for small pages and by up to 38x for large pages; in continuously serving requests, memif has no need for request batching and reduces latency by up to 63\%. By crafting a small runtime atop memif, we improve the throughputs for a set of streaming workloads by up to 33\%. Overall, memif has opened the door to software management of heterogeneous memory.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {369–383},
numpages = {15},
keywords = {data-intensive computing, heterogeneous memory, operating systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252405,
author = {Witchel, Emmett},
title = {Session details: Debate},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252405},
doi = {10.1145/3252405},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2876511,
author = {Witchel, Emmett},
title = {Programmer Productivity in a World of Mushy Interfaces: Challenges of the Post-ISA Reality},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2876511},
doi = {10.1145/2980024.2876511},
abstract = {Since 1964, we had the notion that the instruction set architecture (ISA) is a useful and fairly opaque abstraction layer between hardware and software. Software rode hardware's performance wave while remaining gloriously oblivious to hardware's growing complexity. Unfortunately, the jig is up. We still have ISAs, but the abstraction no longer offers seamless portability---parallel software needs to be tuned for different core counts, and heterogeneous processing elements (CPUs, GPUs, accelerators) further complicate programmability. We are better at building large-scale heterogeneous processors than we are at programming them. Maintaining software across multiple current platforms is difficult and porting to future platforms is also difficult. There have been many technical responses: virtual ISAs (e.g., NVIDIA's PTX), higher-level programming interfaces (e.g., CUDA or OpenCL), and late-stage compilation and platform-specific tailoring (e.g., Android ART), etc.A team of opinionated experts, drawn from the three ASPLOS communities will examine the problem of programmer productivity in the post-ISA world, first from the perspective of their area of expertise and then noting the contributions from the other two communities. What research will save us and how? This wide-ranging debate will frame important research areas for future work while being grounded in frank discussion about what has succeeded in the past. Attendees can expect actionable insight into important research issues as well an entertaining discussion.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {591},
numpages = {1},
keywords = {instruction set architecture, portability, programmer productivity}
}

@article{10.1145/2954679.2876511,
author = {Witchel, Emmett},
title = {Programmer Productivity in a World of Mushy Interfaces: Challenges of the Post-ISA Reality},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2876511},
doi = {10.1145/2954679.2876511},
abstract = {Since 1964, we had the notion that the instruction set architecture (ISA) is a useful and fairly opaque abstraction layer between hardware and software. Software rode hardware's performance wave while remaining gloriously oblivious to hardware's growing complexity. Unfortunately, the jig is up. We still have ISAs, but the abstraction no longer offers seamless portability---parallel software needs to be tuned for different core counts, and heterogeneous processing elements (CPUs, GPUs, accelerators) further complicate programmability. We are better at building large-scale heterogeneous processors than we are at programming them. Maintaining software across multiple current platforms is difficult and porting to future platforms is also difficult. There have been many technical responses: virtual ISAs (e.g., NVIDIA's PTX), higher-level programming interfaces (e.g., CUDA or OpenCL), and late-stage compilation and platform-specific tailoring (e.g., Android ART), etc.A team of opinionated experts, drawn from the three ASPLOS communities will examine the problem of programmer productivity in the post-ISA world, first from the perspective of their area of expertise and then noting the contributions from the other two communities. What research will save us and how? This wide-ranging debate will frame important research areas for future work while being grounded in frank discussion about what has succeeded in the past. Attendees can expect actionable insight into important research issues as well an entertaining discussion.},
journal = {SIGPLAN Not.},
month = mar,
pages = {591},
numpages = {1},
keywords = {instruction set architecture, portability, programmer productivity}
}

@inproceedings{10.1145/2872362.2876511,
author = {Witchel, Emmett},
title = {Programmer Productivity in a World of Mushy Interfaces: Challenges of the Post-ISA Reality},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2876511},
doi = {10.1145/2872362.2876511},
abstract = {Since 1964, we had the notion that the instruction set architecture (ISA) is a useful and fairly opaque abstraction layer between hardware and software. Software rode hardware's performance wave while remaining gloriously oblivious to hardware's growing complexity. Unfortunately, the jig is up. We still have ISAs, but the abstraction no longer offers seamless portability---parallel software needs to be tuned for different core counts, and heterogeneous processing elements (CPUs, GPUs, accelerators) further complicate programmability. We are better at building large-scale heterogeneous processors than we are at programming them. Maintaining software across multiple current platforms is difficult and porting to future platforms is also difficult. There have been many technical responses: virtual ISAs (e.g., NVIDIA's PTX), higher-level programming interfaces (e.g., CUDA or OpenCL), and late-stage compilation and platform-specific tailoring (e.g., Android ART), etc.A team of opinionated experts, drawn from the three ASPLOS communities will examine the problem of programmer productivity in the post-ISA world, first from the perspective of their area of expertise and then noting the contributions from the other two communities. What research will save us and how? This wide-ranging debate will frame important research areas for future work while being grounded in frank discussion about what has succeeded in the past. Attendees can expect actionable insight into important research issues as well an entertaining discussion.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {591},
numpages = {1},
keywords = {instruction set architecture, portability, programmer productivity},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252406,
author = {Tullsen, Dean},
title = {Session details: Session 7A: Non-traditional Computer Systems},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252406},
doi = {10.1145/3252406},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872393,
author = {Angstadt, Kevin and Weimer, Westley and Skadron, Kevin},
title = {RAPID Programming of Pattern-Recognition Processors},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872393},
doi = {10.1145/2954679.2872393},
abstract = {We present RAPID, a high-level programming language and combined imperative and declarative model for programming pattern-recognition processors, such as Micron's Automata Processor (AP). The AP is a novel, non-Von Neumann architecture for direct execution of non-deterministic finite automata (NFAs), and has been demonstrated to provide substantial speedup for a variety of data-processing applications. RAPID is clear, maintainable, concise, and efficient both at compile and run time. Language features, such as code abstraction and parallel control structures, map well to pattern-matching problems, providing clarity and maintainability. For generation of efficient runtime code, we present algorithms to convert RAPID programs into finite automata. Further, we introduce a tessellation technique for configuring the AP, which significantly reduces compile time, increases programmer productivity, and improves maintainability. We evaluate five RAPID programs against custom, baseline implementations previously demonstrated to be significantly accelerated by the AP. We find that RAPID programs are much shorter in length, are expressible at a higher level of abstraction than their handcrafted counterparts, and yield generated code that is often more compact. In addition, our tessellation technique for configuring the AP has comparable device utilization to, and results in compilation that is up to four orders of magnitude faster than, current solutions.},
journal = {SIGPLAN Not.},
month = mar,
pages = {593–605},
numpages = {13},
keywords = {MISD, accelerators, automata processor}
}

@article{10.1145/2980024.2872393,
author = {Angstadt, Kevin and Weimer, Westley and Skadron, Kevin},
title = {RAPID Programming of Pattern-Recognition Processors},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872393},
doi = {10.1145/2980024.2872393},
abstract = {We present RAPID, a high-level programming language and combined imperative and declarative model for programming pattern-recognition processors, such as Micron's Automata Processor (AP). The AP is a novel, non-Von Neumann architecture for direct execution of non-deterministic finite automata (NFAs), and has been demonstrated to provide substantial speedup for a variety of data-processing applications. RAPID is clear, maintainable, concise, and efficient both at compile and run time. Language features, such as code abstraction and parallel control structures, map well to pattern-matching problems, providing clarity and maintainability. For generation of efficient runtime code, we present algorithms to convert RAPID programs into finite automata. Further, we introduce a tessellation technique for configuring the AP, which significantly reduces compile time, increases programmer productivity, and improves maintainability. We evaluate five RAPID programs against custom, baseline implementations previously demonstrated to be significantly accelerated by the AP. We find that RAPID programs are much shorter in length, are expressible at a higher level of abstraction than their handcrafted counterparts, and yield generated code that is often more compact. In addition, our tessellation technique for configuring the AP has comparable device utilization to, and results in compilation that is up to four orders of magnitude faster than, current solutions.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {593–605},
numpages = {13},
keywords = {MISD, accelerators, automata processor}
}

@inproceedings{10.1145/2872362.2872393,
author = {Angstadt, Kevin and Weimer, Westley and Skadron, Kevin},
title = {RAPID Programming of Pattern-Recognition Processors},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872393},
doi = {10.1145/2872362.2872393},
abstract = {We present RAPID, a high-level programming language and combined imperative and declarative model for programming pattern-recognition processors, such as Micron's Automata Processor (AP). The AP is a novel, non-Von Neumann architecture for direct execution of non-deterministic finite automata (NFAs), and has been demonstrated to provide substantial speedup for a variety of data-processing applications. RAPID is clear, maintainable, concise, and efficient both at compile and run time. Language features, such as code abstraction and parallel control structures, map well to pattern-matching problems, providing clarity and maintainability. For generation of efficient runtime code, we present algorithms to convert RAPID programs into finite automata. Further, we introduce a tessellation technique for configuring the AP, which significantly reduces compile time, increases programmer productivity, and improves maintainability. We evaluate five RAPID programs against custom, baseline implementations previously demonstrated to be significantly accelerated by the AP. We find that RAPID programs are much shorter in length, are expressible at a higher level of abstraction than their handcrafted counterparts, and yield generated code that is often more compact. In addition, our tessellation technique for configuring the AP has comparable device utilization to, and results in compilation that is up to four orders of magnitude faster than, current solutions.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {593–605},
numpages = {13},
keywords = {MISD, accelerators, automata processor},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872402,
author = {Sui, Xin and Lenharth, Andrew and Fussell, Donald S. and Pingali, Keshav},
title = {Proactive Control of Approximate Programs},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872402},
doi = {10.1145/2980024.2872402},
abstract = {Approximate computing trades off accuracy of results for resources such as energy or computing time. There is a large and rapidly growing literature on approximate computing that has focused mostly on showing the benefits of approximate computing. However, we know relatively little about how to control approximation in a disciplined way. In this paper, we address the problem of controlling approximation for non-streaming programs that have a set of "knobs" that can be dialed up or down to control the level of approximation of different components in the program. We formulate this control problem as a constrained optimization problem, and describe a system called Capri that uses machine learning to learn cost and error models for the program, and uses these models to determine, for a desired level of approximation, knob settings that optimize metrics such as running time or energy usage. Experimental results with complex benchmarks from different problem domains demonstrate the effectiveness of this approach.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {607–621},
numpages = {15},
keywords = {approximate computing, constrained optimization, energy optimization, machine learning, open-loop control}
}

@article{10.1145/2954679.2872402,
author = {Sui, Xin and Lenharth, Andrew and Fussell, Donald S. and Pingali, Keshav},
title = {Proactive Control of Approximate Programs},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872402},
doi = {10.1145/2954679.2872402},
abstract = {Approximate computing trades off accuracy of results for resources such as energy or computing time. There is a large and rapidly growing literature on approximate computing that has focused mostly on showing the benefits of approximate computing. However, we know relatively little about how to control approximation in a disciplined way. In this paper, we address the problem of controlling approximation for non-streaming programs that have a set of "knobs" that can be dialed up or down to control the level of approximation of different components in the program. We formulate this control problem as a constrained optimization problem, and describe a system called Capri that uses machine learning to learn cost and error models for the program, and uses these models to determine, for a desired level of approximation, knob settings that optimize metrics such as running time or energy usage. Experimental results with complex benchmarks from different problem domains demonstrate the effectiveness of this approach.},
journal = {SIGPLAN Not.},
month = mar,
pages = {607–621},
numpages = {15},
keywords = {approximate computing, constrained optimization, energy optimization, machine learning, open-loop control}
}

@inproceedings{10.1145/2872362.2872402,
author = {Sui, Xin and Lenharth, Andrew and Fussell, Donald S. and Pingali, Keshav},
title = {Proactive Control of Approximate Programs},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872402},
doi = {10.1145/2872362.2872402},
abstract = {Approximate computing trades off accuracy of results for resources such as energy or computing time. There is a large and rapidly growing literature on approximate computing that has focused mostly on showing the benefits of approximate computing. However, we know relatively little about how to control approximation in a disciplined way. In this paper, we address the problem of controlling approximation for non-streaming programs that have a set of "knobs" that can be dialed up or down to control the level of approximation of different components in the program. We formulate this control problem as a constrained optimization problem, and describe a system called Capri that uses machine learning to learn cost and error models for the program, and uses these models to determine, for a desired level of approximation, knob settings that optimize metrics such as running time or energy usage. Experimental results with complex benchmarks from different problem domains demonstrate the effectiveness of this approach.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {607–621},
numpages = {15},
keywords = {approximate computing, constrained optimization, energy optimization, machine learning, open-loop control},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872376,
author = {Park, Jongse and Amaro, Emmanuel and Mahajan, Divya and Thwaites, Bradley and Esmaeilzadeh, Hadi},
title = {AxGames: Towards Crowdsourcing Quality Target Determination in Approximate Computing},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872376},
doi = {10.1145/2980024.2872376},
abstract = {Approximate computing trades quality of application output for higher efficiency and performance. Approximation is useful only if its impact on application output quality is acceptable to the users. However, there is a lack of systematic solutions and studies that explore users' perspective on the effects of approximation. In this paper, we seek to provide one such solution for the developers to probe and discover the boundary of quality loss that most users will deem acceptable. We propose AxGames, a crowdsourced solution that enables developers to readily infer a statistical common ground from the general public through three entertaining games. The users engage in these games by betting on their opinion about the quality loss of the final output while the AxGames framework collects statistics about their perceptions. The framework then statistically analyzes the results to determine the acceptable levels of quality for a pair of (application, approximation technique). The three games are designed such that they effectively capture quality requirements with various tradeoffs and contexts. To evaluate AxGames, we examine seven diverse applications that produce user perceptible outputs and cover a wide range of domains, including image processing, optical character recognition, speech to text conversion, and audio processing. We recruit 700 participants/users through Amazon's Mechanical Turk to play the games that collect statistics about their perception on different levels of quality. Subsequently, the AxGames framework uses the Clopper-Pearson exact method, which computes a binomial proportion confidence interval, to analyze the collected statistics for each level of quality. Using this analysis, AxGames can statistically project the quality level that satisfies a given percentage of users. The developers can use these statistical projections to tune the level of approximation based on the user experience. We find that the level of acceptable quality loss significantly varies across applications. For instance, to satisfy 90\% of users, the level of acceptable quality loss is 2\% for one application (image processing) and 26\% for another (audio processing). Moreover, the pattern with which the crowd responds to approximation takes significantly different shape and form depending on the class of applications. These results confirm the necessity of solutions that systematically explore the effect of approximation on the end user experience.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {623–636},
numpages = {14},
keywords = {approximate computing, crowdsourcing, energy-efficient computing, games-with-a-purpose}
}

@article{10.1145/2954679.2872376,
author = {Park, Jongse and Amaro, Emmanuel and Mahajan, Divya and Thwaites, Bradley and Esmaeilzadeh, Hadi},
title = {AxGames: Towards Crowdsourcing Quality Target Determination in Approximate Computing},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872376},
doi = {10.1145/2954679.2872376},
abstract = {Approximate computing trades quality of application output for higher efficiency and performance. Approximation is useful only if its impact on application output quality is acceptable to the users. However, there is a lack of systematic solutions and studies that explore users' perspective on the effects of approximation. In this paper, we seek to provide one such solution for the developers to probe and discover the boundary of quality loss that most users will deem acceptable. We propose AxGames, a crowdsourced solution that enables developers to readily infer a statistical common ground from the general public through three entertaining games. The users engage in these games by betting on their opinion about the quality loss of the final output while the AxGames framework collects statistics about their perceptions. The framework then statistically analyzes the results to determine the acceptable levels of quality for a pair of (application, approximation technique). The three games are designed such that they effectively capture quality requirements with various tradeoffs and contexts. To evaluate AxGames, we examine seven diverse applications that produce user perceptible outputs and cover a wide range of domains, including image processing, optical character recognition, speech to text conversion, and audio processing. We recruit 700 participants/users through Amazon's Mechanical Turk to play the games that collect statistics about their perception on different levels of quality. Subsequently, the AxGames framework uses the Clopper-Pearson exact method, which computes a binomial proportion confidence interval, to analyze the collected statistics for each level of quality. Using this analysis, AxGames can statistically project the quality level that satisfies a given percentage of users. The developers can use these statistical projections to tune the level of approximation based on the user experience. We find that the level of acceptable quality loss significantly varies across applications. For instance, to satisfy 90\% of users, the level of acceptable quality loss is 2\% for one application (image processing) and 26\% for another (audio processing). Moreover, the pattern with which the crowd responds to approximation takes significantly different shape and form depending on the class of applications. These results confirm the necessity of solutions that systematically explore the effect of approximation on the end user experience.},
journal = {SIGPLAN Not.},
month = mar,
pages = {623–636},
numpages = {14},
keywords = {approximate computing, crowdsourcing, energy-efficient computing, games-with-a-purpose}
}

@inproceedings{10.1145/2872362.2872376,
author = {Park, Jongse and Amaro, Emmanuel and Mahajan, Divya and Thwaites, Bradley and Esmaeilzadeh, Hadi},
title = {AxGames: Towards Crowdsourcing Quality Target Determination in Approximate Computing},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872376},
doi = {10.1145/2872362.2872376},
abstract = {Approximate computing trades quality of application output for higher efficiency and performance. Approximation is useful only if its impact on application output quality is acceptable to the users. However, there is a lack of systematic solutions and studies that explore users' perspective on the effects of approximation. In this paper, we seek to provide one such solution for the developers to probe and discover the boundary of quality loss that most users will deem acceptable. We propose AxGames, a crowdsourced solution that enables developers to readily infer a statistical common ground from the general public through three entertaining games. The users engage in these games by betting on their opinion about the quality loss of the final output while the AxGames framework collects statistics about their perceptions. The framework then statistically analyzes the results to determine the acceptable levels of quality for a pair of (application, approximation technique). The three games are designed such that they effectively capture quality requirements with various tradeoffs and contexts. To evaluate AxGames, we examine seven diverse applications that produce user perceptible outputs and cover a wide range of domains, including image processing, optical character recognition, speech to text conversion, and audio processing. We recruit 700 participants/users through Amazon's Mechanical Turk to play the games that collect statistics about their perception on different levels of quality. Subsequently, the AxGames framework uses the Clopper-Pearson exact method, which computes a binomial proportion confidence interval, to analyze the collected statistics for each level of quality. Using this analysis, AxGames can statistically project the quality level that satisfies a given percentage of users. The developers can use these statistical projections to tune the level of approximation based on the user experience. We find that the level of acceptable quality loss significantly varies across applications. For instance, to satisfy 90\% of users, the level of acceptable quality loss is 2\% for one application (image processing) and 26\% for another (audio processing). Moreover, the pattern with which the crowd responds to approximation takes significantly different shape and form depending on the class of applications. These results confirm the necessity of solutions that systematically explore the effect of approximation on the end user experience.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {623–636},
numpages = {14},
keywords = {approximate computing, crowdsourcing, energy-efficient computing, games-with-a-purpose},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872397,
author = {Bornholt, James and Lopez, Randolph and Carmean, Douglas M. and Ceze, Luis and Seelig, Georg and Strauss, Karin},
title = {A DNA-Based Archival Storage System},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872397},
doi = {10.1145/2954679.2872397},
abstract = {Demand for data storage is growing exponentially, but the capacity of existing storage media is not keeping up. Using DNA to archive data is an attractive possibility because it is extremely dense, with a raw limit of 1 exabyte/mm3 (109 GB/mm3), and long-lasting, with observed half-life of over 500 years. This paper presents an architecture for a DNA-based archival storage system. It is structured as a key-value store, and leverages common biochemical techniques to provide random access. We also propose a new encoding scheme that offers controllable redundancy, trading off reliability for density. We demonstrate feasibility, random access, and robustness of the proposed encoding with wet lab experiments involving 151 kB of synthesized DNA and a 42 kB random-access subset, and simulation experiments of larger sets calibrated to the wet lab experiments. Finally, we highlight trends in biotechnology that indicate the impending practicality of DNA storage for much larger datasets.},
journal = {SIGPLAN Not.},
month = mar,
pages = {637–649},
numpages = {13},
keywords = {DNA, archival storage, molecular computing}
}

@article{10.1145/2980024.2872397,
author = {Bornholt, James and Lopez, Randolph and Carmean, Douglas M. and Ceze, Luis and Seelig, Georg and Strauss, Karin},
title = {A DNA-Based Archival Storage System},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872397},
doi = {10.1145/2980024.2872397},
abstract = {Demand for data storage is growing exponentially, but the capacity of existing storage media is not keeping up. Using DNA to archive data is an attractive possibility because it is extremely dense, with a raw limit of 1 exabyte/mm3 (109 GB/mm3), and long-lasting, with observed half-life of over 500 years. This paper presents an architecture for a DNA-based archival storage system. It is structured as a key-value store, and leverages common biochemical techniques to provide random access. We also propose a new encoding scheme that offers controllable redundancy, trading off reliability for density. We demonstrate feasibility, random access, and robustness of the proposed encoding with wet lab experiments involving 151 kB of synthesized DNA and a 42 kB random-access subset, and simulation experiments of larger sets calibrated to the wet lab experiments. Finally, we highlight trends in biotechnology that indicate the impending practicality of DNA storage for much larger datasets.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {637–649},
numpages = {13},
keywords = {DNA, archival storage, molecular computing}
}

@inproceedings{10.1145/2872362.2872397,
author = {Bornholt, James and Lopez, Randolph and Carmean, Douglas M. and Ceze, Luis and Seelig, Georg and Strauss, Karin},
title = {A DNA-Based Archival Storage System},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872397},
doi = {10.1145/2872362.2872397},
abstract = {Demand for data storage is growing exponentially, but the capacity of existing storage media is not keeping up. Using DNA to archive data is an attractive possibility because it is extremely dense, with a raw limit of 1 exabyte/mm3 (109 GB/mm3), and long-lasting, with observed half-life of over 500 years. This paper presents an architecture for a DNA-based archival storage system. It is structured as a key-value store, and leverages common biochemical techniques to provide random access. We also propose a new encoding scheme that offers controllable redundancy, trading off reliability for density. We demonstrate feasibility, random access, and robustness of the proposed encoding with wet lab experiments involving 151 kB of synthesized DNA and a 42 kB random-access subset, and simulation experiments of larger sets calibrated to the wet lab experiments. Finally, we highlight trends in biotechnology that indicate the impending practicality of DNA storage for much larger datasets.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {637–649},
numpages = {13},
keywords = {DNA, archival storage, molecular computing},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252407,
author = {Torrellas, Josep},
title = {Session details: Session 7B: Heterogeneous Architectures and Accelerators II},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252407},
doi = {10.1145/3252407},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872415,
author = {Prabhakar, Raghu and Koeplinger, David and Brown, Kevin J. and Lee, HyoukJoong and De Sa, Christopher and Kozyrakis, Christos and Olukotun, Kunle},
title = {Generating Configurable Hardware from Parallel Patterns},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872415},
doi = {10.1145/2980024.2872415},
abstract = {In recent years the computing landscape has seen an increasing shift towards specialized accelerators. Field programmable gate arrays (FPGAs) are particularly promising for the implementation of these accelerators, as they offer significant performance and energy improvements over CPUs for a wide class of applications and are far more flexible than fixed-function ASICs. However, FPGAs are difficult to program. Traditional programming models for reconfigurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software languages but produce very efficient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efficient. Functional languages with parallel patterns are a better fit for hardware generation because they provide high-level abstractions to programmers with little experience in hardware design and avoid many of the problems faced when generating hardware from imperative languages. In this paper, we identify two important optimizations for using parallel patterns to generate efficient hardware: tiling and metapipelining. We present a general representation of tiled parallel patterns, and provide rules for automatically tiling patterns and generating metapipelines. We demonstrate experimentally that these optimizations result in speedups up to 39.4\texttimes{} on a set of benchmarks from the data analytics domain.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {651–665},
numpages = {15},
keywords = {FPGAs, hardware generation, metapipelining, parallel patterns, reconfigurable hardware, tiling}
}

@article{10.1145/2954679.2872415,
author = {Prabhakar, Raghu and Koeplinger, David and Brown, Kevin J. and Lee, HyoukJoong and De Sa, Christopher and Kozyrakis, Christos and Olukotun, Kunle},
title = {Generating Configurable Hardware from Parallel Patterns},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872415},
doi = {10.1145/2954679.2872415},
abstract = {In recent years the computing landscape has seen an increasing shift towards specialized accelerators. Field programmable gate arrays (FPGAs) are particularly promising for the implementation of these accelerators, as they offer significant performance and energy improvements over CPUs for a wide class of applications and are far more flexible than fixed-function ASICs. However, FPGAs are difficult to program. Traditional programming models for reconfigurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software languages but produce very efficient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efficient. Functional languages with parallel patterns are a better fit for hardware generation because they provide high-level abstractions to programmers with little experience in hardware design and avoid many of the problems faced when generating hardware from imperative languages. In this paper, we identify two important optimizations for using parallel patterns to generate efficient hardware: tiling and metapipelining. We present a general representation of tiled parallel patterns, and provide rules for automatically tiling patterns and generating metapipelines. We demonstrate experimentally that these optimizations result in speedups up to 39.4\texttimes{} on a set of benchmarks from the data analytics domain.},
journal = {SIGPLAN Not.},
month = mar,
pages = {651–665},
numpages = {15},
keywords = {FPGAs, hardware generation, metapipelining, parallel patterns, reconfigurable hardware, tiling}
}

@inproceedings{10.1145/2872362.2872415,
author = {Prabhakar, Raghu and Koeplinger, David and Brown, Kevin J. and Lee, HyoukJoong and De Sa, Christopher and Kozyrakis, Christos and Olukotun, Kunle},
title = {Generating Configurable Hardware from Parallel Patterns},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872415},
doi = {10.1145/2872362.2872415},
abstract = {In recent years the computing landscape has seen an increasing shift towards specialized accelerators. Field programmable gate arrays (FPGAs) are particularly promising for the implementation of these accelerators, as they offer significant performance and energy improvements over CPUs for a wide class of applications and are far more flexible than fixed-function ASICs. However, FPGAs are difficult to program. Traditional programming models for reconfigurable logic use low-level hardware description languages like Verilog and VHDL, which have none of the productivity features of modern software languages but produce very efficient designs, and low-level software languages like C and OpenCL coupled with high-level synthesis (HLS) tools that typically produce designs that are far less efficient. Functional languages with parallel patterns are a better fit for hardware generation because they provide high-level abstractions to programmers with little experience in hardware design and avoid many of the problems faced when generating hardware from imperative languages. In this paper, we identify two important optimizations for using parallel patterns to generate efficient hardware: tiling and metapipelining. We present a general representation of tiled parallel patterns, and provide rules for automatically tiling patterns and generating metapipelines. We demonstrate experimentally that these optimizations result in speedups up to 39.4\texttimes{} on a set of benchmarks from the data analytics domain.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {651–665},
numpages = {15},
keywords = {FPGAs, hardware generation, metapipelining, parallel patterns, reconfigurable hardware, tiling},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872373,
author = {Chang, Li-Wen and Kim, Hee-Seok and Hwu, Wen-mei W.},
title = {DySel: Lightweight Dynamic Selection for Kernel-based Data-parallel Programming Model},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872373},
doi = {10.1145/2954679.2872373},
abstract = {The rising pressure for simultaneously improving performance and reducing power is driving more diversity into all aspects of computing devices. An algorithm that is well-matched to the target hardware can run multiple times faster and more energy efficiently than one that is not. The problem is complicated by the fact that a program's input also affects the appropriate choice of algorithm. As a result, software developers have been faced with the challenge of determining the appropriate algorithm for each potential combination of target device and data. This paper presents DySel, a novel runtime system for automating such determination for kernel-based data parallel programming models such as OpenCL, CUDA, OpenACC, and C++AMP. These programming models cover many applications that demand high performance in mobile, cloud and high-performance computing. DySel systematically deploys candidate kernels on a small portion of the actual data to determine which achieves the best performance for the hardware-data combination. The test-deployment, referred to as micro-profiling, contributes to the final execution result and incurs less than 8\% of overhead in the worst observed case when compared to an oracle. We show four major use cases where DySel provides significantly more consistent performance without tedious effort from the developer.},
journal = {SIGPLAN Not.},
month = mar,
pages = {667–680},
numpages = {14},
keywords = {graphics processing unit, dynamic profiling}
}

@article{10.1145/2980024.2872373,
author = {Chang, Li-Wen and Kim, Hee-Seok and Hwu, Wen-mei W.},
title = {DySel: Lightweight Dynamic Selection for Kernel-based Data-parallel Programming Model},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872373},
doi = {10.1145/2980024.2872373},
abstract = {The rising pressure for simultaneously improving performance and reducing power is driving more diversity into all aspects of computing devices. An algorithm that is well-matched to the target hardware can run multiple times faster and more energy efficiently than one that is not. The problem is complicated by the fact that a program's input also affects the appropriate choice of algorithm. As a result, software developers have been faced with the challenge of determining the appropriate algorithm for each potential combination of target device and data. This paper presents DySel, a novel runtime system for automating such determination for kernel-based data parallel programming models such as OpenCL, CUDA, OpenACC, and C++AMP. These programming models cover many applications that demand high performance in mobile, cloud and high-performance computing. DySel systematically deploys candidate kernels on a small portion of the actual data to determine which achieves the best performance for the hardware-data combination. The test-deployment, referred to as micro-profiling, contributes to the final execution result and incurs less than 8\% of overhead in the worst observed case when compared to an oracle. We show four major use cases where DySel provides significantly more consistent performance without tedious effort from the developer.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {667–680},
numpages = {14},
keywords = {dynamic profiling, graphics processing unit}
}

@inproceedings{10.1145/2872362.2872373,
author = {Chang, Li-Wen and Kim, Hee-Seok and Hwu, Wen-mei W.},
title = {DySel: Lightweight Dynamic Selection for Kernel-based Data-parallel Programming Model},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872373},
doi = {10.1145/2872362.2872373},
abstract = {The rising pressure for simultaneously improving performance and reducing power is driving more diversity into all aspects of computing devices. An algorithm that is well-matched to the target hardware can run multiple times faster and more energy efficiently than one that is not. The problem is complicated by the fact that a program's input also affects the appropriate choice of algorithm. As a result, software developers have been faced with the challenge of determining the appropriate algorithm for each potential combination of target device and data. This paper presents DySel, a novel runtime system for automating such determination for kernel-based data parallel programming models such as OpenCL, CUDA, OpenACC, and C++AMP. These programming models cover many applications that demand high performance in mobile, cloud and high-performance computing. DySel systematically deploys candidate kernels on a small portion of the actual data to determine which achieves the best performance for the hardware-data combination. The test-deployment, referred to as micro-profiling, contributes to the final execution result and incurs less than 8\% of overhead in the worst observed case when compared to an oracle. We show four major use cases where DySel provides significantly more consistent performance without tedious effort from the developer.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {667–680},
numpages = {14},
keywords = {dynamic profiling, graphics processing unit},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872368,
author = {Chen, Quan and Yang, Hailong and Mars, Jason and Tang, Lingjia},
title = {Baymax: QoS Awareness and Increased Utilization for Non-Preemptive Accelerators in Warehouse Scale Computers},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872368},
doi = {10.1145/2954679.2872368},
abstract = {Modern warehouse-scale computers (WSCs) are being outfitted with accelerators to provide the significant compute required by emerging intelligent personal assistant (IPA) workloads such as voice recognition, image classification, and natural language processing. It is well known that the diurnal user access pattern of user-facing services provides a strong incentive to co-locate applications for better accelerator utilization and efficiency, and prior work has focused on enabling co-location on multicore processors. However, interference when co-locating applications on non-preemptive accelerators is fundamentally different than contention on multi-core CPUs and introduces a new set of challenges to reduce QoS violation. To address this open problem, we first identify the underlying causes for QoS violation in accelerator-outfitted servers. Our experiments show that queuing delay for the compute resources and PCI-e bandwidth contention for data transfer are the main two factors that contribute to the long tails of user-facing applications. We then present Baymax, a runtime system that orchestrates the execution of compute tasks from different applications and mitigates PCI-e bandwidth contention to deliver the required QoS for user-facing applications and increase the accelerator utilization. Using DjiNN, a deep neural network service, Sirius, an end-to-end IPA workload, and traditional applications on a Nvidia K40 GPU, our evaluation shows that Baymax improves the accelerator utilization by 91.3\% while achieving the desired 99\%-ile latency target for for user-facing applications. In fact, Baymax reduces the 99\%-ile latency of user-facing applications by up to 195x over default execution.},
journal = {SIGPLAN Not.},
month = mar,
pages = {681–696},
numpages = {16},
keywords = {non-preemptive accelerators, quality of service, scheduling, warehouse scale computers}
}

@article{10.1145/2980024.2872368,
author = {Chen, Quan and Yang, Hailong and Mars, Jason and Tang, Lingjia},
title = {Baymax: QoS Awareness and Increased Utilization for Non-Preemptive Accelerators in Warehouse Scale Computers},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872368},
doi = {10.1145/2980024.2872368},
abstract = {Modern warehouse-scale computers (WSCs) are being outfitted with accelerators to provide the significant compute required by emerging intelligent personal assistant (IPA) workloads such as voice recognition, image classification, and natural language processing. It is well known that the diurnal user access pattern of user-facing services provides a strong incentive to co-locate applications for better accelerator utilization and efficiency, and prior work has focused on enabling co-location on multicore processors. However, interference when co-locating applications on non-preemptive accelerators is fundamentally different than contention on multi-core CPUs and introduces a new set of challenges to reduce QoS violation. To address this open problem, we first identify the underlying causes for QoS violation in accelerator-outfitted servers. Our experiments show that queuing delay for the compute resources and PCI-e bandwidth contention for data transfer are the main two factors that contribute to the long tails of user-facing applications. We then present Baymax, a runtime system that orchestrates the execution of compute tasks from different applications and mitigates PCI-e bandwidth contention to deliver the required QoS for user-facing applications and increase the accelerator utilization. Using DjiNN, a deep neural network service, Sirius, an end-to-end IPA workload, and traditional applications on a Nvidia K40 GPU, our evaluation shows that Baymax improves the accelerator utilization by 91.3\% while achieving the desired 99\%-ile latency target for for user-facing applications. In fact, Baymax reduces the 99\%-ile latency of user-facing applications by up to 195x over default execution.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {681–696},
numpages = {16},
keywords = {non-preemptive accelerators, quality of service, scheduling, warehouse scale computers}
}

@inproceedings{10.1145/2872362.2872368,
author = {Chen, Quan and Yang, Hailong and Mars, Jason and Tang, Lingjia},
title = {Baymax: QoS Awareness and Increased Utilization for Non-Preemptive Accelerators in Warehouse Scale Computers},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872368},
doi = {10.1145/2872362.2872368},
abstract = {Modern warehouse-scale computers (WSCs) are being outfitted with accelerators to provide the significant compute required by emerging intelligent personal assistant (IPA) workloads such as voice recognition, image classification, and natural language processing. It is well known that the diurnal user access pattern of user-facing services provides a strong incentive to co-locate applications for better accelerator utilization and efficiency, and prior work has focused on enabling co-location on multicore processors. However, interference when co-locating applications on non-preemptive accelerators is fundamentally different than contention on multi-core CPUs and introduces a new set of challenges to reduce QoS violation. To address this open problem, we first identify the underlying causes for QoS violation in accelerator-outfitted servers. Our experiments show that queuing delay for the compute resources and PCI-e bandwidth contention for data transfer are the main two factors that contribute to the long tails of user-facing applications. We then present Baymax, a runtime system that orchestrates the execution of compute tasks from different applications and mitigates PCI-e bandwidth contention to deliver the required QoS for user-facing applications and increase the accelerator utilization. Using DjiNN, a deep neural network service, Sirius, an end-to-end IPA workload, and traditional applications on a Nvidia K40 GPU, our evaluation shows that Baymax improves the accelerator utilization by 91.3\% while achieving the desired 99\%-ile latency target for for user-facing applications. In fact, Baymax reduces the 99\%-ile latency of user-facing applications by up to 195x over default execution.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {681–696},
numpages = {16},
keywords = {non-preemptive accelerators, quality of service, scheduling, warehouse scale computers},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872412,
author = {Nowatzki, Tony and Sankaralingam, Karthikeyan},
title = {Analyzing Behavior Specialized Acceleration},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872412},
doi = {10.1145/2954679.2872412},
abstract = {Hardware specialization has become a promising paradigm for overcoming the inefficiencies of general purpose microprocessors. Of significant interest are Behavioral Specialized Accelerators (BSAs), which are designed to efficiently execute code with only certain properties, but remain largely configurable or programmable. The most important strength of BSAs -- their ability to target a wide variety of codes -- also makes their interactions and analysis complex, raising the following questions: can multiple BSAs be composed synergistically, what are their interactions with the general purpose core, and what combinations favor which workloads? From a methodological standpoint, BSAs are also challenging, as they each require ISA development, compiler and assembler extensions, and either simulator or RTL models.To study the potential of BSAs, we propose a novel modeling technique called the Transformable Dependence Graph (TDG) - a higher level alternative to the time-consuming traditional compiler+simulator approach, while still enabling detailed microarchitectural models for both general cores and accelerators. We then propose a multi-BSA organization, called ExoCore, which we model and study using the TDG. A design space exploration reveals that an ExoCore organization can push designs beyond the established energy-performance frontiers for general purpose cores. For example, a 2-wide OOO processor with three BSAs matches the performance of a conventional 6-wide OOO core, has 40\% lower area, and is 2.6x more energy efficient.},
journal = {SIGPLAN Not.},
month = mar,
pages = {697–711},
numpages = {15},
keywords = {specialization, program behaviors, modeling, dependence graphs, accelerators}
}

@article{10.1145/2980024.2872412,
author = {Nowatzki, Tony and Sankaralingam, Karthikeyan},
title = {Analyzing Behavior Specialized Acceleration},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872412},
doi = {10.1145/2980024.2872412},
abstract = {Hardware specialization has become a promising paradigm for overcoming the inefficiencies of general purpose microprocessors. Of significant interest are Behavioral Specialized Accelerators (BSAs), which are designed to efficiently execute code with only certain properties, but remain largely configurable or programmable. The most important strength of BSAs -- their ability to target a wide variety of codes -- also makes their interactions and analysis complex, raising the following questions: can multiple BSAs be composed synergistically, what are their interactions with the general purpose core, and what combinations favor which workloads? From a methodological standpoint, BSAs are also challenging, as they each require ISA development, compiler and assembler extensions, and either simulator or RTL models.To study the potential of BSAs, we propose a novel modeling technique called the Transformable Dependence Graph (TDG) - a higher level alternative to the time-consuming traditional compiler+simulator approach, while still enabling detailed microarchitectural models for both general cores and accelerators. We then propose a multi-BSA organization, called ExoCore, which we model and study using the TDG. A design space exploration reveals that an ExoCore organization can push designs beyond the established energy-performance frontiers for general purpose cores. For example, a 2-wide OOO processor with three BSAs matches the performance of a conventional 6-wide OOO core, has 40\% lower area, and is 2.6x more energy efficient.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {697–711},
numpages = {15},
keywords = {accelerators, dependence graphs, modeling, program behaviors, specialization}
}

@inproceedings{10.1145/2872362.2872412,
author = {Nowatzki, Tony and Sankaralingam, Karthikeyan},
title = {Analyzing Behavior Specialized Acceleration},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872412},
doi = {10.1145/2872362.2872412},
abstract = {Hardware specialization has become a promising paradigm for overcoming the inefficiencies of general purpose microprocessors. Of significant interest are Behavioral Specialized Accelerators (BSAs), which are designed to efficiently execute code with only certain properties, but remain largely configurable or programmable. The most important strength of BSAs -- their ability to target a wide variety of codes -- also makes their interactions and analysis complex, raising the following questions: can multiple BSAs be composed synergistically, what are their interactions with the general purpose core, and what combinations favor which workloads? From a methodological standpoint, BSAs are also challenging, as they each require ISA development, compiler and assembler extensions, and either simulator or RTL models.To study the potential of BSAs, we propose a novel modeling technique called the Transformable Dependence Graph (TDG) - a higher level alternative to the time-consuming traditional compiler+simulator approach, while still enabling detailed microarchitectural models for both general cores and accelerators. We then propose a multi-BSA organization, called ExoCore, which we model and study using the TDG. A design space exploration reveals that an ExoCore organization can push designs beyond the established energy-performance frontiers for general purpose cores. For example, a 2-wide OOO processor with three BSAs matches the performance of a conventional 6-wide OOO core, has 40\% lower area, and is 2.6x more energy efficient.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {697–711},
numpages = {15},
keywords = {accelerators, dependence graphs, modeling, program behaviors, specialization},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252408,
author = {Strauss, Karin},
title = {Session details: Session 8A: Security II},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252408},
doi = {10.1145/3252408},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2954679.2872403,
author = {Yoon, Man-Ki and Salajegheh, Negin and Chen, Yin and Christodorescu, Mihai},
title = {PIFT: Predictive Information-Flow Tracking},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872403},
doi = {10.1145/2954679.2872403},
abstract = {Phones today carry sensitive information and have a great number of ways to communicate that data. As a result, malware that steal money, information, or simply disable functionality have hit the app stores. Current security solutions for preventing undesirable data leaks are mostly high-overhead and have not been practical enough for smartphones. In this paper, we show that simply monitoring just some instructions (only memory loads and stores) it is possible to achieve low overhead, highly accurate information flow tracking. Our method achieves 98\% accuracy (0\% false positive and 2\% false negative) over DroidBench and was able to successfully catch seven real-world malware instances that steal phone number, location, and device ID using SMS messages and HTTP connections.},
journal = {SIGPLAN Not.},
month = mar,
pages = {713–725},
numpages = {13},
keywords = {information flow tracking, security}
}

@article{10.1145/2980024.2872403,
author = {Yoon, Man-Ki and Salajegheh, Negin and Chen, Yin and Christodorescu, Mihai},
title = {PIFT: Predictive Information-Flow Tracking},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872403},
doi = {10.1145/2980024.2872403},
abstract = {Phones today carry sensitive information and have a great number of ways to communicate that data. As a result, malware that steal money, information, or simply disable functionality have hit the app stores. Current security solutions for preventing undesirable data leaks are mostly high-overhead and have not been practical enough for smartphones. In this paper, we show that simply monitoring just some instructions (only memory loads and stores) it is possible to achieve low overhead, highly accurate information flow tracking. Our method achieves 98\% accuracy (0\% false positive and 2\% false negative) over DroidBench and was able to successfully catch seven real-world malware instances that steal phone number, location, and device ID using SMS messages and HTTP connections.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {713–725},
numpages = {13},
keywords = {security, information flow tracking}
}

@inproceedings{10.1145/2872362.2872403,
author = {Yoon, Man-Ki and Salajegheh, Negin and Chen, Yin and Christodorescu, Mihai},
title = {PIFT: Predictive Information-Flow Tracking},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872403},
doi = {10.1145/2872362.2872403},
abstract = {Phones today carry sensitive information and have a great number of ways to communicate that data. As a result, malware that steal money, information, or simply disable functionality have hit the app stores. Current security solutions for preventing undesirable data leaks are mostly high-overhead and have not been practical enough for smartphones. In this paper, we show that simply monitoring just some instructions (only memory loads and stores) it is possible to achieve low overhead, highly accurate information flow tracking. Our method achieves 98\% accuracy (0\% false positive and 2\% false negative) over DroidBench and was able to successfully catch seven real-world malware instances that steal phone number, location, and device ID using SMS messages and HTTP connections.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {713–725},
numpages = {13},
keywords = {information flow tracking, security},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872408,
author = {Venkat, Ashish and Shamasunder, Sriskanda and Shacham, Hovav and Tullsen, Dean M.},
title = {HIPStR: Heterogeneous-ISA Program State Relocation},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872408},
doi = {10.1145/2980024.2872408},
abstract = {Heterogeneous Chip Multiprocessors have been shown to provide significant performance and energy efficiency gains over homogeneous designs. Recent research has expanded the dimensions of heterogeneity to include diverse Instruction Set Architectures, called Heterogeneous-ISA Chip Multiprocessors. This work leverages such an architecture to realize substantial new security benefits, and in particular, to thwart Return-Oriented Programming. This paper proposes a novel security defense called HIPStR -- Heterogeneous-ISA Program State Relocation -- that performs dynamic randomization of run-time program state, both within and across ISAs. This technique outperforms the state-of-the-art just-in-time code reuse (JIT-ROP) defense by an average of 15.6\%, while simultaneously providing greater security guarantees against classic return-into-libc, ROP, JOP, brute force, JIT-ROP, and several evasive variants.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {727–741},
numpages = {15},
keywords = {heterogeneous-ISA CMP, return-oriented programming}
}

@article{10.1145/2954679.2872408,
author = {Venkat, Ashish and Shamasunder, Sriskanda and Shacham, Hovav and Tullsen, Dean M.},
title = {HIPStR: Heterogeneous-ISA Program State Relocation},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872408},
doi = {10.1145/2954679.2872408},
abstract = {Heterogeneous Chip Multiprocessors have been shown to provide significant performance and energy efficiency gains over homogeneous designs. Recent research has expanded the dimensions of heterogeneity to include diverse Instruction Set Architectures, called Heterogeneous-ISA Chip Multiprocessors. This work leverages such an architecture to realize substantial new security benefits, and in particular, to thwart Return-Oriented Programming. This paper proposes a novel security defense called HIPStR -- Heterogeneous-ISA Program State Relocation -- that performs dynamic randomization of run-time program state, both within and across ISAs. This technique outperforms the state-of-the-art just-in-time code reuse (JIT-ROP) defense by an average of 15.6\%, while simultaneously providing greater security guarantees against classic return-into-libc, ROP, JOP, brute force, JIT-ROP, and several evasive variants.},
journal = {SIGPLAN Not.},
month = mar,
pages = {727–741},
numpages = {15},
keywords = {heterogeneous-ISA CMP, return-oriented programming}
}

@inproceedings{10.1145/2872362.2872408,
author = {Venkat, Ashish and Shamasunder, Sriskanda and Shacham, Hovav and Tullsen, Dean M.},
title = {HIPStR: Heterogeneous-ISA Program State Relocation},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872408},
doi = {10.1145/2872362.2872408},
abstract = {Heterogeneous Chip Multiprocessors have been shown to provide significant performance and energy efficiency gains over homogeneous designs. Recent research has expanded the dimensions of heterogeneity to include diverse Instruction Set Architectures, called Heterogeneous-ISA Chip Multiprocessors. This work leverages such an architecture to realize substantial new security benefits, and in particular, to thwart Return-Oriented Programming. This paper proposes a novel security defense called HIPStR -- Heterogeneous-ISA Program State Relocation -- that performs dynamic randomization of run-time program state, both within and across ISAs. This technique outperforms the state-of-the-art just-in-time code reuse (JIT-ROP) defense by an average of 15.6\%, while simultaneously providing greater security guarantees against classic return-into-libc, ROP, JOP, brute force, JIT-ROP, and several evasive variants.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {727–741},
numpages = {15},
keywords = {heterogeneous-ISA CMP, return-oriented programming},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872390,
author = {Aweke, Zelalem Birhanu and Yitbarek, Salessawi Ferede and Qiao, Rui and Das, Reetuparna and Hicks, Matthew and Oren, Yossi and Austin, Todd},
title = {ANVIL: Software-Based Protection Against Next-Generation Rowhammer Attacks},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872390},
doi = {10.1145/2980024.2872390},
abstract = {Ensuring the integrity and security of the memory system is critical. Recent studies have shown serious security concerns due to "rowhammer" attacks, where repeated accesses to a row of memory cause bit flips in adjacent rows. Recent work by Google's Project Zero has shown how to leverage rowhammer-induced bit-flips as the basis for security exploits that include malicious code injection and memory privilege escalation. Being an important security concern, industry has attempted to defend against rowhammer attacks. Deployed defenses employ two strategies: (1) doubling the system DRAM refresh rate and (2) restricting access to the CLFLUSH instruction that attackers use to bypass the cache to increase memory access frequency (i.e., the rate of rowhammering). We demonstrate that such defenses are inadequte: we implement rowhammer attacks that both avoid using the CLFLUSH instruction and cause bit flips with a doubled refresh rate. Our next-generation CLFLUSH-free rowhammer attack bypasses the cache by manipulating cache replacement state to allow frequent misses out of the last-level cache to DRAM rows of our choosing.To protect existing systems from more advanced rowhammer attacks, we develop a software-based defense, ANVIL, which thwarts all known rowhammer attacks on existing systems. ANVIL detects rowhammer attacks by tracking the locality of DRAM accesses using existing hardware performance counters. Our detector identifies the rows being frequently accessed (i.e., the aggressors), then selectively refreshes the nearby victim rows to prevent hammering. Experiments running on real hardware with the SPEC2006 benchmarks show that ANVIL has less than a 1\% false positive rate and an average slowdown of 1\%. ANVIL is low-cost and robust, and our experiments indicate that it is an effective approach for protecting existing and future systems from even advanced rowhammer attacks.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {743–755},
numpages = {13},
keywords = {rowhammer, performance counters, kernel module, intel pebs, disturbance errors, bit-plru, DRAM, CLFLUSH}
}

@article{10.1145/2954679.2872390,
author = {Aweke, Zelalem Birhanu and Yitbarek, Salessawi Ferede and Qiao, Rui and Das, Reetuparna and Hicks, Matthew and Oren, Yossi and Austin, Todd},
title = {ANVIL: Software-Based Protection Against Next-Generation Rowhammer Attacks},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872390},
doi = {10.1145/2954679.2872390},
abstract = {Ensuring the integrity and security of the memory system is critical. Recent studies have shown serious security concerns due to "rowhammer" attacks, where repeated accesses to a row of memory cause bit flips in adjacent rows. Recent work by Google's Project Zero has shown how to leverage rowhammer-induced bit-flips as the basis for security exploits that include malicious code injection and memory privilege escalation. Being an important security concern, industry has attempted to defend against rowhammer attacks. Deployed defenses employ two strategies: (1) doubling the system DRAM refresh rate and (2) restricting access to the CLFLUSH instruction that attackers use to bypass the cache to increase memory access frequency (i.e., the rate of rowhammering). We demonstrate that such defenses are inadequte: we implement rowhammer attacks that both avoid using the CLFLUSH instruction and cause bit flips with a doubled refresh rate. Our next-generation CLFLUSH-free rowhammer attack bypasses the cache by manipulating cache replacement state to allow frequent misses out of the last-level cache to DRAM rows of our choosing.To protect existing systems from more advanced rowhammer attacks, we develop a software-based defense, ANVIL, which thwarts all known rowhammer attacks on existing systems. ANVIL detects rowhammer attacks by tracking the locality of DRAM accesses using existing hardware performance counters. Our detector identifies the rows being frequently accessed (i.e., the aggressors), then selectively refreshes the nearby victim rows to prevent hammering. Experiments running on real hardware with the SPEC2006 benchmarks show that ANVIL has less than a 1\% false positive rate and an average slowdown of 1\%. ANVIL is low-cost and robust, and our experiments indicate that it is an effective approach for protecting existing and future systems from even advanced rowhammer attacks.},
journal = {SIGPLAN Not.},
month = mar,
pages = {743–755},
numpages = {13},
keywords = {CLFLUSH, DRAM, bit-plru, disturbance errors, intel pebs, kernel module, performance counters, rowhammer}
}

@inproceedings{10.1145/2872362.2872390,
author = {Aweke, Zelalem Birhanu and Yitbarek, Salessawi Ferede and Qiao, Rui and Das, Reetuparna and Hicks, Matthew and Oren, Yossi and Austin, Todd},
title = {ANVIL: Software-Based Protection Against Next-Generation Rowhammer Attacks},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872390},
doi = {10.1145/2872362.2872390},
abstract = {Ensuring the integrity and security of the memory system is critical. Recent studies have shown serious security concerns due to "rowhammer" attacks, where repeated accesses to a row of memory cause bit flips in adjacent rows. Recent work by Google's Project Zero has shown how to leverage rowhammer-induced bit-flips as the basis for security exploits that include malicious code injection and memory privilege escalation. Being an important security concern, industry has attempted to defend against rowhammer attacks. Deployed defenses employ two strategies: (1) doubling the system DRAM refresh rate and (2) restricting access to the CLFLUSH instruction that attackers use to bypass the cache to increase memory access frequency (i.e., the rate of rowhammering). We demonstrate that such defenses are inadequte: we implement rowhammer attacks that both avoid using the CLFLUSH instruction and cause bit flips with a doubled refresh rate. Our next-generation CLFLUSH-free rowhammer attack bypasses the cache by manipulating cache replacement state to allow frequent misses out of the last-level cache to DRAM rows of our choosing.To protect existing systems from more advanced rowhammer attacks, we develop a software-based defense, ANVIL, which thwarts all known rowhammer attacks on existing systems. ANVIL detects rowhammer attacks by tracking the locality of DRAM accesses using existing hardware performance counters. Our detector identifies the rows being frequently accessed (i.e., the aggressors), then selectively refreshes the nearby victim rows to prevent hammering. Experiments running on real hardware with the SPEC2006 benchmarks show that ANVIL has less than a 1\% false positive rate and an average slowdown of 1\%. ANVIL is low-cost and robust, and our experiments indicate that it is an effective approach for protecting existing and future systems from even advanced rowhammer attacks.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {743–755},
numpages = {13},
keywords = {CLFLUSH, DRAM, bit-plru, disturbance errors, intel pebs, kernel module, performance counters, rowhammer},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@inproceedings{10.1145/3252409,
author = {Chen, Wenguang},
title = {Session details: Session 8B: Transactional Memory},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3252409},
doi = {10.1145/3252409},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872385,
author = {Didona, Diego and Diegues, Nuno and Kermarrec, Anne-Marie and Guerraoui, Rachid and Neves, Ricardo and Romano, Paolo},
title = {ProteusTM: Abstraction Meets Performance in Transactional Memory},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872385},
doi = {10.1145/2980024.2872385},
abstract = {The Transactional Memory (TM) paradigm promises to greatly simplify the development of concurrent applications. This led, over the years, to the creation of a plethora of TM implementations delivering wide ranges of performance across workloads. Yet, no universal implementation fits each and every workload. In fact, the best TM in a given workload can reveal to be disastrous for another one. This forces developers to face the complex task of tuning TM implementations, which significantly hampers their wide adoption. In this paper, we address the challenge of automatically identifying the best TM implementation for a given workload. Our proposed system, ProteusTM, hides behind the TM interface a large library of implementations. Underneath, it leverages a novel multi-dimensional online optimization scheme, combining two popular learning techniques: Collaborative Filtering and Bayesian Optimization.We integrated ProteusTM in GCC and demonstrate its ability to switch between TMs and adapt several configuration parameters (e.g., number of threads). We extensively evaluated ProteusTM, obtaining average performance &lt;3\% from optimal, and gains up to 100x over static alternatives.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {757–771},
numpages = {15},
keywords = {adaptive system, performance tuning, recommender systems, transactional memory}
}

@article{10.1145/2954679.2872385,
author = {Didona, Diego and Diegues, Nuno and Kermarrec, Anne-Marie and Guerraoui, Rachid and Neves, Ricardo and Romano, Paolo},
title = {ProteusTM: Abstraction Meets Performance in Transactional Memory},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872385},
doi = {10.1145/2954679.2872385},
abstract = {The Transactional Memory (TM) paradigm promises to greatly simplify the development of concurrent applications. This led, over the years, to the creation of a plethora of TM implementations delivering wide ranges of performance across workloads. Yet, no universal implementation fits each and every workload. In fact, the best TM in a given workload can reveal to be disastrous for another one. This forces developers to face the complex task of tuning TM implementations, which significantly hampers their wide adoption. In this paper, we address the challenge of automatically identifying the best TM implementation for a given workload. Our proposed system, ProteusTM, hides behind the TM interface a large library of implementations. Underneath, it leverages a novel multi-dimensional online optimization scheme, combining two popular learning techniques: Collaborative Filtering and Bayesian Optimization.We integrated ProteusTM in GCC and demonstrate its ability to switch between TMs and adapt several configuration parameters (e.g., number of threads). We extensively evaluated ProteusTM, obtaining average performance &lt;3\% from optimal, and gains up to 100x over static alternatives.},
journal = {SIGPLAN Not.},
month = mar,
pages = {757–771},
numpages = {15},
keywords = {adaptive system, performance tuning, recommender systems, transactional memory}
}

@inproceedings{10.1145/2872362.2872385,
author = {Didona, Diego and Diegues, Nuno and Kermarrec, Anne-Marie and Guerraoui, Rachid and Neves, Ricardo and Romano, Paolo},
title = {ProteusTM: Abstraction Meets Performance in Transactional Memory},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872385},
doi = {10.1145/2872362.2872385},
abstract = {The Transactional Memory (TM) paradigm promises to greatly simplify the development of concurrent applications. This led, over the years, to the creation of a plethora of TM implementations delivering wide ranges of performance across workloads. Yet, no universal implementation fits each and every workload. In fact, the best TM in a given workload can reveal to be disastrous for another one. This forces developers to face the complex task of tuning TM implementations, which significantly hampers their wide adoption. In this paper, we address the challenge of automatically identifying the best TM implementation for a given workload. Our proposed system, ProteusTM, hides behind the TM interface a large library of implementations. Underneath, it leverages a novel multi-dimensional online optimization scheme, combining two popular learning techniques: Collaborative Filtering and Bayesian Optimization.We integrated ProteusTM in GCC and demonstrate its ability to switch between TMs and adapt several configuration parameters (e.g., number of threads). We extensively evaluated ProteusTM, obtaining average performance &lt;3\% from optimal, and gains up to 100x over static alternatives.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {757–771},
numpages = {15},
keywords = {adaptive system, performance tuning, recommender systems, transactional memory},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872369,
author = {Shalev, Noam and Harpaz, Eran and Porat, Hagar and Keidar, Idit and Weinsberg, Yaron},
title = {CSR: Core Surprise Removal in Commodity Operating Systems},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872369},
doi = {10.1145/2980024.2872369},
abstract = {One of the adverse effects of shrinking transistor sizes is that processors have become increasingly prone to hardware faults. At the same time, the number of cores per die rises. Consequently, core failures can no longer be ruled out, and future operating systems for many-core machines will have to incorporate fault tolerance mechanisms.We present CSR, a strategy for recovery from unexpected permanent processor faults in commodity operating systems. Our approach overcomes surprise removal of faulty cores, and also tolerates cascading core failures. When a core fails in user mode, CSR terminates the process executing on that core and migrates the remaining processes in its run-queue to other cores. We further show how hardware transactional memory may be used to overcome failures in critical kernel code. Our solution is scalable, incurs low overhead, and is designed to integrate into modern operating systems. We have implemented it in the Linux kernel, using Haswell's Transactional Synchronization Extension, and tested it on a real system.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {773–787},
numpages = {15},
keywords = {CPU-hotplug, CSR, OS reliability, core surprise removal, fault-tolerant operating system, hardware transactional memory in kernel, hotplug, htm in kernel, kernel transactions}
}

@article{10.1145/2954679.2872369,
author = {Shalev, Noam and Harpaz, Eran and Porat, Hagar and Keidar, Idit and Weinsberg, Yaron},
title = {CSR: Core Surprise Removal in Commodity Operating Systems},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872369},
doi = {10.1145/2954679.2872369},
abstract = {One of the adverse effects of shrinking transistor sizes is that processors have become increasingly prone to hardware faults. At the same time, the number of cores per die rises. Consequently, core failures can no longer be ruled out, and future operating systems for many-core machines will have to incorporate fault tolerance mechanisms.We present CSR, a strategy for recovery from unexpected permanent processor faults in commodity operating systems. Our approach overcomes surprise removal of faulty cores, and also tolerates cascading core failures. When a core fails in user mode, CSR terminates the process executing on that core and migrates the remaining processes in its run-queue to other cores. We further show how hardware transactional memory may be used to overcome failures in critical kernel code. Our solution is scalable, incurs low overhead, and is designed to integrate into modern operating systems. We have implemented it in the Linux kernel, using Haswell's Transactional Synchronization Extension, and tested it on a real system.},
journal = {SIGPLAN Not.},
month = mar,
pages = {773–787},
numpages = {15},
keywords = {CPU-hotplug, CSR, OS reliability, core surprise removal, fault-tolerant operating system, hardware transactional memory in kernel, hotplug, htm in kernel, kernel transactions}
}

@inproceedings{10.1145/2872362.2872369,
author = {Shalev, Noam and Harpaz, Eran and Porat, Hagar and Keidar, Idit and Weinsberg, Yaron},
title = {CSR: Core Surprise Removal in Commodity Operating Systems},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872369},
doi = {10.1145/2872362.2872369},
abstract = {One of the adverse effects of shrinking transistor sizes is that processors have become increasingly prone to hardware faults. At the same time, the number of cores per die rises. Consequently, core failures can no longer be ruled out, and future operating systems for many-core machines will have to incorporate fault tolerance mechanisms.We present CSR, a strategy for recovery from unexpected permanent processor faults in commodity operating systems. Our approach overcomes surprise removal of faulty cores, and also tolerates cascading core failures. When a core fails in user mode, CSR terminates the process executing on that core and migrates the remaining processes in its run-queue to other cores. We further show how hardware transactional memory may be used to overcome failures in critical kernel code. Our solution is scalable, incurs low overhead, and is designed to integrate into modern operating systems. We have implemented it in the Linux kernel, using Haswell's Transactional Synchronization Extension, and tested it on a real system.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {773–787},
numpages = {15},
keywords = {CPU-hotplug, CSR, OS reliability, core surprise removal, fault-tolerant operating system, hardware transactional memory in kernel, hotplug, htm in kernel, kernel transactions},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

@article{10.1145/2980024.2872400,
author = {Gangwani, Tanmay and Morrison, Adam and Torrellas, Josep},
title = {CASPAR: Breaking Serialization in Lock-Free Multicore Synchronization},
year = {2016},
issue_date = {May 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {0163-5964},
url = {https://doi.org/10.1145/2980024.2872400},
doi = {10.1145/2980024.2872400},
abstract = {In multicores, performance-critical synchronization is increasingly performed in a lock-free manner using atomic instructions such as CAS or LL/SC. However, when many processors synchronize on the same variable, performance can still degrade significantly. Contending writes get serialized, creating a non-scalable condition. Past proposals that build hardware queues of synchronizing processors do not fundamentally solve this problem---at best, they help to efficiently serialize the contending writes.This paper proposes a novel architecture that breaks the serialization of hardware queues and enables the queued processors to perform lock-free synchronization in parallel. The architecture, called CASPAR, is able to (1) execute the CASes in the queued-up processors in parallel through eager forwarding of expected values, and (2) validate the CASes in parallel and dequeue groups of processors at a time. The result is highly-scalable synchronization. We evaluate CASPAR with simulations of a 64-core chip. Compared to existing proposals with hardware queues, CASPAR improves the throughput of kernels by 32\% on average, and reduces the execution time of the sections considered in lock-free versions of applications by 47\% on average. This makes these sections 2.5x faster than in the original applications.},
journal = {SIGARCH Comput. Archit. News},
month = mar,
pages = {789–804},
numpages = {16},
keywords = {lock-free synchronization, serialization}
}

@article{10.1145/2954679.2872400,
author = {Gangwani, Tanmay and Morrison, Adam and Torrellas, Josep},
title = {CASPAR: Breaking Serialization in Lock-Free Multicore Synchronization},
year = {2016},
issue_date = {April 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/2954679.2872400},
doi = {10.1145/2954679.2872400},
abstract = {In multicores, performance-critical synchronization is increasingly performed in a lock-free manner using atomic instructions such as CAS or LL/SC. However, when many processors synchronize on the same variable, performance can still degrade significantly. Contending writes get serialized, creating a non-scalable condition. Past proposals that build hardware queues of synchronizing processors do not fundamentally solve this problem---at best, they help to efficiently serialize the contending writes.This paper proposes a novel architecture that breaks the serialization of hardware queues and enables the queued processors to perform lock-free synchronization in parallel. The architecture, called CASPAR, is able to (1) execute the CASes in the queued-up processors in parallel through eager forwarding of expected values, and (2) validate the CASes in parallel and dequeue groups of processors at a time. The result is highly-scalable synchronization. We evaluate CASPAR with simulations of a 64-core chip. Compared to existing proposals with hardware queues, CASPAR improves the throughput of kernels by 32\% on average, and reduces the execution time of the sections considered in lock-free versions of applications by 47\% on average. This makes these sections 2.5x faster than in the original applications.},
journal = {SIGPLAN Not.},
month = mar,
pages = {789–804},
numpages = {16},
keywords = {lock-free synchronization, serialization}
}

@inproceedings{10.1145/2872362.2872400,
author = {Gangwani, Tanmay and Morrison, Adam and Torrellas, Josep},
title = {CASPAR: Breaking Serialization in Lock-Free Multicore Synchronization},
year = {2016},
isbn = {9781450340915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2872362.2872400},
doi = {10.1145/2872362.2872400},
abstract = {In multicores, performance-critical synchronization is increasingly performed in a lock-free manner using atomic instructions such as CAS or LL/SC. However, when many processors synchronize on the same variable, performance can still degrade significantly. Contending writes get serialized, creating a non-scalable condition. Past proposals that build hardware queues of synchronizing processors do not fundamentally solve this problem---at best, they help to efficiently serialize the contending writes.This paper proposes a novel architecture that breaks the serialization of hardware queues and enables the queued processors to perform lock-free synchronization in parallel. The architecture, called CASPAR, is able to (1) execute the CASes in the queued-up processors in parallel through eager forwarding of expected values, and (2) validate the CASes in parallel and dequeue groups of processors at a time. The result is highly-scalable synchronization. We evaluate CASPAR with simulations of a 64-core chip. Compared to existing proposals with hardware queues, CASPAR improves the throughput of kernels by 32\% on average, and reduces the execution time of the sections considered in lock-free versions of applications by 47\% on average. This makes these sections 2.5x faster than in the original applications.},
booktitle = {Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {789–804},
numpages = {16},
keywords = {lock-free synchronization, serialization},
location = {Atlanta, Georgia, USA},
series = {ASPLOS '16}
}

