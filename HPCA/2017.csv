"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Towards Pervasive and User Satisfactory CNN across GPU Microarchitectures","M. Song; Y. Hu; H. Chen; T. Li","Department of Electrical and Computer Engineering, University of Florida, Gainesville, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, USA",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","1","12","Accelerating Convolutional Neural Networks (CNNs) on GPUs usually involves two stages: training and inference. Traditionally, this two-stage process is deployed on high-end GPU-equipped servers. Driven by the increase in compute power of desktop and mobile GPUs, there is growing interest in performing inference on various kinds of platforms. In contrast to the requirements of high throughput and accuracy during the training stage, end-users will face diverse requirements related to inference tasks. To address this emerging trend and new requirements, we propose Pervasive CNN (P-CNN), a user satisfaction-aware CNN inference framework. P-CNN is composed of two phases: cross-platform offline compilation and run-time management. Based on users' requirements, offline compilation generates the optimal kernel using architecture-independent techniques, such as adaptive batch size selection and coordinated fine-tuning. The runtime management phase consists of accuracy tuning, execution, and calibration. First, accuracy tuning dynamically identifies the fastest kernels with acceptable accuracy. Next, the run-time kernel scheduler partitions the optimal computing resource for each layer and schedules the GPU thread blocks. If its accuracy is not acceptable to the end-user, the calibration stage selects a slower but more precise kernel to improve the accuracy. Finally, we design a user satisfaction metric for CNNs to evaluate our Pervasive deign. Our evaluation results show P-CNN can provide the best user satisfaction for different inference tasks.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920809","","Feature extraction;Frequency modulation;Real-time systems;Computer architecture;Convolution;Support vector machines;Entropy","","53","","38","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Near-Optimal Access Partitioning for Memory Hierarchies with Multiple Heterogeneous Bandwidth Sources","J. Gaur; M. Chaudhuri; P. Ramachandran; S. Subramoney","Microarchitecture Research Lab, Intel Corporation; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur; MulticoreWare Incorporated; Microarchitecture Research Lab, Intel Corporation",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","13","24","The memory wall continues to be a major performance bottleneck. While small on-die caches have been effective so far in hiding this bottleneck, the ever-increasing footprint of modern applications renders such caches ineffective. Recent advances in memory technologies like embedded DRAM (eDRAM) and High Bandwidth Memory (HBM) have enabled the integration of large memories on the CPU package as an additional source of bandwidth other than the DDR main memory. Because of limited capacity, these memories are typically implemented as a memory-side cache. Driven by traditional wisdom, many of the optimizations that target improving system performance have been tried to maximize the hit rate of the memory-side cache. A higher hit rate enables better utilization of the cache, and is therefore believed to result in higher performance. In this paper, we challenge this traditional wisdom and present DAP, a Dynamic Access Partitioning algorithm that sacrifices cache hit rates to exploit under-utilized bandwidth available at main memory. DAP achieves a near-optimal bandwidth partitioning between the memory-side cache and main memory by using a light-weight learning mechanism that needs just sixteen bytes of additional hardware. Simulation results show a 13% average performance gain when DAP is implemented on top of a die-stacked memory-side DRAM cache. We also show that DAP delivers large performance benefits across different implementations, bandwidth points, and capacity points of the memory-side cache, making it a valuable addition to any current or future systems based on multiple heterogeneous bandwidth sources beyond the on-chip SRAM cache hierarchy.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920810","DRAM cache;memory system bandwidth;access partitioning","Bandwidth;Random access memory;Metals;Memory architecture;Optimization;Metadata;Benchmark testing","","7","","52","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"NCAP: Network-Driven, Packet Context-Aware Power Management for Client-Server Architecture","M. Alian; A. H. M. O. Abulila; L. Jindal; D. Kim; N. S. Kim","University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Wisconsin, Madison; DGIST; University of Illinois, Urbana-Champaign",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","25","36","The rate of network packets encapsulating requests from clients can significantly affect the utilization, and thus performance and sleep states of processors in servers deploying a power management policy. To improve energy efficiency, servers may adopt an aggressive power management policy that frequently transitions a processor to a low-performance or sleep state at a low utilization. However, such servers may not respond to a sudden increase in the rate of requests from clients early enough due to a considerable performance penalty of transitioning a processor from a sleep or low-performance state to a high-performance state. This in turn entails violations of a service level agreement (SLA), discourages server operators from deploying an aggressive power management policy, and thus wastes energy during low-utilization periods. For both fast response time and high energy-efficiency, we propose NCAP, Network-driven, packet Context-Aware Power management for client-server architecture. NCAP enhances a network interface card (NIC) and its driver such that it can examine received and transmitted network packets, determine the rate of network packets containing latency-critical requests, and proactively transition a processor to an appropriate performance or sleep state. To demonstrate the efficacy, we evaluate on-line data-intensive (OLDI) applications and show that a server deploying NCAP consumes 37~61% lower processor energy than a baseline server while satisfying a given SLA at various load levels.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920811","server;on-line data-intensive applications;power management","Program processors;Servers;Time factors;Kernel;Computer architecture;Linux;Energy efficiency","","16","","38","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Supporting Address Translation for Accelerator-Centric Architectures","Y. Hao; Z. Fang; G. Reinman; J. Cong","University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","37","48","While emerging accelerator-centric architectures offer orders-of-magnitude performance and energy improvements, use cases and adoption can be limited by their rigid programming model. A unified virtual address space between the host CPU cores and customized accelerators can largely improve the programmability, which necessitates hardware support for address translation. However, supporting address translation for customized accelerators with low overhead is nontrivial. Prior studies either assume an infinite-sized TLB and zero page walk latency, or rely on a slow IOMMU for correctness and safety- which penalizes the overall system performance. To provide efficient address translation support for accelerator-centric architectures, we examine the memory access behavior of customized accelerators to drive the TLB augmentation and MMU designs. First, to support bulk transfers of consecutive data between the scratchpad memory of customized accelerators and the memory system, we present a relatively small private TLB design to provide low-latency caching of translations to each accelerator. Second, to compensate for the effects of the widely used data tiling techniques, we design a shared level-two TLB to serve private TLB misses on common virtual pages, eliminating duplicate page walks from accelerators working on neighboring data tiles that are mapped to the same physical page. This two-level TLB design effectively reduces page walks by 75.8% on average. Finally, instead of implementing a dedicated MMU which introduces additional hardware complexity, we propose simply leveraging the host per-core MMU for efficient page walk handling. This mechanism is based on our insight that the existing MMU cache in the CPU MMU satisfies the demand of customized accelerators with minimal overhead. Our evaluation demonstrates that the combined approach incurs only a 6.4% performance overhead compared to the ideal address translation.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920812","","Acceleration;Arrays;Performance evaluation;Hardware;Pipeline processing","","40","7","56","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Vulnerabilities in MLC NAND Flash Memory Programming: Experimental Analysis, Exploits, and Mitigation Techniques","Y. Cai; S. Ghose; Y. Luo; K. Mai; O. Mutlu; E. F. Haratsch",NA; Carnegie Mellon University; Carnegie Mellon University; ETH Zurich; Seagate Technology; Carnegie Mellon University,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","49","60","Modern NAND flash memory chips provide high density by storing two bits of data in each flash cell, called a multi-level cell (MLC). An MLC partitions the threshold voltage range of a flash cell into four voltage states. When a flash cell is programmed, a high voltage is applied to the cell. Due to parasitic capacitance coupling between flash cells that are physically close to each other, flash cell programming can lead to cell-to-cell program interference, which introduces errors into neighboring flash cells. In order to reduce the impact of cell-to-cell interference on the reliability of MLC NAND flash memory, flash manufacturers adopt a two-step programming method, which programs the MLC in two separate steps. First, the flash memory partially programs the least significant bit of the MLC to some intermediate threshold voltage. Second, it programs the most significant bit to bring the MLC up to its full voltage state. In this paper, we demonstrate that two-step programming exposes new reliability and security vulnerabilities. We experimentally characterize the effects of two-step programming using contemporary 1X-nm (i.e., 15–19nm) flash memory chips. We find that a partially-programmed flash cell (i.e., a cell where the second programming step has not yet been performed) is much more vulnerable to cell-to-cell interference and read disturb than a fully-programmed cell. We show that it is possible to exploit these vulnerabilities on solid-state drives (SSDs) to alter the partially-programmed data, causing (potentially malicious) data corruption. Building on our experimental observations, we propose several new mechanisms for MLC NAND flash memory that eliminate or mitigate data corruption in partially-programmed cells, thereby removing or reducing the extent of the vulnerabilities, and at the same time increasing flash memory lifetime by 16%.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920813","","Programming;Threshold voltage;Flash memories;Computer architecture;Microprocessors;Interference;Transistors","","81","1","47","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Defect Analysis and Cost-Effective Resilience Architecture for Future DRAM Devices","S. Cha; O. Seongil; H. Shin; S. Hwang; K. Park; S. J. Jang; J. S. Choi; G. Y. Jin; Y. H. Son; H. Cho; J. H. Ahn; N. S. Kim",Samsung Electronics; NA; Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics; Samsung Electronics; Seoul National University; Seoul National University,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","61","72","Technology scaling has continuously improved the density, performance, energy efficiency, and cost of DRAM-based main memory systems. Starting from sub-20nm processes, however, the industry began to pay considerably higher costs to screen and manage notably increasing defective cells. The traditional technique, which replaces the rows/columns containing faulty cells with spare rows/columns, has been able to cost-effectively repair the defective cells so far, but it will become unaffordable soon because an excessive number of spare rows/columns are required to manage the increasing number of defective cells. This necessitates a synergistic application of an alternative resilience technique such as In-DRAM ECC with the traditional one. Through extensive measurement and simulation, we first identify that aggressive miniaturization makes DRAM cells more sensitive to random telegraph noise or variable retention time, which is dominantly manifested as a surge in randomly scattered single-cell faults. Second, we advocate using InDRAM ECC to overcome the DRAM scaling challenges and architect In-DRAM ECC to accomplish high area efficiency and minimal performance degradation. Moreover, we show that advancement in process technology reduces decoding/correction time to a small fraction of DRAM access time, and that the throughput penalty of a write operation due to an additional read for a parity update is mostly overcome by the multi-bank structure and long burst writes that span an entire In-DRAM ECC codeword. Lastly, we demonstrate that system reliability with modern rank-level ECC schemes such as single device data correction is further improved by hundred million times with the proposed In-DRAM ECC architecture.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920814","DRAM;resilience;In-DRAM ECC;single-cell faults;long-burst writes","Random access memory;Circuit faults;Error correction codes;Capacitors;Capacitance;Performance evaluation;Transistors","","57","2","57","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Architecting an Energy-Efficient DRAM System for GPUs","N. Chatterjee; M. O’Connor; D. Lee; D. R. Johnson; S. W. Keckler; M. Rhu; W. J. Dally",NVIDIA; The University of Texas at Austin; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","73","84","This paper proposes an energy-efficient, high-throughput DRAM architecture for GPUs and throughput processors. In these systems, requests from thousands of concurrent threads compete for a limited number of DRAM row buffers. As a result, only a fraction of the data fetched into a row buffer is used, leading to significant energy overheads. Our proposed DRAM architecture exploits the hierarchical organization of a DRAM bank to reduce the minimum row activation granularity. To avoid significant incremental area with this approach, we must partition the DRAM datapath into a number of semi-independent subchannels. These narrow subchannels increase data toggling energy which we mitigate using a static data reordering scheme designed to lower the toggle rate. This design has 35% lower energy consumption than a die-stacked DRAM with 2.6% area overhead. The resulting architecture, when augmented with an improved memory access protocol, can support parallel operations across the semi-independent subchannels, thereby improving system performance by 13% on average for a range of workloads.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.58","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920815","","Random access memory;Bandwidth;Computer architecture;Graphics processing units;Graphics;Throughput","","69","1","52","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Design and Analysis of an APU for Exascale Computing","T. Vijayaraghavan; Y. Eckert; G. H. Loh; M. J. Schulte; M. Ignatowski; B. M. Beckmann; W. C. Brantley; J. L. Greathouse; W. Huang; A. Karunanithi; O. Kayiran; M. Meswani; I. Paul; M. Poremba; S. Raasch; S. K. Reinhardt; G. Sadowski; V. Sridharan","Department of Electrical and Computer Engineering, University of Wisconsin-Madison; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.; AMD Research, Advanced Micro Devices, Inc.",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","85","96","The challenges to push computing to exaflop levels are difficult given desired targets for memory capacity, memory bandwidth, power efficiency, reliability, and cost. This paper presents a vision for an architecture that can be used to construct exascale systems. We describe a conceptual Exascale Node Architecture (ENA), which is the computational building block for an exascale supercomputer. The ENA consists of an Exascale Heterogeneous Processor (EHP) coupled with an advanced memory system. The EHP provides a high-performance accelerated processing unit (CPU+GPU), in-package high-bandwidth 3D memory, and aggressive use of die-stacking and chiplet technologies to meet the requirements for exascale computing in a balanced manner. We present initial experimental analysis to demonstrate the promise of our approach, and we discuss remaining open research challenges for the community.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920816","","Graphics processing units;Computer architecture;Three-dimensional displays;Central Processing Unit;Bandwidth;Architecture;Supercomputers","","51","","50","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"BRAVO: Balanced Reliability-Aware Voltage Optimization","K. Swaminathan; N. Chandramoorthy; C. -Y. Cher; R. Bertran; A. Buyuktosunoglu; P. Bose","IBM T. J. Watson Research Center, NY; IBM T. J. Watson Research Center, NY; IBM T. J. Watson Research Center, NY; IBM T. J. Watson Research Center, NY; IBM Thomas J Watson Research Center, Yorktown Heights, NY, US; IBM T. J. Watson Research Center, NY",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","97","108","Defining a processor micro-architecture for a targeted productspace involves multi-dimensional optimization across performance, power and reliability axes. A key decision in sucha definition process is the circuit-and technology-driven parameterof the nominal (voltage, frequency) operating point. This is a challenging task, since optimizing individually orpair-wise amongst these metrics usually results in a designthat falls short of the specification in at least one of the threedimensions. Aided by academic research, industry has nowadopted early-stage definition methodologies that considerboth energy-and performance-related metrics. Reliabilityrelatedenhancements, on the other hand, tend to get factoredin via a separate thread of activity. This task is typically pursuedwithout thorough pre-silicon quantifications of the energyor even the performance cost. In the late-CMOS designera, reliability needs to move from a post-silicon afterthoughtor validation-only effort to a pre-silicon definitionprocess. In this paper, we present BRAVO, a methodologyfor such reliability-aware design space exploration. BRAVOis supported by a multi-core simulation framework that integratesperformance, power and reliability modeling capability. Errors induced by both soft and hard fault incidence arecaptured within the reliability models. We introduce the notionof the Balanced Reliability Metric (BRM), that we useto evaluate overall reliability of the processor across soft andhard error incidences. We demonstrate up to 79% improvementin reliability in terms of this metric, for only a 6% dropin overall energy efficiency over design points that maximizeenergy efficiency. We also demonstrate several real-life usecaseapplications of BRAVO in an industrial setting.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.56","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920817","Processor reliability;soft errors;hard errors;optimal voltage","Measurement;Reliability engineering;Power system reliability;Integrated circuit reliability;Industries;Threshold voltage","","24","","57","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Maximizing Cache Performance Under Uncertainty","N. Beckmann; D. Sanchez","Carnegie Mellon University, MIT; Massachusetts Institute of Technology",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","109","120","Much prior work has studied cache replacement, but a large gap remains between theory and practice. The design of many practical policies is guided by the optimal policy, Belady's MIN. However, MIN assumes perfect knowledge of the future that is unavailable in practice, and the obvious generalizations of MIN are suboptimal with imperfect information. What, then, is the right metric for practical cache replacement? We propose that practical policies should replace lines based on their economic value added (EVA), the difference of their expected hits from the average. Drawing on the theory of Markov decision processes, we discuss why this metric maximizes the cache's hit rate. We present an inexpensive implementation of EVA and evaluate it exhaustively. EVA outperforms several prior policies and saves area at iso-performance. These results show that formalizing cache replacement yields practical benefits.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920818","cache replacement;cache modeling;Markov decision processes","Uncertainty;Analytical models;Marine vehicles;Measurement;Markov processes;Electronics packaging;Economics","","42","","40","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"SWAP: Effective Fine-Grain Management of Shared Last-Level Caches with Minimum Hardware Support","X. Wang; S. Chen; J. Setter; J. F. Martínez","Computer Systems Laboratory, Cornell University Ithaca, NY, USA; Computer Systems Laboratory, Cornell University Ithaca, NY, USA; Dept. of Electrical Engineering, Stanford University Stanford, CA, USA; Computer Systems Laboratory, Cornell University Ithaca, NY, USA",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","121","132","Performance isolation is an important goal in server-class environments. Partitioning the last-level cache of a chip multiprocessor (CMP) across co-running applications has proven useful in this regard. Two popular approaches are (a) hardware support for way partitioning, or (b) operating system support for set partitioning through page coloring. Unfortunately, neither approach by itself is scalable beyond a handful of cores without incurring in significant performance overheads. We propose SWAP, a scalable and fine-grained cache management technique that seamlessly combines set and way partitioning. By cooperatively managing cache ways and sets, SWAP (“Set and WAy Partitioning”) can successfully provide hundreds of fine-grained cache partitions for the manycore era. SWAP requires no additional hardware beyond way partitioning. In fact, SWAP can be readily implemented in existing commercial servers whose processors do support hardware way partitioning. In this paper, we prototype SWAP on a 48-core Cavium ThunderX platform running Linux, and we show average speedups over no cache partitioning that are twice as large as those attained with ThunderX's hardware way partitioning alone.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920819","cache partitioning;resource management;QoS;throughput;multicore","Color;Hardware;Program processors;Probabilistic logic;Servers;Throughput;Interference","","36","","48","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"A Split Cache Hierarchy for Enabling Data-Oriented Optimizations","A. Sembrant; E. Hagersten; D. Black-Schaffer","Department of Information Technology, Uppsala University, Uppsala, Sweden; Department of Information Technology, Uppsala University, Uppsala, Sweden; Department of Information Technology, Uppsala University, Uppsala, Sweden",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","133","144","Today's caches tightly couple data with metadata (Address Tags) at the cache line granularity. The co-location of data and its identifying metadata means that they require multiple approaches to locate data (associative way searches and level-by-level searches), evict data (coherent writebacks buffers and associative level-by-level searches) and keep data coherent (directory indirections and associative level-by-level searches). This results in complex implementations with many corner cases, increased latency and energy, and limited flexibility for data optimizations. We propose splitting the metadata and data into two separate structures: a metadata hierarchy and a data hierarchy. The metadata hierarchy tracks the location of the data in the data hierarchy. This allows us to easily apply many different optimizations to the data hierarchy, including smart data placement, dynamic coherence, and direct accesses. The new split cache hierarchy, Direct-to-Master (D2M), provides a unified mechanism for cache searching, eviction, and coherence, that eliminates level-by-level data movement and searches, associative cache address tags comparisons and about 90% of the indirections through a central directory. Optimizations such as moving LLC slices to the near-side of the network and private/shared data classification can easily be built on top off D2M to further improve its efficiency. This approach delivers a 54% improvement in cache hierarchy EDP vs. a mobile processor and 40% vs. a server processor, reduces network traffic by an average of 70%, reduces the L1 miss latency by 30% and is especially effective for workloads with high cache pressure.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920820","","Metadata;Coherence;Optimization;Encoding;Arrays;Multicore processing;Couplings","","7","","45","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Fast and Accurate Exploration of Multi-level Caches Using Hierarchical Reuse Distance","R. K. V. Maeda; Q. Cai; J. Xu; Z. Wang; Z. Tian",Hong Kong University of Science and Technology; HP Labs; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; Hong Kong University of Science and Technology,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","145","156","Exploring the design space of the memory hierarchy requires the use of effective methodologies, tools, and models to evaluate different parameter values. Reuse distance is of one of the locality models used in the design exploration and permits analytical cache miss estimation, program characterization, and synthetic trace generation. Unfortunately, the reuse distance is limited to a single locality granularity. Hence, it is not a suitable model for caches with hybrid line sizes, such as sectored caches, an increasingly popular choice for large caches. In this work, we introduce a generalization to the reuse distance, which is able to capture locality seen at multiple granularities. We refer to it as Hierarchical Reuse Distance (HRD). The proposed model has same profiling and synthesis complexity as the traditional reuse distance, and our results show that HRD reduces the average miss rate error on sectored caches by more than three times. In addition, it has superior characteristics in exploring multi-level caches with conventional single line size. For instance, our method increases the accuracy on L2 and L3 by a factor of 4 and converges three orders of magnitude faster.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920821","reuse distance;cache;simulation;statistical","Computational modeling;Benchmark testing;Estimation;Analytical models;Measurement;Organizations;Computers","","16","","42","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Enabling Effective Module-Oblivious Power Gating for Embedded Processors","H. Cherupalli; H. Duwe; W. Ye; R. Kumar; J. Sartori",University of Minnesota; Universny of Illinois at Urbana-Champaign; Universny of Illinois at Urbana-Champaign; Universny of Illinois at Urbana-Champaign; University of Minnesota,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","157","168","The increasingly-stringent power and energy requirements of emerging embedded applications have led to a strong recent interest in aggressive power gating techniques. Conventional techniques for aggressive power gating perform module-based power gating in processors, where power domains correspond to RTL modules. We observe that there can be significant power benefits from module-oblivious power gating, where power domains can include an arbitrary set of gates, possibly from multiple RTL modules. However, since it is not possible to infer the activity of module-oblivious power domains from software alone, conventional software-based power management techniques cannot be applied for module-oblivious power gating in processors. Also, since module-oblivious domains are not encapsulated with a well-defined port list and functionality like RTL modules, hardware-based management of module-oblivious domains is prohibitively expensive. In this paper, we present a technique for low-cost management of moduleoblivious power domains in embedded processors. The technique involves symbolic simulation-based co-analysis of a processor's hardware design and a software binary to derive profitable and safe power gating decisions for a given set of module-oblivious domains when the software binary is run on the processor. Our technique is automated, does not require programmer intervention, and incurs low management overhead. We demonstrate that module-oblivious power gating based on our technique reduces leakage energy by 2× with respect to state-of-the-art aggressive module-based power gating for a common embedded processor.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920822","Power-gating;Embedded;Low-power;Leakage","Logic gates;Program processors;Hardware;Monitoring;Correlation;Microprocessors","","6","","72","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Application-Specific Performance-Aware Energy Optimization on Android Mobile Devices","K. Rao; J. Wang; S. Yalamanchili; Y. Wardi; H. Ye","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; Huawei US R&D, Atlanta, USA; Sch. of Electr. & Comput. Eng., Georgia Inst. of Technol., Atlanta, USA; Sch. of Electr. & Comput. Eng., Huawei US R&D, Santa Clara, USA; Huawei US R&D, Santa Clara, CA, USA",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","169","180","Energy management is a key issue for mobile devices. On current Android devices, power management relies heavily on OS modules known as governors. These modules are created for various hardware components, including the CPU, to support DVFS. They implement algorithms that attempt to balance performance and power consumption. In this paper we make the observation that the existing governors are (1) general-purpose by nature (2) focused on power reduction and (3) are not energy-optimal for many applications. We thus establish the need for an application-specific approach that could overcome these drawbacks and provide higher energy efficiency for suitable applications. We also show that existing methods manage power and performance in an independent and isolated fashion and that co-ordinated control of multiple components can save more energy. In addition, we note that on mobile devices, energy savings cannot be achieved at the expense of performance. Consequently, we propose a solution that minimizes energy consumption of specific applications while maintaining a user-specified performance target. Our solution consists of two stages: (1) offline profiling and (2) online controlling. Utilizing the offline profiling data of the target application, our control theory based online controller dynamically selects the optimal system configuration (in this paper, combination of CPU frequency and memory bandwidth) for the application, while it is running. Our energy management solution is tested on a Nexus 6 smartphone with 6 real-world applications. We achieve 4 - 31% better energy than default governors with a worst case performance loss of <; 1%.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920823","Android;energy optimization;control theory;DVFS;SoC","Performance evaluation;Frequency control;Bandwidth;Mobile handsets;Androids;Humanoid robots;Hardware","","32","2","26","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Fast Decentralized Power Capping for Server Clusters","R. Azimi; M. Badiei; X. Zhan; N. Li; S. Reda","School of Engineering Brown University, Providence, RI; SEAS Harvard University, Cambridge, MA; School of Engineering Brown University, Providence, RI; SEAS Harvard University—, Cambridge, MA; School of Engineering Brown University, Providence, RI",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","181","192","Power capping is a mechanism to ensure that the power consumption of clusters does not exceed the provisioned resources. A fast power capping method allows for a safe over-subscription of the rated power distribution devices, provides equipment protection, and enables large clusters to participate in demand-response programs. However, current methods have a slow response time with a large actuation latency when applied across a large number of servers as they rely on hierarchical management systems. We propose a fast decentralized power capping (DPC) technique that reduces the actuation latency by localizing power management at each server. The DPC method is based on a maximum throughput optimization formulation that takes into account the workloads priorities as well as the capacity of circuit breakers. Therefore, DPC significantly improves the cluster performance compared to alternative heuristics. We implement the proposed decentralized power management scheme on a real computing cluster. Compared to state-of-the-art hierarchical methods, DPC reduces the actuation latency by 72% up to 86% depending on the cluster size. In addition, DPC improves the system throughput performance by 16%, while using only 0.02% of the available network bandwidth. We describe how to minimize the overhead of each local DPC agent to a negligible amount. We also quantify the traffic and fault resilience of our decentralized power capping approach.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920824","","Computer architecture","","14","","25","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Random Folded Clos Topologies for Datacenter Networks","C. Camarero; C. Martínez; R. Beivide","Computer Science and Electronics Department, University of Cantabria; Computer Science and Electronics Department, University of Cantabria; Computer Science and Electronics Department, University of Cantabria",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","193","204","In datacenter networks, big scale, high performance and faulttolerance, low-cost, and graceful expandability are pursued features. Recently, random regular networks, as the Jellyfish, have been proposed for satisfying these stringent requirements. However, their completely unstructured design entails several drawbacks. As a related alternative, in this paper we propose Random Folded Clos (RFC) networks. They constitute a compromise between total randomness and maintaining some topological structure. As it will be shown, RFCs preserve important properties of Clos networks that provide a straightforward deadlock-free equal-cost multi-path routing and enough randomness to gracefully expanding. These networks are minutely compared, in topological and cost terms, against fat-trees, orthogonal fat-trees and random regular graphs. Also, experiments are carried out to simulate their performance under synthetic traffics that emulate common loads in datacenters. It is shown that RFCs constitute an interesting alternative to currently deployed networks since they appropriately balance all the important design requirements. Moreover, they do that at much lower cost than the fat-tree, their natural competitor. Being able up to connect the same number of compute nodes, saving up to 95% of the cost, and giving similar performance.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920825","","Topology;Network topology;Routing;Bandwidth;System recovery;Graph theory;Servers","","7","","39","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Tiny Directory: Efficient Shared Memory in Many-Core Systems with Ultra-Low-Overhead Coherence Tracking","S. Shukla; M. Chaudhuri","Department of Computer Science and Engineering, Indian Institute of Technology Kanpur; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","205","216","The sparse directory has emerged as a critical component for supporting the shared memory abstraction in multiand many-core chip-multiprocessors. Recent research efforts have explored ways to reduce the number of entries in the sparse directory. These include tracking coherence of private regions at a coarse grain, not tracking blocks that belong to pages identified as private by the operating system (OS), and not tracking a subset of blocks that are speculated to be private by the hardware. These techniques require support for multi-grain coherence, assistance of OS, or broadcast-based recovery on sharing an untracked block that is wrongly speculated as private. In this paper, we design a robust minimally-sized sparse directory that can offer adequate performance while enjoying the simplicity, scalability, and OS-independence of traditional broadcast-free block-grain coherence. We begin our exploration with a naïve design that does not have a sparse directory and the location/sharers of a block are tracked by borrowing a portion of the block's lastlevel cache (LLC) data way. Such a design, however, lengthens the critical path from two transactions to three transactions (two hops to three hops) for the blocks that experience frequent shared read accesses. We address this problem by architecting a tiny sparse directory that dynamically identifies and tracks a selected subset of the blocks that experience a large volume of shared accesses. We augment the tiny directory proposal with an option of selectively spilling into the LLC space for tracking the coherence of the critical shared blocks that the tiny directory fails to accommodate. Detailed simulation-based study on a 128-core system with a large set of multi-threaded applications spanning scientific, general-purpose, and commercial computing shows that our coherence tracking proposal operating with1/32 × to 1/256 × sparse directories offers performance within a percentage of a traditional 2× sparse directory.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920826","sparse directory;cache coherence;shared memory","Coherence;Proposals;Protocols;Oceans;Organizations;Switches;Instruction sets","","11","2","51","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Partial Row Activation for Low-Power DRAM System","Y. Lee; H. Kim; S. Hong; S. Kim","KAIST, Schcol of Computing; KAIST, Schcol of Computing; Samsung Electronics; KAIST, Schcol of Computing",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","217","228","Owing to increasing demand of faster and larger DRAM system, the DRAM system accounts for a large portion of the total power consumption of computing systems. As memory traffic and DRAM bandwidth grow, the row activation and I/O power consumptions are becoming major contributors to total DRAM power consumption. Thus, reducing row activation and I/O power consumptions has big potential for improving the power and energy efficiency of the computing systems. To this end, we propose a partial row activation scheme for memory writes, in which DRAM is rearchitected to mitigate row overfetching problem of modern DRAMs and to reduce row activation power consumption. In addition, accompanying I/O power consumption in memory writes is also reduced by transferring only a part of cache line data that must be written to partially opened rows. In our proposed scheme, partial rows ranging from a one-eighth row to a full row can be activated to minimize row activation granularity for memory writes and the full bandwidth of the conventional DRAM can be maintained for memory reads. Our partial row activation scheme is shown to reduce total DRAM power consumption by up to 32% and 23% on average, which outperforms previously proposed schemes in DRAM power saving with almost no performance loss.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920827","","Random access memory;Power demand;Bandwidth;Memory management;Decoding;Prefetching;Organizations","","23","","56","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Understanding and Optimizing Power Consumption in Memory Networks","X. Jian; P. K. Hanumolu; R. Kumar","University of Illinois at Urbana-Champaign, Champaign, USA; University of Illinois at Urbana-Champaign, Champaign, USA; University of Illinois at Urbana-Champaign, Champaign, USA",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","229","240","As the amount of digital data the world generates explodes, data centers and HPC systems that process this big data will require high bandwidth and high capacity main memory. Unfortunately, conventional memory technologies either provide high memory capacity (e.g., DDRx memory) or high bandwidth (GDDRx memory), but not both. Memory networks, which provide both high bandwidth and high capacity memory by connecting memory modules together via a network of pointto-point links, are promising future memory candidates for data centers and HPCs. In this paper, we perform the first exploration to understand the power characteristics of memory networks. We find idle I/O links to be the biggest power contributor in memory networks. Subsequently, we study idle I/O power in more detail. We evaluate well-known circuitlevel I/O power control mechanisms such as rapid on off, variable link width, and DVFS. We also adapt prior works on memory power management to memory networks. The adapted schemes together reduce I/O power by 32% and 21%, on average, for big and small networks, respectively. We also explore novel power management schemes specifically targeting memory networks, which yield another 29% and 17% average I/O power reduction for big and small networks, respectively.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920828","Memory Power Management;Hybrid Memory Cube;Point-to-point Network;High-speed Memory I/O","Memory management;Bandwidth;Network topology;Topology;Random access memory;Pins;Power demand","","10","","23","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"SoftMC: A Flexible and Practical Open-Source Infrastructure for Enabling Experimental DRAM Studies","H. Hassan; N. Vijaykumar; S. Khan; S. Ghose; K. Chang; G. Pekhimenko; D. Lee; O. Ergin; O. Mutlu",Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; TOBB University of Economics & Technology; Carnegie Mellon University,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","241","252","DRAM is the primary technology used for main memory in modern systems. Unfortunately, as DRAM scales down to smaller technology nodes, it faces key challenges in both data integrity and latency, which strongly affects overall system reliability and performance. To develop reliable and high-performance DRAM-based main memory in future systems, it is critical to characterize, understand, and analyze various aspects (e.g., reliability, latency) of existing DRAM chips. To enable this, there is a strong need for a publicly-available DRAM testing infrastructure that can flexibly and efficiently test DRAM chips in a manner accessible to both software and hardware developers. This paper develops the first such infrastructure, SoftMC (Soft Memory Controller), an FPGA-based testing platform that can control and test memory modules designed for the commonly used DDR (Double Data Rate) interface. SoftMC has two key properties: (i) it provides flexibility to thoroughly control memory behavior or to implement a wide range of mechanisms using DDR commands; and (ii) it is easy to use as it provides a simple and intuitive high-level programming interface for users, completely hiding the low-level details of the FPGA. We demonstrate the capability, flexibility, and programming ease of SoftMC with two example use cases. First, we implement a test that characterizes the retention time of DRAM cells. Experimental results we obtain using SoftMC are consistent with the findings of prior studies on retention time in modern DRAM, which serves as a validation of our infrastructure. Second, we validate two recently-proposed mechanisms, which rely on accessing recently-refreshed or recently-accessed DRAM cells faster than other DRAM cells. Using our infrastructure, we show that the expected latency reduction effect of these mechanisms is not observable in existing DRAM chips, which demonstrates the usefulness of SoftMC in testing new ideas on existing memory modules. We discuss several other use cases of SoftMC, including the ability to characterize emerging non-volatile memory modules that obey the DDR standard. We hope that our open-source release of SoftMC fills a gap in the space of publicly-available experimental memory testing infrastructures and inspires new studies, ideas, and methodologies in memory system design.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920829","DRAM;FPGA;Memory Characterization","DRAM chips;Reliability;Testing;Timing;Open source software","","83","1","107","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Static Bubble: A Framework for Deadlock-Free Irregular On-chip Topologies","A. Ramrakhyani; T. Krishna",School of ECE Georgia Institute of Technology; School of ECE Georgia Institute of Technology,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","253","264","Future SoCs are expected to have irregular onchip topologies, either at design time due to heterogeneity in the size of core/accelerator tiles, or at runtime due to link/node failures or power-gating of network elements such as routers/router datapaths. A key challenge with irregular topologies is that of routing deadlocks (cyclic dependence between buffers), since conventional XY or turn-model based approaches are no longer applicable. Most prior works in heterogeneous SoC design, resiliency, and power-gating, have addressed the deadlock problem by constructing spanning trees over the physical topology; messages are routed via the root removing cyclic dependencies. However, this comes at a cost of tree construction at runtime, and increased latency and energy for certain flows as they are forced to use non-minimal routes. In this work, we sweep the design space of possible topologies as the number of disconnected components (links/routers) increase, and demonstrate that while most of the resulting topologies are deadlock prone (i.e., have cycles), the injection rates at which they deadlock are often much higher than the injection rates of real applications, making the current solutions highly conservative. We propose a novel framework for deadlock-freedom called Static Bubble, that can be applied at design time to the underlying mesh topology, and guarantees deadlock-freedom for any runtime topology derived from this mesh due to powergating or failure of router/link. We present an algorithm to augment a subset of routers in any n×m mesh (21 routers in a 64-core mesh) with an additional buffer called static bubble, such that any dependence chain has at least one static bubble. We also present the microarchitecture of a low-cost (less than 1% overhead) FSM at every router to activate one static bubble for deadlock recovery. Static Bubble enhances existing solutions for NoC resiliency and power-gating by providing up to 30% less network latency, 4x more throughput and 50% less EDP.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.44","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920830","Networks on chip;Deadlocks;NoC Power Gating;NoC Fault tolerance;Irregular topologies","System recovery;Topology;Routing;Network topology;Runtime;System-on-chip;Microarchitecture","","29","","36","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Designing Low-Power, Low-Latency Networks-on-Chip by Optimally Combining Electrical and Optical Links","S. Werner; J. Navaridas; M. Luján","The University of Manchester, Manchester, UK; The University of Manchester, Manchester, UK; The University of Manchester, Manchester, UK",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","265","276","Optical on-chip communication is considered a promising candidate to overcome latency and energy bottlenecks of electrical interconnects. Although recently proposed hybrid Networks-on-chip (NoCs), which implement both electrical and optical links, improve power efficiency, they often fail to combine these two interconnect technologies efficiently and suffer from considerable laser power overheads caused by high-bandwidth optical links. We argue that these overheads can be avoided by inserting a higher quantity of low-bandwidth optical links in a topology, as this yields lower optical loss and in turn laser power. Moreover, when optimally combined with electrical links for short distances, this can be done without trading off latency. We present the effectiveness of this concept with Lego, our hybrid, mesh-based NoC that provides high power efficiency by utilizing electrical links for local traffic, and low-bandwidth optical links for long distances. Electrical links are placed systematically to outweigh the serialization delay introduced by the optical links, simplify router microarchitecture, and allow to save optical resources. Our routing algorithm always chooses the link that offers the lowest latency and energy. Compared to state-of-the-art proposals, Lego increases throughput-per-watt by at least 40%, and lowers latency by 35% on average for synthetic traffic. On SPLASH-2/PARSEC workloads, Lego improves power efficiency by at least 37% (up to 3.5×).","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920831","","Optical fiber communication;Power lasers;Delays;Bandwidth;Clocks;Optical resonators;Laser modes","","37","","53","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Near-Ideal Networks-on-Chip for Servers","P. Lotfi-Kamran; M. Modarressi; H. Sarbazi-Azad","School of Computer Science, Institute for Research in Fundamental Sciences (IPM); School of Computer Science, Institute for Research in Fundamental Sciences (IPM); School of Computer Science, Institute for Research in Fundamental Sciences (IPM)",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","277","288","Server workloads benefit from execution on many-core processors due to their massive request-level parallelism. A key characteristic of server workloads is the large instruction footprints. While a shared last-level cache (LLC) captures the footprints, it necessitates a low-latency network-on-chip (NOC) to minimize the core stall time on accesses serviced by the LLC. As strict quality-of-service requirements preclude the use of lean cores in server processors, we observe that even state-of-the-art single-cycle multi-hop NOCs are far from ideal because they impose significant NOC-induced delays on the LLC access latency, and diminish performance. Most of the NOC delay is due to per-hop resource allocation. In this paper, we take advantage of proactive resource allocation (PRA) to eliminate per-hop resource allocation time in single-cycle multi-hop networks to reach a near-ideal network for servers. PRA is undertaken during (1) the time interval in which it is known that LLC has the requested data, but the data is not yet ready, and (2) the time interval in which a packet is stalled in a router because the required resources are dedicated to another packet. Through detailed evaluation targeting a 64-core processor and a set of server workloads, we show that our proposal improves system performance by 12% over the state-of-the-art single-cycle multi-hop mesh NOC.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920832","Latency;network-on-chip;resource allocation;server","Servers;Program processors;Spread spectrum communication;Delays;Resource management;Quality of service;Clocks","","12","","63","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Design and Evaluation of AWGR-Based Photonic NoC Architectures for 2.5D Integrated High Performance Computing Systems","P. Grani; R. Proietti; V. Akella; S. J. Ben Yoo","Department of Electrical and Computer Engineering, University of California, Davis, CA, USA; Department of Electrical and Computer Engineering, University of California, Davis, CA, USA; Department of Electrical and Computer Engineering, University of California, Davis, CA, USA; Dept. of Electr. & Comput. Eng., University of California Davis, Davis, CA, US",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","289","300","In future performance improvement of the basic building block of supercomputers has to come through increased integration enabled by 3D (vertical) and 2.5D (horizontal) die-stacking. But to take advantage of this integration we need an interconnection network between the memory and compute die that not only can provide an order of magnitude higher bandwidth but also consume an order of magnitude less power than today's state of the art electronic interconnects. We show how Arrayed Waveguide Grating Router-based photonic interconnects implemented on the silicon interposer can be used to realize a 16 × 16 photonic Network-on-Chip (NoC) with a bisection bandwidth of 16 Tb/s. We propose a baseline network, which consumes 2.57 pJ/bit assuming 100% utilization. We show that the power is dominated by the electro-optical interface of the transmitter, which can be reduced by a more aggressive design that improves the energy per bit to 0.454 pJ/bit at 100% utilization. Compared to recently proposed interposer-based electrical NoC's we show an average performance improvement of 25% on the PARSEC benchmark suite on a 64-core system using the Gem5 simulation framework.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920833","","Bandwidth;Photonics;Arrayed waveguide gratings;Ports (Computers);Multiprocessor interconnection;Topology","","15","","49","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Secure Dynamic Memory Scheduling Against Timing Channel Attacks","Y. Wang; B. Wu; G. E. Suh","Cornell University, Ithaca, NY, USA; Cornell University, Ithaca, NY, USA; Cornell University, Ithaca, NY, US",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","301","312","This paper presents SecMC, a secure memory controller that provides efficient memory scheduling with a strong quantitative security guarantee against timing channel attacks. The first variant, named SecMC-NI, eliminates timing channels while allowing a tight memory schedule by interleaving memory requests that access different banks or ranks. Experimental results show that SecMC-NI significantly (45% on average) improves the performance of the best known scheme that does not rely on restricting memory placements. To further improve the performance, the paper proposes SecMC-Bound, which enables trading-off security for performance with a quantitative information theoretic bound on information leakage. The experimental results show that allowing small information leakage can yield significant performance improvements.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920834","","Timing;Security;Schedules;Interference;Dynamic scheduling;Random access memory;Cloud computing","","6","1","23","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Cold Boot Attacks are Still Hot: Security Analysis of Memory Scramblers in Modern Processors","S. F. Yitbarek; M. T. Aga; R. Das; T. Austin","University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","313","324","Previous work has demonstrated that systems with unencrypted DRAM interfaces are susceptible to cold boot attacks - where the DRAM in a system is frozen to give it sufficient retention time and is then re-read after reboot, or is transferred to an attacker's machine for extracting sensitive data. This method has been shown to be an effective attack vector for extracting disk encryption keys out of locked devices. However, most modern systems incorporate some form of data scrambling into their DRAM interfaces making cold boot attacks challenging. While first added as a measure to improve signal integrity and reduce power supply noise, these scramblers today serve the added purpose of obscuring the DRAM contents. It has previously been shown that scrambled DDR3 systems do not provide meaningful protection against cold boot attacks. In this paper, we investigate the enhancements that have been introduced in DDR4 memory scramblers in the 6th generation Intel Core (Skylake) processors. We then present an attack that demonstrates these enhanced DDR4 scramblers still do not provide sufficient protection against cold boot attacks. We detail a proof-of-concept attack that extracts memory resident AES keys, including disk encryption keys. The limitations of memory scramblers we point out in this paper motivate the need for strong yet low-overhead fullmemory encryption schemes. Existing schemes such as Intel's SGX can effectively prevent such attacks, but have overheads that may not be acceptable for performance-sensitive applications. However, it is possible to deploy a memory encryption scheme that has zero performance overhead by forgoing integrity checking and replay attack protections afforded by Intel SGX. To that end, we present analyses that confirm modern stream ciphers such as ChaCha8 are sufficiently fast that it is now possible to completely overlap keystream generation with DRAM row buffer access latency, thereby enabling the creation of strongly encrypted DRAMs with zero exposed latency. Adopting such low-overhead measures in future generation of products can effectively shut down cold boot attacks in systems where the overhead of existing memory encryption schemes is unacceptable. Furthermore, the emergence of non-volatile DIMMs that fit into DDR4 buses is going to exacerbate the risk of cold boot attacks. Hence, strong full memory encryption is going to be even more crucial on such systems.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920835","cold boot attack;memory;DRAM;security;cryptography","Random access memory;Encryption;Program processors;Registers;Capacitors;Data mining","","53","","35","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Cooperative Path-ORAM for Effective Memory Bandwidth Sharing in Server Settings","R. Wang; Y. Zhang; J. Yang","University of Pittsburgh, Pittsburgh, PA, US; University of Pittsburgh; University of Pittsburgh, Pittsburgh, PA, US",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","325","336","Path ORAM (Oblivious RAM) is a recently proposed ORAM protocol for preventing information leakage from memory access sequences. It receives wide adoption due to its simplicity, practical efficiency and asymptotic efficiency. However, Path ORAM has extremely large memory bandwidth demand, leading to severe memory competition in server settings, e.g., a server may service one application that uses Path ORAM and one or multiple applications that do not. While Path ORAM synchronously and intensively uses all memory channels, the non-secure applications often exhibit low access intensity and large channel level imbalance. Traditional memory scheduling schemes lead to wasted memory bandwidth to the system and large performance degradation to both types of applications. In this paper, we propose CP-ORAM, a Cooperative Path ORAM design, to effectively schedule the memory requests from both types of applications. CP-ORAM consists of three schemes: P-Path,R-Path, and W-Path. P-Path assigns and enforces scheduling priority for effective memory bandwidth sharing. R-Path maximizes bandwidth utilization by proactively scheduling read operations from the next Path ORAM access. W-Path mitigates contention on busy memory channels with write redirection. We evaluate CP-ORAM and compare it to the state-of-the-art. Our results show that CP-ORAM helps to achieve 20% performance improvement on average over the baseline Path ORAM for the secure application in a four-channel server setting.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920836","","Random access memory;Servers;Bandwidth;Degradation;Memory management;Cryptography","","28","","32","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Camouflage: Memory Traffic Shaping to Mitigate Timing Attacks","Y. Zhou; S. Wagh; P. Mittal; D. Wentzlaff","Electrical Engineering Department, Princeton University, Princeton, NJ, United States; Electrical Engineering Department, Princeton University, Princeton, NJ, United States; Electrical Engineering Department, Princeton University, Princeton, NJ, United States; Electrical Engineering Department, Princeton University, Princeton, NJ, United States",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","337","348","Information leaks based on timing side channels in computing devices have serious consequences for user security and privacy. In particular, malicious applications in multi-user systems such as data centers and cloud-computing environments can exploit memory timing as a side channel to infer a victim's program access patterns/phases. Memory timing channels can also be exploited for covert communications by an adversary. We propose Camouflage, a hardware solution to mitigate timing channel attacks not only in the memory system, but also along the path to and from the memory system (e.g. NoC, memory scheduler queues). Camouflage introduces the novel idea of shaping memory requests' and responses' interarrival time into a pre-determined distribution for security purposes, even creating additional fake traffic if needed. This limits untrusted parties (either cloud providers or coscheduled clients) from inferring information from another security domain by probing the bus to and from memory, or analyzing memory response rate. We design three different memory traffic shaping mechanisms for different security scenarios by having Camouflage work on requests, responses, and bi-directional (both) traffic. Camouflage is complementary to ORAMs and can be optionally used in conjunction with ORAMs to protect information leaks via both memory access timing and memory access patterns. Camouflage offers a tunable trade-off between system security and system performance. We evaluate Camouflage's security and performance both theoretically and via simulations, and find that Camouflage outperforms state-of-the-art solutions in performance by up to 50%.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920837","hardware;security;memory system","Timing;Security;Hardware;Memory management;Monitoring;Instruction sets;Shape","","29","","37","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"SILC-FM: Subblocked InterLeaved Cache-Like Flat Memory Organization","J. H. Ryoo; M. R. Meswani; A. Prodromou; L. K. John","The University of Texas at Austin, Austin, TX; ARM*, Austin, TX; UCSD, San Diego, CA; The University of Texas at Austin, Austin, TX",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","349","360","With current DRAM technology reaching its limit, emerging heterogeneous memory systems have become attractive to continue scaling memory performance. This paper argues for using a small, fast memory closer to the processor as part of a flat address space where the memory system is composed of two or more memory types. OS-transparent management of such memory has been proposed in prior works such as CAMEO and Part of Memory (PoM). Data migration is typically handled either at coarse granularity with high bandwidth overheads (as in PoM) or at fine granularity with low hit rate (as in CAMEO). Prior work uses restricted address mapping from only congruence groups in order to simplify the mapping. At any time, only one page (block) from a congruence group is resident in the fast memory. In this paper, we present a flat address space organization called SILC-FM that uses large granularity but allows subblocks from two pages to coexist in an interleaved fashion in fast memory. Data movement is done at subblocked granularity, avoiding fetching of useless subblocks and consuming less bandwidth compared to migrating the entire large block. SILC-FM can achieve more spatial locality hits than CAMEO and PoM due to page-level operation and interleaving blocks respectively. The interleaved subblock placement improves performance by 55% on average over a static placement scheme without data migration. We also selectively lock hot blocks to prevent them from being involved in hardware swapping operations. Additional features such as locking, associativity and bandwidth balancing improve performance by 11%, 8%, and 8% respectively, resulting in a total of 82% performance improvement over a no migration static placement scheme. Compared to the best state-of-the-art scheme, SILC-FM gets performance improvement of 36% with 13% energy savings.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920838","die-stacked DRMA;subblocked;flat memory","Bandwidth;Random access memory;Frequency modulation;Hardware;Memory management;Metadata;System-on-chip","","23","","44","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"ATOM: Atomic Durability in Non-volatile Memory through Hardware Logging","A. Joshi; V. Nagarajan; S. Viglas; M. Cintra","University of Edinburgh; University of Edinburgh; University of Edinburgh; Intel, Germany",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","361","372","Non-volatile memory (NVM) is emerging as a fast byte-addressable alternative for storing persistent data. Ensuring atomic durability in NVM requires logging. Existing techniques have proposed software logging either by using streaming stores for an undo log; or, by relying on the combination of clflush and mfence for a redo log. These techniques are suboptimal because they waste precious execution cycles to implement logging, which is fundamentally a data movement operation. We propose ATOM, a hardware log manager based on undo logging that performs the logging operation out of the critical path. We present the design principles behind ATOM and two techniques to optimize its performance. Our results show that ATOM achieves an improvement of 27% to 33% for micro-benchmarks and 60% for TPC-C over a baseline undo log design.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920839","non-volatile memory;atomicity;durability","Nonvolatile memory;Hardware;Software;Writing;Data structures;Data models;Computer crashes","","91","6","37","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"KAML: A Flexible, High-Performance Key-Value SSD","Y. Jin; H. -W. Tseng; Y. Papakonstantinou; S. Swanson","Department of Computer Science and Engineering, University of California, San Diego; Department of Computer Science and Engineering, University of California, San Diego; Department of Computer Science and Engineering, University of California, San Diego; Department of Computer Science and Engineering, University of California, San Diego",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","373","384","Modern solid state drives (SSDs) unnecessarily confine host programs to the conventional block I/O interface, leading to suboptimal performance and resource under-utilization. Recent attempts to replace or extend this interface with a key-value-oriented interface and/or built-in support for transactions offer some improvements, but the details of their implementations make them a poor match for many applications. This paper presents the key-addressable, multi-log SSD (KAML), an SSD with a key-value interface that uses a novel multi-log architecture and stores data as variable-sized records rather than fixed-sized sectors. Exposing a key-value interface allows applications to remove a layer of indirection between application-level keys (e.g., database record IDs or file inode numbers) and data stored in the SSD. KAML also provides native transaction support tuned to support fine-grained locking, achieving improved performance compared to previous designs that require page-level locking. Finally, KAML includes a caching layer analogous to a conventional page cache that leverages host DRAM to improve performance and provides additional transactional features. We have implemented a prototype of KAML on a commercial SSD prototyping platform, and our results show that compared with existing key-value stores, KAML improves the performance of online transaction processing (OLTP) workloads by 1.1x - 4.0x, and NoSQL key-value store applications by 1.1x - 3.0x.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920840","","Atomic layer deposition;Databases;Proposals;Protocols;Nonvolatile memory;Random access memory;Flash memories","","54","1","47","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Balancing Performance and Lifetime of MLC PCM by Using a Region Retention Monitor","M. Zhang; L. Zhang; L. Jiang; Z. Liu; F. T. Chong","Computer Science Department, University of Chicago, Beijing, China; Computer Science Department, University of Chicago; Department fo Intelligent Systems Engineering, Indiana University Bloomington; ICT, University of Chicago, Beijing, China; Computer Science Department, University of Chicago",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","385","396","Multi Level Cell (MLC) Phase Change Memory (PCM) is an enhancement of PCM technology, which provides higher capacity by allowing multiple digital bits to be stored in a single PCM cell. However, the retention time of MLC PCM is limited by the resistance drift problem and refresh operations are required. Previous work shows that there exists a trade-off between write latency and retention-a write scheme with more SET iterations and smaller current provides a longer retention time but at the cost of a longer write latency. Otherwise, a write scheme with fewer SET iterations achieves high performance for writes but requires a greater number of refresh operations due to its significantly reduced retention time, and this hurts the lifetime of MLC PCM. In this paper, we show that only a small part of memory (i.e., hot memory regions) will be frequently accessed in a given period of time. Based on such an observation, we propose Region Retention Monitor (RRM), a novel structure that records and predicts the write frequency of memory regions. For every incoming memory write operation, RRM select a proper write latency for it. Our evaluations show that RRM helps the system improves the balance between system performance and memory lifetime. On the performance side, the system with RRM bridges 77.2% of the performance gap between systems with long writes and systems with short writes. On the lifetime side, a system with RRM achieves a lifetime of 6.4 years, while systems using only long writes and short writes achieve lifetimes of 10.6 and 0.3 years, respectively. Also, we can easily control the aggressiveness of RRM through an attribute called hot threshold. A more aggressively configured RRM can achieve the performance which is only 3.5% inferior than the system using static short writes, while still achieve a lifetime of 5.78 years.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920841","Non-Volatile Memory;Phase Change Memory;Dynamic Trade-off","Phase change materials;Resistance;Microprocessors;Memory management;Monitoring;Phase change memory","","28","","38","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Reliability-Aware Scheduling on Heterogeneous Multicore Processors","A. Naithani; S. Eyerman; L. Eeckhout","Ghent University, Belgium; Intel, Ghent University, Belgium; Ghent University, Belgium",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","397","408","Reliability to soft errors is an increasingly important issue as technology continues to shrink. In this paper, we show that applications exhibit different reliability characteristics on big, high-performance cores versus small, power-efficient cores, and that there is significant opportunity to improve system reliability through reliability-aware scheduling on heterogeneous multicore processors. We monitor the reliability characteristics of all running applications, and dynamically schedule applications to the different core types in a heterogeneous multicore to maximize system reliability. Reliability-aware scheduling improves reliability by 25.4% on average (and up to 60.2%) compared to performance-optimized scheduling on a heterogeneous multicore processor with two big cores and two small cores, while degrading performance by 6.3% only. We also introduce a novel system-level reliability metric for multiprogram workloads on (heterogeneous) multicores. We further show that our reliability-aware scheduler is robust across core count, number of big and small cores, and their frequency settings. The hardware cost in support of our reliability-aware scheduler is limited to 296 bytes per core.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920842","heterogeneous multicore processor;reliability;scheduling","Reliability;Multicore processing;Program processors;Measurement;Benchmark testing;Job shop scheduling;Error analysis","","28","","31","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Hipster: Hybrid Task Manager for Latency-Critical Cloud Workloads","R. Nishtala; P. Carpenter; V. Petrucci; X. Martorell","Universitat Politècnica de Catalunya, Barcelona, Spain; Barcelona Supercomputing Center, Barcelona, Spain; Federal University of Bahia, Salvador, Brazil; Universitat Politècnica de Catalunya, Barcelona, Spain",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","409","420","In 2013, U.S. data centers accounted for 2.2% of the country's total electricity consumption, a figure that is projected to increase rapidly over the next decade. Many important workloads are interactive, and they demand strict levels of quality-of-service (QoS) to meet user expectations, making it challenging to reduce power consumption due to increasing performance demands. This paper introduces Hipster, a technique that combines heuristics and reinforcement learning to manage latency-critical workloads. Hipster's goal is to improve resource efficiency in data centers while respecting the QoS of the latency-critical workloads. Hipster achieves its goal by exploring heterogeneous multi-cores and dynamic voltage and frequency scaling (DVFS). To improve data center utilization and make best usage of the available resources, Hipster can dynamically assign remaining cores to batch workloads without violating the QoS constraints for the latency-critical workloads. We perform experiments using a 64-bit ARM big.LITTLE platform, and show that, compared to prior work, Hipster improves the QoS guarantee for Web-Search from 80% to 96%, and for Memcached from 92% to 99%, while reducing the energy consumption by up to 18%.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920843","","Quality of service;Power demand;Energy consumption;Servers;Learning (artificial intelligence);Resource management;Throughput","","52","","62","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Cooper: Task Colocation with Cooperative Games","Q. Llull; S. Fan; S. M. Zahedi; B. C. Lee",Duke University; Duke University; Duke University; Duke University,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","421","432","Task colocation improves datacenter utilization but introduces resource contention for shared hardware. In this setting, a particular challenge is balancing performance and fairness. We present Cooper, a game-theoretic framework for task colocation that provides fairness while preserving performance. Cooper predicts users' colocation preferences and finds stable matches between them. Its colocations satisfy preferences and encourage strategic users to participate inshared systems. Given Cooper's colocations, users' performance penalties are strongly correlated to their contributions to contention, which is fair according to cooperative game theory. Moreover, its colocations perform within 5% of prior heuristics.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920844","Datacenter Management;Task Colocation;Interference;Performance Prediction;Fairness;Game Theory","Games;Hardware;Game theory;Throughput;Bandwidth;Servers;Stability analysis","","16","","48","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"MemPod: A Clustered Architecture for Efficient and Scalable Migration in Flat Address Space Multi-level Memories","A. Prodromou; M. Meswani; N. Jayasena; G. Loh; D. M. Tullsen","University of California, San Diego; ARM, AMD Research; AMD Research; AMD Research; University of California, San Diego",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","433","444","In the near future, die-stacked DRAM will be increasingly present in conjunction with off-chip memories in hybrid memory systems. Research on this subject revolves around using the stacked memory as a cache or as part of a flat address space. This paper proposes MemPod, a scalable and efficient memory management mechanism for flat address space hybrid memories. MemPod monitors memory activity and periodically migrates the most frequently accessed memory pages to the faster on-chip memory. MemPod's partitioned architectural organization allows for efficient scaling with memory system capabilities. Further, a big data analytics algorithm is adapted to develop an efficient, low-cost activity tracking technique. MemPod improves the average main memory access time of multi-programmed workloads, by up to 29% (9% on average) compared to the state of the art, and that will increase as the differential between memory speeds widens. MemPod's novel activity tracking approach leads to significant cost reduction (~12800x lower storage space requirements) and improved future prediction accuracy over prior work which maintains a separate counter per page.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920845","Memory architecture;Die-stacked memory","Radiation detectors;Memory management;Random access memory;Hardware;Organizations;Software;Monitoring","","34","","32","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Exploring Hyperdimensional Associative Memory","M. Imani; A. Rahimi; D. Kong; T. Rosing; J. M. Rabaey","CSE UC San Diego, CA, USA; EECS, UC Berkeley, Berkeley, CA, USA; CSE UC San Diego, CA, USA; CSE UC San Diego, CA, USA; EECS, UC Berkeley, Berkeley, CA, USA",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","445","456","Brain-inspired hyperdimensional (HD) computing emulates cognition tasks by computing with hypervectors as an alternative to computing with numbers. At its very core, HD computing is about manipulating and comparing large patterns, stored in memory as hypervectors: the input symbols are mapped to a hypervector and an associative search is performed for reasoning and classification. For every classification event, an associative memory is in charge of finding the closest match between a set of learned hypervectors and a query hypervector by using a distance metric. Hypervectors with the i.i.d. components qualify a memory-centric architecture to tolerate massive number of errors, hence it eases cooperation of various methodological design approaches for boosting energy efficiency and scalability. This paper proposes architectural designs for hyperdimensional associative memory (HAM) to facilitate energy-efficient, fast, and scalable search operation using three widely-used design approaches. These HAM designs search for the nearest Hamming distance, and linearly scale with the number of dimensions in the hypervectors while exploring a large design space with orders of magnitude higher efficiency. First, we propose a digital CMOS-based HAM (D-HAM) that modularly scales to any dimension. Second, we propose a resistive HAM (R-HAM) that exploits timing discharge characteristic of nonvolatile resistive elements to approximately compute Hamming distances at a lower cost. Finally, we combine such resistive characteristic with a currentbased search method to design an analog HAM (A-HAM) that results in faster and denser alternative. Our experimental results show that R-HAM and A-HAM improve the energy-delay product by 9.6× and 1347× compared to D-HAM while maintaining a moderate accuracy of 94% in language recognition.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920846","Associative memory;Hyperdimensional computing;Neuromorphic computing;Non-volatile memory","Computer architecture","","179","","29","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"GraphPIM: Enabling Instruction-Level PIM Offloading in Graph Computing Frameworks","L. Nai; R. Hadidi; J. Sim; H. Kim; P. Kumar; H. Kim","Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA; Intel Labs, Portland, OR; Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","457","468","With the emergence of data science, graph computing has become increasingly important these days. Unfortunately, graph computing typically suffers from poor performance when mapped to modern computing systems because of the overhead of executing atomic operations and inefficient utilization of the memory subsystem. Meanwhile, emerging technologies, such as Hybrid Memory Cube (HMC), enable the processing-in-memory (PIM) functionality with offloading operations at an instruction level. Instruction offloading to the PIM side has considerable potentials to overcome the performance bottleneck of graph computing. Nevertheless, this functionality for graph workloads has not been fully explored, and its applications and shortcomings have not been well identified thus far. In this paper, we present GraphPIM, a full-stack solution for graph computing that achieves higher performance using PIM functionality. We perform an analysis on modern graph workloads to assess the applicability of PIM offloading and present hardware and software mechanisms to efficiently make use of the PIM functionality. Following the real-world HMC 2.0 specification, GraphPIM provides performance benefits for graph applications without any user code modification or ISA changes. In addition, we propose an extension to PIM operations that can further bring performance benefits for more graph applications. The evaluation results show that GraphPIM achieves up to a 2.4× speedup with a 37% reduction in energy consumption.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920847","processing-in-memory;PIM;graph computing;hybrid memory cube;HMC","Computer architecture;Hardware;Random access memory;Metadata;Software;Complexity theory;Atomic measurements","","204","","54","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"High-Bandwidth Low-Latency Approximate Interconnection Networks","D. Fujiki; K. Ishii; I. Fujiwara; H. Matsutani; H. Amano; H. Casanova; M. Koibuchi","National Institute of Informatics, JAPAN; National Institute of Advanced Industrial Science and Technology (AIST), JAPAN; National Institute of Informatics, JAPAN; Keio University, JAPAN; Keio University, JAPAN; University of Hawaii, Manoa; National Institute of Informatics, JAPAN",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","469","480","Computational applications are subject to various kinds of numerical errors, ranging from deterministic roundoff errors to soft errors caused by non-deterministic bit flips, which do not lead to application failure but corrupt application results. Non-deterministic bit flips are typically mitigated in hardware using various error correcting codes (ECC). But in practice, due to performance and cost concerns, these techniques do not guarantee error-free execution. On large-scale computing platforms, soft errors occur with non-negligible probability in RAM and on the CPU, and it has become clear that applications must tolerate them. For some applications, this tolerance is intrinsic as result quality can remain acceptable even in the presence of soft errors (e.g., data analysis applications, multimedia applications). Tolerance can also be built into the application, resolving data corruptions in software during application execution. By contrast, today's optical networks hold on to a rigid error-free standard, which imposes limits on network performance scalability. In this work we propose high-bandwidth, low-latency approximate networks with the following three features: (1) Optical links that exploit multi-level quadrature amplitude modulation (QAM) for achieving high bandwidth; (2) Avoidance of forward error correction (FEC), which makes optical link error-prone but affords lower latency; and (3) The use of symbol mapping coding between bit sequence and QAM to ensure data integrity that is sufficient for practical soft-error-tolerant applications. Discrete-event simulation results for application benchmarks show that approx networks achieve speedups up to 2.94 when compared to conventional networks.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.38","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920848","Approximate computing;Interconnect and network interface architectures","Optical switches;Forward error correction;Bandwidth;Optical packet switching;Optical interconnections;Network topology","","17","","45","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Compute Caches","S. Aga; S. Jeloka; A. Subramaniyan; S. Narayanasamy; D. Blaauw; R. Das","University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","481","492","This paper presents the Compute Cache architecture that enables in-place computation in caches. Compute Caches uses emerging bit-line SRAM circuit technology to re-purpose existing cache elements and transforms them into active very large vector computational units. Also, it significantly reduces the overheads in moving data between different levels in the cache hierarchy. Solutions to satisfy new constraints imposed by Compute Caches such as operand locality are discussed. Also discussed are simple solutions to problems in integrating them into a conventional cache hierarchy while preserving properties such as coherence, consistency, and reliability. Compute Caches increase performance by 1.9× and reduce energy by 2.4× for a suite of data-centric applications, including text and database query processing, cryptographic kernels, and in-memory checkpointing. Applications with larger fraction of Compute Cache operations could benefit even more, as our micro-benchmarks indicate (54× throughput, 9× dynamic energy savings).","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920849","Cache;Data Movement;Vector Processing;In-Memory Processing;Performance;Energy","Computer architecture;Program processors;Random access memory;Robustness;Geometry;Throughput;Databases","","271","1","32","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Boomerang: A Metadata-Free Architecture for Control Flow Delivery","R. Kumar; C. -C. Huang; B. Grot; V. Nagarajan","Institute of Computing Systems Architecture, University of Edinburgh; Institute of Computing Systems Architecture, University of Edinburgh; Institute of Computing Systems Architecture, University of Edinburgh; Institute of Computing Systems Architecture, University of Edinburgh",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","493","504","Contemporary server workloads feature massive instruction footprints stemming from deep, layered software stacks. The active instruction working set of the entire stack can easily reach into megabytes, resulting in frequent frontend stalls due to instruction cache misses and pipeline flushes due to branch target buffer (BTB) misses. While a number of techniques have been proposed to address these problems, every one of them requires dedicated metadata structures, translating into significant storage and complexity costs. In this paper, we ask the question whether it is possible to achieve high-performance control flow delivery without the metadata costs of prior techniques. We revisit a previously proposed approach of branch-predictor-directed prefetching, which leverages just the branch predictor and BTB to discover and prefetch the missing instruction cache blocks by exploring the program control flow ahead of the core front-end. Contrary to conventional wisdom, we find that this approach can be effective in covering instruction cache misses in modern CMPs with long LLC access latencies and multi-MB server binaries. Our first contribution lies in explaining the reasons for the efficacy of branch-predictor-directed prefetching. Our second contribution is in Boomerang, a metadata-free architecture for control flow delivery. Boomerang leverages a branch-predictor-directed prefetcher to discover and prefill not only the instruction cache blocks, but also the missing BTB entries. Crucially, we demonstrate that the additional hardware cost required to identify and fill BTB misses is negligible. Our experimental evaluation shows that Boomerang matches the performance of the state-of-the-art control flow delivery scheme without the latter's high metadata and complexity overheads.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.53","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920850","Server Processors;Microarchitecture;Core Front-end;Instruction Prefetching;BTB Prefetching;Branch-predictor-directed Prefetching;Control Flow Delivery","Prefetching;Servers;Metadata;Pipelines;Complexity theory","","44","1","25","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"PABST: Proportionally Allocated Bandwidth at the Source and Target","D. R. Hower; H. W. Cain; C. A. Waldspurger",Qualcomm Technologies Inc; Qualcomm Datacenter Technologies Inc; Qualcomm Datacenter Technologies Inc,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","505","516","Higher integration lowers total cost of ownership (TCO) in the data center by reducing equipment cost and lowering energy consumption. However, higher integration also makes it difficult to achieve guaranteed quality of service (QoS) for shared resources. Unlike many other resources, memory bandwidth cannot be finely controlled by software in existing systems. As a result, many systems running critical, bandwidth-sensitive applications remain underutilized to protect against bandwidth interference. In this paper, we propose a novel hardware architecture allowing practical, software-controlled partitioning of memory bandwidth. Proportionally Allocated Bandwidth at the Source and Target (PABST) precisely controls the bandwidth of applications by throttling request rates at the source and prioritizes requests at the target. We show that PABST is work conserving, such that excess bandwidth beyond the requested allocation will not go unused. For applications sensitive to memory latency, we pair PABST with a simple priority scheme at the memory controller. We show that when combined, the system is able to lower TCO by providing performance isolation across a wide range of workloads, even when co-located with memory-intensive background jobs.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920851","quality of service;memory bandwidth;proportional share;manycore;data center","Bandwidth;Quality of service;Resource management;Computer architecture;Channel allocation;Software;Regulators","","4","","50","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"SOUP-N-SALAD: Allocation-Oblivious Access Latency Reduction with Asymmetric DRAM Microarchitectures","Y. Ro; H. Cho; E. Lee; D. Jung; Y. H. Son; J. H. Ahn; J. W. Lee",Seoul National University; Samsung Electronics; Seoul National University; Seoul National University; Samsung Electronics; Seoul National University; Seoul National University,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","517","528","Memory access latency has a significant impact on application performance. Unfortunately, the random access latency of DRAM has been scaling relatively slowly, and often directly affects the critical path of execution, especially for applications with insufficient locality or memory-level parallelism. The existing low-latency DRAM organizations either incur significant area overhead or burden the software stack with non-uniform access latency. This paper proposes two microarchitectural techniques to provide uniformly low access time over the entire DRAM chip. The first technique is SALAD, a new DRAM device architecture that provides symmetric access latency with asymmetric DRAM bank organizations. Because local regions have lower data transfer time due to their proximity to the I/O pads, SALAD applies high aspectratio (i.e., low-latency) mats only to remote regions to offset the difference in data transfer time, resulting in symmetrically low latency across regions. The second technique is SOUP (skewed organization of μbanks with pipelined accesses), which leverages asymmetry in column access latency within a region due to non-uniform distance to the column decoders. By starting I/O transfers as soon as data from near cells arrive, instead of waiting for the entire column data, SOUP further saves two memory clock cycles for column accesses for all regions. The resulting design, called SOUP-N-SALAD, improves IPC and EDP by 9.6% (11.2%) and 18.2% (21.8%) over the baseline DDR4 device, respectively, for memory-intensive SPEC CPU2006 workloads without any software modifications, while incurring only 3% (6%) area overhead.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.31","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920852","DRAM;symmetric access latency;asymmetric DRAM bank organizations;skewed and pipelined accesses","Random access memory;Organizations;Software;Performance evaluation;Memory management;Hardware","","6","","48","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Transparent and Efficient CFI Enforcement with Intel Processor Trace","Y. Liu; P. Shi; X. Wang; H. Chen; B. Zang; H. Guan","Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University; Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University; Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University; Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University; Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University; Shanghai Key Laboratory for Scalable Computing and Systems, Shanghai Jiao Tong University",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","529","540","Current control flow integrity (CFI) enforcement approaches either require instrumenting application executables and even shared libraries, or are unable to defend against sophisticated attacks due to relaxed security policies, or both; many of them also incur high runtime overhead. This paper observes that the main obstacle of providing transparent and strong defense against sophisticated adversaries is the lack of sufficient runtime control flow information. To this end, this paper describes FlowGuard, a lightweight, transparent CFI enforcement approach by a novel reuse of Intel Processor Trace (IPT), a recent hardware feature that efficiently captures the entire runtime control flow. The main challenge is that IPT is designed for offline performance analysis and software debugging such that decoding collected control flow traces is prohibitively slow on the fly. FlowGuard addresses this challenge by reconstructing applications' conservative control flow graphs (CFG) to be compatible with the compressed encoding format of IPT, and labeling the CFG edges with credits in the help of fuzzing-like dynamic training. At runtime, FlowGuard separates fast and slow paths such that the fast path compares the labeled CFGs with the IPT traces for fast filtering, while the slow path decodes necessary IPT traces for strong security. We have implemented and evaluated FlowGuard on a commodity Intel Skylake machine with IPT support. Evaluation results show that FlowGuard is effective in enforcing CFI for several applications, while introducing only small performance overhead. We also show that, with minor hardware extensions, the performance overhead can be further reduced.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920853","Control-flow integrity;Intel processor trace","Decoding;Runtime;Hardware;Security;Libraries;Instruments;Registers","","61","3","50","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"PipeLayer: A Pipelined ReRAM-Based Accelerator for Deep Learning","L. Song; X. Qian; H. Li; Y. Chen","University of Pittsburgh; University of Southern, California; NA; University of Pittsburgh",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","541","552","Convolution neural networks (CNNs) are the heart of deep learning applications. Recent works PRIME [1] and ISAAC [2] demonstrated the promise of using resistive random access memory (ReRAM) to perform neural computations in memory. We found that training cannot be efficiently supported with the current schemes. First, they do not consider weight update and complex data dependency in training procedure. Second, ISAAC attempts to increase system throughput with a very deep pipeline. It is only beneficial when a large number of consecutive images can be fed into the architecture. In training, the notion of batch (e.g. 64) limits the number of images can be processed consecutively, because the images in the next batch need to be processed based on the updated weights. Third, the deep pipeline in ISAAC is vulnerable to pipeline bubbles and execution stall. In this paper, we present PipeLayer, a ReRAM-based PIM accelerator for CNNs that support both training and testing. We analyze data dependency and weight update in training algorithms and propose efficient pipeline to exploit inter-layer parallelism. To exploit intra-layer parallelism, we propose highly parallel design based on the notion of parallelism granularity and weight replication. With these design choices, PipeLayer enables the highly pipelined execution of both training and testing, without introducing the potential stalls in previous work. The experiment results show that, PipeLayer achieves the speedups of 42.45x compared with GPU platform on average. The average energy saving of PipeLayer compared with GPU implementation is 7.17x.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920854","","Training;Neural networks;Machine learning;Computer architecture;Pipelines;Testing;Kernel","","690","6","68","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"FlexFlow: A Flexible Dataflow Accelerator Architecture for Convolutional Neural Networks","W. Lu; G. Yan; J. Li; S. Gong; Y. Han; X. Li","University of Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","553","564","Convolutional Neural Networks (CNN) are very computation-intensive. Recently, a lot of CNN accelerators based on the CNN intrinsic parallelism are proposed. However, we observed that there is a big mismatch between the parallel types supported by computing engine and the dominant parallel types of CNN workloads. This mismatch seriously degrades resource utilization of existing accelerators. In this paper, we propose a flexible dataflow architecture (FlexFlow) that can leverage the complementary effects among feature map, neuron, and synapse parallelism to mitigate the mismatch. We evaluated our design with six typical practical workloads, it acquires 2-10x performance speedup and 2.5-10x power efficiency improvement compared with three state-of-the-art accelerator architectures. Meanwhile, FlexFlow is highly scalable with growing computing engine scale.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920855","Flexible Dataflow;Complementary Effect;Convolutional Neural Networks;Accelerator","Parallel processing;Neurons;Computer architecture;Kernel;Clocks;Pipelines;Biological neural networks","","272","5","30","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Needle: Leveraging Program Analysis to Analyze and Extract Accelerators from Whole Programs","S. Kumar; N. Sumner; V. Srinivasan; S. Margerm; A. Shriraman",Simon Fraser University; Simon Fraser University; IBM Research; Simon Fraser University; Simon Fraser University,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","565","576","Technology constraints have increasingly led to the adoption of specialized coprocessors, i.e. hardware accelerators. The first challenge that computer architects encounter is identifying “what to specialize in the program”. We demonstrate that this requires precise enumeration of program paths based on dynamic program behavior. We hypothesize that path-based [4] accelerator offloading leads to good coverage of dynamic instructions and improve energy efficiency. Unfortunately, hot paths across programs demonstrate diverse control flow behavior. Accelerators (typically based on dataflow execution), often lack an energy-efficient, complexity effective, and high performance (eg. branch prediction) support for control flow. We have developed NEEDLE, an LLVM based compiler framework that leverages dynamic profile information to identify, merge, and offload acceleratable paths from whole applications. NEEDLE derives insight into what code coverage (and consequently energy reduction) an accelerator can achieve. We also develop a novel program abstraction for offload calledBraid, that merges common code regions across different paths to improve coverage of the accelerator while trading off the increase in dataflow size. This enables coarse grained offloading, reducing interaction with the host CPU core. To prepare the Braids and paths for acceleration, NEEDLE generates software frames. Software frames enable energy efficient speculative execution on accelerators. They are accelerator microarchitecture independent support speculative execution including memory operations. NEEDLE is automated and has been used to analyze 225K paths across 29 workloads. It filtered and ranked 154K paths for acceleration across unmodified SPEC, PARSEC and PERFECT workload suites. We target NEEDLE's offload regions toward a CGRA and demonstrate 34% performance and 20% energy improvement.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.59","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920856","Synthesis;Hardware Accelerators;Program analysis;LLVM;Speculation;Braids;Hyperblocks;Frames;Traces;Energy Efficiency","Needles;Hardware;Acceleration;Out of order;Complexity theory;Compounds","","10","","46","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Radiation-Induced Error Criticality in Modern HPC Parallel Accelerators","D. A. G. D. Oliveira; L. L. Pilla; M. Hanzich; V. Fratin; F. Fernandes; C. Lunardi; J. M. Cela; P. O. A. Navaux; L. Carro; P. Rech","Institute of Informatics, UFRGS, Porto, Alegre, Brazil; Department of Informatics and Statistics, UFSC, Florianópolis, Brazil; CASE Department, Barcelona Supercomputing Center, Barcelona, Spain; Institute of Informatics, UFRGS, Porto, Alegre, Brazil; Institute of Informatics, UFRGS, Porto, Alegre, Brazil; Institute of Informatics, UFRGS, Porto, Alegre, Brazil; CASE Department, Barcelona Supercomputing Center, Barcelona, Spain; Institute of Informatics, UFRGS, Porto, Alegre, Brazil; NA; Institute of Informatics, UFRGS, Porto, Alegre, Brazil",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","577","588","In this paper, we evaluate the error criticality of radiation-induced errors on modern High-Performance Computing (HPC) accelerators (Intel Xeon Phi and NVIDIA K40) through a dedicated set of metrics. We show that, as long as imprecise computing is concerned, the simple mismatch detection is not sufficient to evaluate and compare the radiation sensitivity of HPC devices and algorithms. Our analysis quantifies and qualifies radiation effects on applications' output correlating the number of corrupted elements with their spatial locality. Also, we provide the mean relative error (dataset-wise) to evaluate radiation-induced error magnitude. We apply the selected metrics to experimental results obtained in various radiation test campaigns for a total of more than 400 hours of beam time per device. The amount of data we gathered allows us to evaluate the error criticality of a representative set of algorithms from HPC suites. Additionally, based on the characteristics of the tested algorithms, we draw generic reliability conclusions for broader classes of codes. We show that arithmetic operations are less critical for the K40, while Xeon Phi is more reliable when executing particles interactions solved through Finite Difference Methods. Finally, iterative stencil operations seem the most reliable on both architectures.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.41","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920857","Radiation-induced errors;HPC sensitivity;Fault Tolerance","Reliability;Computer architecture;Measurement;Neutrons;Resilience;Computer crashes;Supercomputers","","32","","47","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Pilot Register File: Energy Efficient Partitioned Register File for GPUs","M. Abdel-Majeed; A. Shafaei; H. Jeon; M. Pedram; M. Annavaram","Computer Engineering Department, University of Jordan, Jordan; Computer Engineering Department, San Jose State University, USA; Computer Engineering Department, University of Southern California, USA; Computer Engineering Department, University of Jordan, Jordan; Computer Engineering Department, University of Jordan, Jordan",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","589","600","GPU adoption for general purpose computing has been accelerating. To support a large number of concurrently active threads, GPUs are provisioned with a very large register file (RF). The RF power consumption is a critical concern. One option to reduce the power consumption dramatically is to use near-threshold voltage(NTV) to operate the RF. However, operating MOSFET devices at NTV is fraught with stability and reliability concerns. The adoption of FinFET devices in chip industry is providing a promising path to operate the RF at NTV while satisfactorily tackling the stability and reliability concerns. However, the fundamental problem of NTV operation, namely slow access latency, remains. To tackle this challenge in this paper we propose to build a partitioned RF using FinFET technology. The partitioned RF design exploits our observation that applications exhibit strong preference to utilize a small subset of their registers. One way to exploit this behavior is to cache the RF content as has been proposed in recent works. However, caching leads to unnecessary area overheads since a fraction of the RF must be replicated. Furthermore, we show that caching is not efficient as we increase the number of issued instructions per cycle, which is the expected trend in GPU designs. The proposed partitioned RF splits the registers into two partitions: the highly accessed registers are stored in a small RF that switches between high and low power modes. We use the FinFET's back gate control to provide low overhead switching between the two power modes. The remaining registers are stored in a large RF partition that always operates at NTV. The assignment of the registers to the two partitions will be based on statistics collected by the a hybrid profiling technique that combines the compiler based profiling and the pilot warp profiling technique proposed in this paper. The partitioned FinFET RF is able to save 39% and 54% of the RF leakage and the dynamic energy, respectively, and suffers less than 2% performance overhead.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920858","GPUs;Register File;Low power;FinFET","Registers;Radio frequency;FinFETs;Kernel;Delays;Graphics processing units;Logic gates","","27","","38","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"G-Scalar: Cost-Effective Generalized Scalar Execution Architecture for Power-Efficient GPUs","Z. Liu; S. Gilani; M. Annavaram; N. S. Kim",University of Illinois Urbana-Champaign; AMD; University of Southern California; University of Illinois Urbana-Champaign,2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","601","612","The GPU has provide higher throughput by integrating more execution resources into a single chip without unduly compromising power efficiency. With the power wall challenge, however, increasing the throughput will require significant improvement in power efficiency. To accomplish this goal, we propose G-Scalar, a cost-effective generalized scalar execution architecture for GPUs in this paper. G-Scalar offers two key advantages over prior architectures supporting scalar execution for only non-divergent arithmetic/logic instructions. First, G-Scalar is more power-efficient as it can also support scalar execution of divergent and special-function instructions, the fraction of which in contemporary GPU applications has notably increased. Second, G-Scalar is less expensive as it can share most of its hardware resources with register value compression, of which adoption has been strongly promoted to reduce high power consumption of accessing the large register file. Compared with the baseline and previous scalar architectures, G-Scalar improves power efficiency by 24% and 15%, respectively, at a negligible cost.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920859","GPU;scalar execution;register file;register file compression","Registers;Graphics processing units;Pipelines;Hardware;Computer architecture;Microarchitecture;Power demand","","17","","33","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Dynamic GPGPU Power Management Using Adaptive Model Predictive Control","A. Majumdar; L. Piga; I. Paul; J. L. Greathouse; W. Huang; D. H. Albonesi","Computer System Laboratory, Cornell University, Ithaca, NY, USA; AMD Research, Advanced Micro Devices Inc, Austin, TX, USA; AMD Research, Advanced Micro Devices Inc, Austin, TX, USA; AMD Research, Advanced Micro Devices Inc, Austin, TX, USA; AMD Research, Advanced Micro Devices Inc, Austin, TX, USA; Computer System Laboratory, Cornell University, Ithaca, NY, USA",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","613","624","Modern processors can greatly increase energy efficiency through techniques such as dynamic voltage and frequency scaling. Traditional predictive schemes are limited in their effectiveness by their inability to plan for the performance and energy characteristics of upcoming phases. To date, there has been little research exploring more proactive techniques that account for expected future behavior when making decisions. This paper proposes using Model Predictive Control (MPC) to attempt to maximize the energy efficiency of GPU kernels without compromising performance. We develop performance and power prediction models for a recent CPU-GPU heterogeneous processor. Our system then dynamically adjusts hardware states based on recent execution history, the pattern of upcoming kernels, and the predicted behavior of those kernels. We also dynamically trade off the performance overhead and the effectiveness of MPC in finding the best configuration by adapting the horizon length at runtime. Our MPC technique limits performance loss by proactively spending energy on the kernel iterations that will gain the most performance from that energy. This energy can then be recovered in future iterations that are less performance sensitive. Our scheme also avoids wasting energy on low-throughput phases when it foresees future high-throughput kernels that could better use that energy. Compared to state-of-the-practice schemes, our approach achieves 24.8% energy savings with a performance loss (including MPC overheads) of 1.8%. Compared to state-of-the-art history-based schemes, our approach achieves 6.6% chip-wide energy savings while simultaneously improving performance by 9.6%.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920860","","Kernel;Graphics processing units;Hardware;Niobium;Throughput;Benchmark testing;Performance evaluation","","31","","49","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Efficient Sequential Consistency in GPUs via Relativistic Cache Coherence","X. Ren; M. Lis","University of British, Columbia; University of British, Columbia",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","625","636","Recent work has argued that sequential consistency (SC) in GPUs can perform on par with weak memory models, provided ordering stalls are made less frequent by relaxing ordering for private and read-only data. In this paper, we address the complementary problem of reducing stall latencies for both read-only and read-write data. We find that SC stalls are particularly problematic for workloads with inter-workgroup sharing, and occur primarily due to earlier stores in the same thread; a substantial part of the overhead comes from the need to stall until write permissions are obtained (to ensure write atomicity). To address this, we propose RCC, a GPU coherence protocol which grants write permissions without stalling but can still be used to implement SC. RCC uses logical timestamps to determine a global memory order and L1 read permissions; even though each core may see a different logical ""time,"" SC ordering can still be maintained. Unlike previous GPU SC proposals, our design does not require invasive core changes and additional per-core storage to classify read-only/private data. For workloads with interworkgroup sharing overall performance is 29% better and energy is 25% less than in best previous GPU SC proposals, and within 7% of the best non-SC design.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920861","GPU;coherence;consistency","Computer architecture","","20","","75","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Processing-in-Memory Enabled Graphics Processors for 3D Rendering","C. Xie; S. L. Song; J. Wang; W. Zhang; X. Fu","ECE Department, University of Houston; HPC group, Pacific Northwest National Lab (PNNL); College of Information Engineering, Capital Normal University; College of Information Engineering, Capital Normal University; ECE Department, University of Houston",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","637","648","The performance of 3D rendering of Graphics Processing Unit that converts 3D vector stream into 2D frame with 3D image effects significantly impacts users gaming experience on modern computer systems. Due to its high texture throughput requirement, main memory bandwidth becomes a critical obstacle for improving the overall rendering performance. 3D-stacked memory systems such as Hybrid Memory Cube provide opportunities to significantly overcome the memory wall by directly connecting logic controllers to DRAM dies. Although recent works have shown promising improvement in performance by utilizing HMC to accelerate special-purpose applications, a critical challenge of how to effectively leverage its high internal bandwidth and computing capability in GPU for 3D rendering remains unresolved. Based on the observation that texel fetches greatly impact off-chip memory traffic, we propose two architectural designs to enable Processing-In-Memory based GPU for efficient 3D rendering. Additionally, we employ camera angles of pixels to control the performance-quality tradeoff of 3D rendering. Extensive evaluation across several real-world games demonstrates that our design can significantly improve the performance of texture filtering and 3D rendering by an average of 3.97X (up to 6.4X) and 43% (up to 65%) respectively, over the baseline GPU. Meanwhile, our design provides considerable memory traffic and energy reduction without sacrificing rendering quality.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920862","GPU;Processing-In-Memory;3D-Stacked Memory;Approximate Computing;3D Rendering","Three-dimensional displays;Rendering (computer graphics);Graphics processing units;Bandwidth;Memory management;Through-silicon vias;Random access memory","","33","1","46","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
"Controlled Kernel Launch for Dynamic Parallelism in GPUs","X. Tang; A. Pattnaik; H. Jiang; O. Kayiran; A. Jog; S. Pai; M. Ibrahim; M. T. Kandemir; C. R. Das","Pennsylvania State University; Pennsylvania State University; Pennsylvania State University; Advanced Micro Devices Inc; College of William and Mary; University of Texas, Austin; College of William and Mary; Pennsylvania State University; Pennsylvania State University",2017 IEEE International Symposium on High Performance Computer Architecture (HPCA),"8 May 2017","2017","","","649","660","Dynamic parallelism (DP) is a promising feature for GPUs, which allows on-demand spawning of kernels on the GPU without any CPU intervention. However, this feature has two major drawbacks. First, the launching of GPU kernels can incur significant performance penalties. Second, dynamically-generated kernels are not always able to efficiently utilize the GPU cores due to hardware-limits. To address these two concerns cohesively, we propose SPAWN, a runtime framework that controls the dynamically-generated kernels, thereby directly reducing the associated launch overheads and queuing latency. Moreover, it allows a better mix of dynamically-generated and original (parent) kernels for the scheduler to effectively hide the remaining overheads and improve the utilization of the GPU resources. Our results show that, across 13 benchmarks, SPAWN achieves 69% and 57% speedup over the flat (non-DP) implementation and baseline DP, respectively.","2378-203X","978-1-5090-4985-1","10.1109/HPCA.2017.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920863","","Kernel;Graphics processing units;Instruction sets;Parallel processing;Benchmark testing;Hardware;Performance evaluation","","35","","46","IEEE","8 May 2017","","","IEEE","IEEE Conferences"
